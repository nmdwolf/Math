\chapter{Derivations: Mathematics}

\section{Group theory}
\subsection{Explanation for property \ref{group:transitive_action_property}}\label{proof:stabilizer}

    Pick an element $x\in X$. The stabilizer of $x$ with respect to $G$ is the set \[S_x := \{g\in G:g\cdot x = x\}.\]
    Due to the transitivity of the group action we have that \[\forall x, y\in X: \exists h\in G: h\cdot x = y.\] So for every $z\in X$ we can choose a group element $g_z$ such that $g_z\cdot x = z$. For all elements in the coset $g_zS_x = \{g_zs\in G:s\in S_x\}$ the following equality is satisfied: \[(g_zs)\cdot x = g_z\cdot (s\cdot x) = g_z\cdot x = z.\] This implies that the map $\Phi:G/S_x \rightarrow X$ is surjective.

    Now we need to prove that $\Phi$ is also injective. We give a proof by contradiction. Choose two distinct cosets $gS_x$ and $hS_x$. Then there exist two elements $G, H\in X$ such that $g\cdot x = G$ and $h\cdot x = H$. Assume that $G = H$. This means that
    \begin{align*}
        &g\cdot x = h\cdot x\\
        \iff&(h^{-1}g)\cdot x = x\\
        \iff&h^{-1}g\in S_x\\
        \iff&hS_x\mathrel{\reflectbox{$\in$}}h(h^{-1}g) = g.
    \end{align*}
    This would imply that $gS_x = hS_x$ which is in contradiction with our assumptions. It follows that $G\neq H$ and hence that $\Phi$ is injective.\qed

\section{Calculus}
\subsection{Proof of method \ref{calculus:borel_transform}}

    The function $F(x)$ is defined as follows:
    \begin{gather}
        F(x) := \ds\sum_{n=0}^{+\infty}\stylefrac{a_n}{n!}x^n.
    \end{gather}
    We now perform a Borel transform:
    \begin{gather}
        \begin{array}{ccl}
            \ds\int_0^{+\infty}F(xt)e^{-t}dt&=&\ds\sum_{n=0}^N\int_0^{+\infty}\stylefrac{a_n}{n!}x^nt^ne^{-t}dt\\
            &=&\ds\sum_{n=0}^N\frac{a_n}{n!}x^n\int_0^{+\infty}t^ne^{-t}dt\\
            &=&\ds\sum_{n=0}^N\frac{a_n}{n!}x^n\Gamma(n+1)\\
            &=&\ds\sum_{n=0}^Na_nx^n
        \end{array}
   \end{gather}
   where we used the definition of the Gamma function \ref{calculus:gamma_function} on line 3 and the relation between the factorial function and the Gamma function \ref{calculus:gamma_factorial_relation} on line 4.\qed

\section{Linear algebra}
\subsection{Proof of equivalence of definitions \ref{vector:exterior_algebra} and \ref{vector:adef_exterior_algebra}}

    \begin{gather}
        (u+v)\otimes(u+v) - u\otimes u - v\otimes v = u\otimes v + v\otimes u
    \end{gather}
    The LHS is an element of the ideal $I$ generated by $\{v\otimes v;v\in V\}$. Using the ideal generated by elements such as in the RHS gives the usual definition of the exterior algebra based on the wedge product as defined in \ref{vector:wedge_product} because it imposes the relation $u\wedge v = -v\wedge u$.

    We do however have to pay attention to one little detail. As mentioned in \ref{vector:adef_exterior_algebra} the general definition uses the ideal $I$ to construct the quotient space. The other construction is only equivalent when are working over a field with characteristic different from 2. This follows from the fact that we have to divide by 2 when trying to obtain the ideal $I$ from the RHS when setting $u=v$.

\section{Manifolds and bundles}
\subsection{Proof of equivalence of definitions \ref{diff:tangent_vector_partial} and \ref{diff:alternative_definition}}

    Let $(U, \varphi)$ be a chart around the point $p\in M$. Using the first definition of a tangent vector (\ref{diff:tangent_vector_partial}), i.e. \[\left.\ds\pderiv{}{q^i}\right|_{p}:\mathcal{F}_p(M, \mathbb{R})\rightarrow\mathbb{R}:f\mapsto \pderiv{}{q^i}\left(f\circ\varphi^{-1}\right)(\varphi(p))\] we can rewrite equation \ref{diff:tangent_vector_chain_rule} \[v_p(f) = \pderiv{(f\circ\varphi^{-1})}{q^i}(\varphi(p))\deriv{q^i}{t}(0)\] as follows: \[v_p(f) = \left.\pderiv{f}{q^i}\right|_p\deriv{q^i}{t}(0).\] Because the partial derivatives as defined in \ref{diff:tangent_vector_partial} form a basis for the tangent space (by construction), we see that this equation is in fact an expansion of the tangent vector $v_p$ in terms of that basis. It follows that vectors tangent to curves\footnote{More precisely: representatives of equivalence classes of vectors tangent to curves.} are also tangent vectors according to the first definition.

    To prove the other direction we have to show that the partial derivative operators can be constructed as vectors tangent to curves.

    A tangent vector can be expressed, according to the first construction, in the following way:
    \[
        v_p = v^i\left.\pderiv{}{q^i}\right|_p
    \]
    where we also define $v = (v^1, ..., v^n)$. We can then construct the curve $\gamma: t\mapsto \varphi^{-1}(q_0+vt)$. It is obvious that the tangent vector $v_p$ is tangent to the curve $\gamma$. From this it follows that we have an isomorphism between the tangent vectors from to the first definition and the equivalence classes of vectors tangent to curves from the second definition. These definitions are thus equivalent.\qed

    Although the previous equivalence implies that the tangent space construction using germs of curves gives us a vector space we could also check the vector space axioms directly. First we prove that the sum of vectors tangent to the curves $\gamma$ and $\delta$ is again a vector tangent to some curve $\chi:\mathbb{R}\rightarrow M$. For this let us define the curve \[\chi(t) \equiv \varphi^{-1}\circ\Big(\varphi\circ\gamma(t) + \varphi\circ\delta(t) - \varphi(p)\Big)\] where $\varphi$ is again the coordinate map in some chart $(U, \varphi)$ around $p\in M$. Using equation \ref{diff:tangent_vector_chain_rule} we find
    \begin{align*}
        v_{p, \chi}(f) &= \pderiv{(f\circ\varphi^{-1})}{q^i}(\varphi(p))\deriv{(\varphi^i\circ\chi)}{t}(0)\\
        &=\pderiv{(f\circ\varphi^{-1})}{q^i}(\varphi(p))\deriv{}{t}\left(\varphi^i\circ\gamma + \varphi^i\circ\delta - \varphi^i(p)\right)\\
        &=\pderiv{(f\circ\varphi^{-1})}{q^i}(\varphi(p))\left(\deriv{(\varphi^i\circ\gamma)}{t} + \deriv{(\varphi^i\circ\delta)}{t}\right)\\
        &=v_{p, \gamma}(f) + v_{p, \delta}(f).
    \end{align*}
    The constant term $-\varphi(p)$ in the definition of $\chi(t)$ is necessary to make sure that $\chi(0) = \gamma(0) = \delta(0) = p$. The scalar multiplication by a number $\lambda\in K$ can be proven by defining the curve $\chi(t) = \varphi^{-1}\circ\left[\lambda\Big(\varphi\circ\gamma(t)\Big)\right]$.

\subsection{Explanation for example \ref{diff:lie_derivative_function}}\index{Landau!little-o notation}

    In this derivation we use the Landau little-o notation $o(t)$, i.e.:
    \begin{gather}
        \lim_{t\rightarrow0}\frac{o(t)}{t} = 0
    \end{gather}
    Now assume that $X$  is a smooth vector field and $f$ is a smooth function. Because the Lie derivative is a local operation we can work in a local chart such that $\gamma$ is (again locally) equivalent to a curve\footnote{The vector field $X(p) = (p, Y(p))$ where $Y$ is a smooth vector field on $\mathbb{R}^n$ can also be identified with $Y$ itself. This is implicitly done in the derivation by using the notation $X$ for both vector fields.} $\beta_p:U\rightarrow\mathbb{R}^n$ and such that we can expand $\beta_p(t)$ around $p\in U$:
    \begin{align}
        \mathcal{L}_Xf(p) &= \lim_{t\rightarrow0}\left[\stylefrac{f(\beta_p(0) + t\beta_p'(0) + o(t)) - f(p)}{t}\right]\nonumber\\
        &= \lim_{t\rightarrow0}\left[\stylefrac{f(p + tX(p) + o(t)) - f(p)}{t}\right]\nonumber\\
        &= \lim_{t\rightarrow0}\left[\stylefrac{f(p) + tDf(p)\cdot X(p) + o(t) - f(p)}{t}\right]\nonumber\\
        &= \sum_k\pderiv{f}{x^k}(p)X_k(p) + \lim_{t\rightarrow0}\stylefrac{o(t)}{t}\nonumber\\
        &= \sum_k\pderiv{f}{x^k}(p)X_k(p)\label{manifolds:lie_derivative_calc}
    \end{align}
    where we used the defining condition \ref{diff:integral_curve} for integral curves on the second line. If we now rewrite this equation as an operator equality, we obtain
    \begin{gather}
        \mathcal{L}_X = \sum_kX_k\pderiv{}{x^k}.
    \end{gather}

\subsection{Explanation for formula \ref{diff:lie_derivative_vector_field}}

    For vector fields we cannot just take the difference at two different points because the tangent spaces generally do not coincide. We can solve this by using the flow \ref{diff:flow}:
    \begin{gather}
        \label{derivmath:lie_derivative_vector_fields}
        \mathcal{L}_XY = \lim_{t\rightarrow0}\stylefrac{(T\sigma_t)^{-1}[X(\gamma_p(t))] - X(p)}{t}
    \end{gather}
    where the $T\sigma_t$ is the differential \ref{diff:differential} of the flow which satisfies $(T\sigma)^{-1} = T\sigma_{-t}$. To see that this definition makes sense we have to show that $(T\sigma_t)^{-1}[X(\gamma_p(t))]\in T_pM$. This goes as follows:
    \begin{align*}
        (T\sigma_t)^{-1}[X(\gamma_p(t))](f) &= T\sigma_{-t}[X(\gamma_p(t))](f)\\
        &= X(\sigma_{-t}\circ\gamma_p(t))(f\circ\sigma_{-t})\\
        &= X(\sigma_{-t}\circ\sigma_t(p))(f\circ\sigma_{-t})\\
        &= X(p)(f\circ\sigma_{-t})\\
        &\in T_pM
    \end{align*}
    for all $f\in C^k(M, \mathbb{R})$. On the third line we used the definition of the flow \ref{diff:flow}.

    We can also rewrite the second term in the numerator of \ref{derivmath:lie_derivative_vector_fields} using the flow: \[X(p) = X(\sigma_0(p)) = T\sigma_0(X)\] Using the definition of the pushforward of vector fields \ref{diff:pushforward} the Lie derivative can be rewritten as follows:
    \begin{align*}
        \mathcal{L}_XY &= \lim_{t\rightarrow0}\stylefrac{\sigma_{-t*}X(\gamma_p(t)) - \sigma_{0*}X(\gamma_p(0))}{t}\\
        &= \left.\deriv{}{t}(\sigma_{-t*}X)(\gamma_p(t))\right|_{t=0}.
    \end{align*}
    Or finally by using the relation between pushforward and pullback \ref{diff:pullback_pushforward} this becomes
    \begin{gather}
        \mathcal{L}_XY = \left.\deriv{}{t}(\sigma_t^*X)(\gamma_p(t))\right|_{t=0}.
    \end{gather}

\subsection{Explanation of remark \ref{diff:vector_calculus}}

    Looking at formula \ref{diff:function_derivative} for the exterior derivative of a smooth function and remembering the definition of the gradient \ref{vector:gradient} we see that these two definitions appear very similar. The major difference lies in the fact that $\nabla f$ is a vector in $\mathbb{R}^3$ and $df$ is a covector in $\mathbb{R}^{*3}$. However there exists an isomorphism between these spaces and so we can identify $\nabla f$ and $df$.

    Similar relations hold for the rotor \ref{vector:rotor} and divergence \ref{vector:divergence}, however here we have to use a different construction as we will be working with the spaces $\Lambda^1$ and $\Lambda^2$. However we can use the Hodge star \ref{vector:hodge_star} to obtain the correct dimensions.

    Consider a vector $\vector{f} = (f_1, f_2, f_3)$ where $f_i$ is smooth. Using these functions $f_i$ we can construct a 1-form $\alpha = f_1dx_1 + f_2dx_2 + f_3dx_3$ and a 2-form $\omega = f_1dx_2\wedge dx_3 + f_2dx_3\wedge dx_1 + f_3 dx_1\wedge dx_2$. After applying the exterior derivative (in the corresponding spaces) we obtain
    \begin{align}
        d\alpha &= \left(\pderiv{f_3}{x_2} - \pderiv{f_2}{x_3}\right)dx_2\wedge dx_3 + \left(\pderiv{f_1}{x_3} - \pderiv{f_3}{x_1}\right)dx_3\wedge dx_1 + \left(\pderiv{f_2}{x_1} - \pderiv{f_1}{x_2}\right)dx_1\wedge dx_2 \nonumber\\
        d\omega &= \left(\pderiv{f_1}{x_1} + \pderiv{f_2}{x_2} + \pderiv{f_3}{x_3}\right)dx_1\wedge dx_2\wedge dx_3. \nonumber
    \end{align}
    Using result \ref{vector:hodge_star_vectorcalculus} and the canonical isomorphism $\sim\ :\mathbb{R}^{3*}\rightarrow\mathbb{R}^3$ we can rewrite this as
    \begin{align}
        \sim df &= \nabla f \\
        \sim (\ast d\alpha) &= \nabla\times\vector{f} \\
        \ast d\omega &= \nabla\cdot\vector{f}.
    \end{align}
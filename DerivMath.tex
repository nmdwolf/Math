\chapter{Derivations: Mathematics}

\section{Calculus}

\subsection{Proof of method \ref{calculus:borel_transform}}
	The function $F(x)$ is defined as follows:
	\begin{equation}
		F(x) = \ds\sum_{n=0}^{+\infty}\stylefrac{a_n}{n!}x^n
	\end{equation}
	We now perform a Borel transform:
	\begin{equation}
    		\begin{array}{ccl}
    			\ds\int_0^{+\infty}F(xt)e^{-t}dt&=&\ds\sum_{n=0}^N\int_0^{+\infty}\stylefrac{a_n}{n!}x^nt^ne^{-t}dt\\
        		&=&\ds\sum_{n=0}^N\frac{a_n}{n!}x^n\int_0^{+\infty}t^ne^{-t}dt\\
		        &=&\ds\sum_{n=0}^N\frac{a_n}{n!}x^n\Gamma(n+1)\\
		        &=&\ds\sum_{n=0}^Na_nx^n
	    	\end{array}
       	\end{equation}
       	where we used the definition of the Gamma function \ref{calculus:gamma_function} on line 3 and the relation between the factorial function and the Gamma function \ref{calculus:gamma_factorial_relation} on line 4.\qed

\section{Linear algebra}
\subsection{Explanation for property \ref{linalgebra:grassmannian_construction}}\label{proof:stabilizer}

	Pick a subspace $W\in \text{Gr}(k, V)$. The stabilizer of $W$ with respect to $GL(V)$ is the set \[H_W = \{g\in GL(V)| g\cdot W = W\}\]
	Due to the transitivity of the group action we have that
	\[\forall X, Y\in Gr(k, V): \exists h\in GL(V): h\cdot X = Y\]
	So for every $U\in \text{Gr}(k, V)$ we can choose a group element $g_U$ such that $g_U\cdot W = U$. For all elements in the coset $g_UH_W = \{g_Uh\in GL(V)|h\in H_W\}$ the following equality is satisfied:
	\[(g_Uh_W)\cdot W = g_U\cdot (h_WW) = g_U\cdot W = U\]
	This implies that the map $\Phi:GL(V)/H_W \rightarrow \text{Gr}(k, V)$ is surjective.
	
	Now we need to prove that $\Phi$ is also injective. We give a proof by contradiction. Choose two distinct cosets $pH_W$ and $qH_W$. Then there exist two subspaces $P, Q\in \text{Gr}(k, V)$ such that $p\cdot W = P$ and $q\cdot W = Q$. Now assume that $P = Q$. This means that
	\begin{align*}
		&p\cdot W = q\cdot W\\
		\iff&(q^{-1}p)\cdot W = W\\
		\iff&q^{-1}p\in H_W\\
		\iff&qH_W\mathrel{\reflectbox{$\in$}}q(q^{-1}p) = p
	\end{align*}
	This would imply that $pH_W = qH_W$ which is in contradiction to our assumption. It follows that $P\neq Q$ and that $\Phi$ is injective.\qed

\subsection{Proof for the equality of definitions \ref{tensor:exterior_algebra} and \ref{tensor:adef_exterior_algebra}}
	\begin{equation}
		(u+v)\otimes(u+v) - u\otimes u - v\otimes v = u\otimes v + v\otimes u
	\end{equation}
	The LHS is an element of the ideal $I$ generated by $\{v\otimes v|v\in V\}$. Using the ideal generated by elements such as in the RHS gives the usual definition of the exterior algebra based on the wedge product as defined in \ref{tensor:wedge_product} because it imposes the relation $u\wedge v = -v\wedge u$.
	
	We do however have to pay attention to one little detail. As mentioned in \ref{tensor:adef_exterior_algebra} the general definition uses the ideal $I$ to construct the quotient space. The other construction is only equivalent when working over a field with a characteristic different from 2. This follows from the fact that we have to divide by 2 when trying to obtain the ideal $I$ from the RHS by setting $u=v$.

\section{Vector fields \& differential forms}
\subsection{Explanation for example \ref{manifolds:ex:lie_derivative_function}}\index{Landau!little-o notation}

	In this derivation we use the Landau little-o notation $o(t)$, i.e.:
	\begin{equation}
		\lim_{t\rightarrow0}\frac{o(t)}{t} = 0
	\end{equation}
	Now assume that $X$  is a smooth vector field and $f$ is a smooth function. Because the Lie derivative is a local operation we can work in a local chart such that $\gamma$ is (again locally) equivalent to a curve\footnotemark\ $\beta_p:U\rightarrow\mathbb{R}^n$ and such that we can expand $\beta_p(t)$ around $p\in U$:
	\begin{align}
		\mathcal{L}_Xf(p) &= \lim_{t\rightarrow0}\left[\stylefrac{f(\beta_p(0) + t\beta_p'(0) + o(t)) - f(p)}{t}\right]\nonumber\\
		&= \lim_{t\rightarrow0}\left[\stylefrac{f(p + tX(p) + o(t)) - f(p)}{t}\right]\nonumber\\
		&= \lim_{t\rightarrow0}\left[\stylefrac{f(p) + tDf(p)\cdot X(p) + o(t) - f(p)}{t}\right]\nonumber\\
		&= \sum_k\pderiv{f}{x^k}(p)X_k(p) + \lim_{t\rightarrow0}\stylefrac{o(t)}{t}\nonumber\\
		&= \sum_k\pderiv{f}{x^k}(p)X_k(p)\label{manifolds:lie_derivative_calc}
	\end{align}
	where we used the defining condition \ref{manifolds:integral_curve} for integral curves on line 2. If we now rewrite this equation as an operator equality, we obtain:
	\begin{equation}
		\boxed{\mathcal{L}_X = \sum_kX_k\pderiv{}{x^k}}
	\end{equation}
	\footnotetext{The vector field $X(p) = (p, Y(p))$ where $Y$ is a smooth vector field on $\mathbb{R}^n$ can also be identified with $Y$ itself. This is implicitly done in the derivation by using the notation $X$ for both vector fields.}
		
\subsection{Explanation for formula \ref{manifolds:ex:lie_derivative_vector_fields}}

	For vector fields we cannot just take the difference at two different points because the tangent spaces generally do not coincide. We can solve this by using the flow \ref{manifolds:flow}:
	\begin{equation}
		\label{derivmath:lie_derivative_vector_fields}
		\mathcal{L}_XY = \lim_{t\rightarrow0}\stylefrac{(T\sigma_t)^{-1}[X(\gamma_p(t))] - X(p)}{t}
	\end{equation}
	where the $T\sigma_t$ is the differential \ref{manifolds:differential} of the flow which satisfies $(T\sigma)^{-1} = T\sigma_{-t}$. To see that this definition makes sense we have to show that $(T\sigma_t)^{-1}[X(\gamma_p(t))]\in T_pM$. This goes as follows:
	\begin{align*}
		(T\sigma_t)^{-1}[X(\gamma_p(t))](f) &= T\sigma_{-t}[X(\gamma_p(t))](f)\\
		&= X(\sigma_{-t}\circ\gamma_p(t))(f\circ\sigma_{-t})\\
		&= X(\sigma_{-t}\circ\sigma_t(p))(f\circ\sigma_{-t})\\
		&= X(p)(f\circ\sigma_{-t})\\
		&\in T_pM
	\end{align*}
	for all $f\in C^k(M, \mathbb{R})$. On line 3 we used the definition of the flow \ref{manifolds:flow}.
		
	We can also rewrite the second term in the numerator of \ref{derivmath:lie_derivative_vector_fields} using the flow:
	\[
		X(p) = X(\sigma_0(p)) = T\sigma_0(X)
	\]
	Using the definition of the pushforward of vector fields \ref{manifolds:pushforward} the Lie derivative can be rewritten as:
	\begin{align*}
		\mathcal{L}_XY &= \lim_{t\rightarrow0}\stylefrac{\sigma_{-t*}X(\gamma_p(t)) - \sigma_{0*}X(\gamma_p(0))}{t}\\
		&= \left.\deriv{}{t}(\sigma_{-t*}X)(\gamma_p(t))\right|_{t=0}
	\end{align*}
	Or finally by using the relation between pushforward and pullback \ref{manifolds:pullback_pushforward} this becomes:
	\begin{equation}
		\boxed{\mathcal{L}_XY = \left.\deriv{}{t}(\sigma_t^*X)(\gamma_p(t))\right|_{t=0}}
	\end{equation}
		 
\subsection{Explanation for remark \ref{forms:vector_calculus}}

Looking at formula \ref{forms:function_derivative} for the exterior derivative of a smooth function and remembering the definition of the gradient \ref{vectorcalculus:gradient} we see that these two definitions appear very similar. The major difference lies in the fact that $\nabla f$ is a vector in $\mathbb{R}^3$ and $df$ is a covector in $\mathbb{R}^{*3}$. However there exists an isomorphism between these spaces and so we can identify $\nabla f$ and $df$.
		
		Similar relations hold for the rotor \ref{vectorcalculus:rotor} and divergence \ref{vectorcalculus:divergence}, however here we have to use a different construction as we will be working with the spaces $\Lambda^1$ and $\Lambda^2$. However we can use the Hodge star \ref{tensor:hodge_star} to obtain the correct dimensions.
		
		Consider a vector $\vector{f} = (f_1, f_2, f_3)$ where $f_i$ is smooth. Using these functions $f_i$ we can construct a 1-form $\alpha = f_1dx_1 + f_2dx_2 + f_3dx_3$ and a 2-form $\omega = f_1dx_2\wedge dx_3 + f_2dx_3\wedge dx_1 + f_3 dx_1\wedge dx_2$. After applying the exterior derivative (in the corresponding spaces) we obtain:
		\begin{align}
			d\alpha &= \left(\pderiv{f_3}{x_2} - \pderiv{f_2}{x_3}\right)dx_2\wedge dx_3 + \left(\pderiv{f_1}{x_3} - \pderiv{f_3}{x_1}\right)dx_3\wedge dx_1 + \left(\pderiv{f_2}{x_1} - \pderiv{f_1}{x_2}\right)dx_1\wedge dx_2 \nonumber\\
			d\omega &= \left(\pderiv{f_1}{x_1} + \pderiv{f_2}{x_2} + \pderiv{f_3}{x_3}\right)dx_1\wedge dx_2\wedge dx_3 \nonumber
		\end{align}
		Using result \ref{tensor:hodge_star_vectorcalculus} and the isomorphism $\sim\ :\mathbb{R}^{3*}\rightarrow\mathbb{R}^3$ we can rewrite this as:
		\begin{empheq}[box=\fbox]{align}
			\sim df &= \nabla f \\
			\sim (\ast d\alpha) &= \nabla\times\vector{f} \\
			\ast d\omega &= \nabla\cdot\vector{f}
		\end{empheq}

\chapter{Calculus}

\nomenclature[S_CartSp]{$\mathrm{CartSp}$}{the category of Euclidean spaces and ``suitable'' homomorphisms (e.g. linear maps, smooth maps, ...)}

\section{General definitions}

    \newdef{Domain}{\index{domain}
        A connected open subset of $\mathbb{R}^n$.
    }

    \newdef{Factorial}{\index{factorial}
        \begin{gather}
            n! := n(n-1)\cdots1
        \end{gather}
    }

\section{Sequences}\index{sequence}

    \newdef{Limit superior}{\index{limit}\label{calculus:limit_superior}
        Let $\seq{x}$ be a sequence of real numbers. The limit superior is defined as follows:
        \begin{gather}
            \limsup_{n\rightarrow\infty}x_n := \inf_{n\geq1}\left\{\sup_{k\geq n}x_n\right\}.
        \end{gather}
    }
    \newdef{Limit inferior}{\label{calculus:limit_inferior}
        Let $\seq{x}$ be a sequence of real numbers. The limit superior is defined as follows:
        \begin{gather}
            \liminf_{n\rightarrow\infty}x_n := \sup_{n\geq1}\left\{\inf_{k\geq n}x_n\right\}.
        \end{gather}
    }

    \begin{property}
        A sequence $\seq{x}$ converges pointwise if and only if
        \begin{gather}
            \limsup_{n\rightarrow\infty}x_n = \liminf_{n\rightarrow\infty}x_n.
        \end{gather}
    \end{property}

\section{Continuity}\index{continuity}

    \newdef{Lipschitz continuity}{\index{Lipschitz!continuity}\label{calculus:lipschitz_continuity}
        A function $f:\mathbb{R}\rightarrow\mathbb{R}$ is said to be Lipschitz continuous if there exists a constant $C>0$ such that
        \begin{gather}
            |f(x) - f(x')|\leq C|x-x'|
        \end{gather}
        for all $x,x'\in\mathbb{R}$.
    }

    \begin{theorem}[Darboux]\index{Darboux!theorem for differentiable functions}
        Every differentiable function defined on a closed interval has the intermediate value property \ref{topology:intermediate_value_theorem}.
    \end{theorem}
    \begin{definition}[Darboux function]\index{Darboux!function}
        A function that has the intermediate value property.
    \end{definition}
    \begin{result}[Bolzano]\index{Bolzano}
        If $f(a)<0$ and $f(b)>0$ (or vice versa), there exists at least one point $x_0$ for which $f(x_0)=0$.
    \end{result}

    \begin{theorem}[Weierstrass's extreme value theorem]\index{Weierstrass!extreme value theorem}
        Let $I=[a,b]\subset\mathbb{R}$ be a closed interval and let $f$ be a continuous function defined on $I$. Then $f$ attains a minimum and maximum at least once on $I$.
    \end{theorem}

    \newdef{Absolute continuity}{\index{continuity!absolute}\label{calculus:absolute_continuity}
        A function $f:\mathbb{R}\rightarrow\mathbb{R}$ is said to be absolutely continuous if for every $\varepsilon>0$ there exists a $\delta_\varepsilon>0$ such that for every finite collection of disjoint intervals $]x_i,y_i[$ satisfying
        \begin{gather}
            \sum_i(y_i-x_i)<\delta_\varepsilon,
        \end{gather}
        the function $f$ satisfies
        \begin{gather}
            \sum_i|f(y_i)-f(x_i)|<\varepsilon.
        \end{gather}
    }

    \begin{property}
        The different types of continuity form the following hierarchy: \[\text{Lipschitz-continuous}\subset\text{absolutely  continuous}\subset\text{uniformly continuous}\subset\text{continuous}.\]
    \end{property}

    \newdef{Function of bounded variation}{\index{bounded variation}
        A function $f$ is said to be of bounded variation on the interval $[a,b]$ if the following quantity is finite:
        \begin{gather}
            V_{a,b}(f) := \sup_{P\in\mathcal{P}}\sum_{i=0}^{|P|-1}|f(x_{i+1})-f(x_i)|,
        \end{gather}
        where the supremum is taken over all partitions of $[a,b]$.
    }
    \begin{property}\label{calculus:bounded_variation_decomposition}
        Every function of bounded variation can be decomposed as the difference of two monotonically increasing functions.
    \end{property}

    \begin{example}
        Every absolutely continuous function is of bounded variation.
    \end{example}

\section{Convergence}\index{convergence}

    \newdef{Pointwise convergence}{
        Let $\seq{f}$ be a sequence of functions. The sequence is said to converge pointwise to a limit function $f$ if
        \begin{gather}
            \forall x\in\dom(f_n):\lim_{n\rightarrow\infty}f_n(x) = f(x).
        \end{gather}
    }
    \newdef{Uniform convergence}{
        Let $\seq{f}$ be a sequence of functions. The sequence is said to converge uniformly to a limit function $f$ if
        \begin{gather}
            \lim_{n\rightarrow\infty}\sup_{x\in\dom(f_n)}\big\{|f_n(x) - f(x)|\big\} = 0.
        \end{gather}
    }

\section{Series}
\subsection{Convergence tests}\index{convergence}

    \begin{property}
        A necessary condition for the convergence of a series $\sum_{i=n}^\infty a_i$ is that $\lim_{n\rightarrow\infty}a_n = 0$.
    \end{property}

    \newprop{Absolute/conditional convergence}{
        If $S'=\sum_{i=1}^\infty|a_i|$ converges, so does the series $S=\sum_{i=1}^\infty a_i$. Moreover, $S$ is said to be absolutely convergent. If $S$ converges but $S'$ does not, then $S$ is said to be conditionally convergent.
    }

    \newdef{Majorizing series}{\index{majorization}
        Let $S_a=\sum_{i=1}^\infty a_i$ and $S_b=\sum_{i=1}^\infty b_i$ be two series. The series $S_a$ is said to majorize $S_b$ if for every $k>0$ the partial sums satisfy $S_{a,k}\geq S_{b,k}$.
    }
    \begin{method}[Comparison test]\index{convergence!comparison test}
        Let $S_a,S_b$ be two series such that $S_a$ majorizes $S_b$.
        \begin{itemize}
            \item If $S_b$ diverges, then $S_a$ diverges.
            \item If $S_a$ converges, then $S_b$ converges.
            \item If $S_b$ converges, nothing can be said about $S_a$.
            \item If $S_a$ diverges, nothing can be said about $S_b$.
        \end{itemize}
    \end{method}

    \begin{method}[MacLaurin-Cauchy integral test]\index{convergence!integral test}\index{MacLaurin-Cauchy|see{convergence}}
        Let $f$ be a nonnegative, continuous and monotonically decreasing function defined on the interval $[n,\infty[$. If $\int_n^\infty f(x)dx$ is convergent, so is $\sum_{k=n}^\infty f(k)$. On the other hand, if the integral is divergent, so is the series.
    \end{method}
    \begin{remark}
        The function does not have to be nonnegative and decreasing on the complete interval. As long as it does on the interval $[N,\infty[$ for some $N\geq n$, the statement holds. This can be seen by writing $\sum_{k=n}^\infty f(k) = \sum_{k=n}^Nf(k) + \sum_{k=N}^\infty f(k)$ and noting that the first term is always finite (and similarly for the integral).
    \end{remark}

    \begin{property}
        If the integral in the previous theorem converges, the series is bounded in the following way:
        \begin{gather}
            \int_n^\infty f(x)dx \leq \sum_{i=n}^\infty a_i \leq f(n) + \int_n^\infty f(x)dx
        \end{gather}
    \end{property}

    \begin{method}[d'Alembert's ratio test]\index{convergence!ratio test}\index{d'Alembert!ratio test|see{convergence}}
        Define the quantity
        \begin{gather}
            R := \lim_{n\rightarrow\infty}\left|\stylefrac{a_{n+1}}{a_n}\right|
        \end{gather}
        The following cases can be distinguished:
        \begin{itemize}
            \item $R<1$: the series converges absolutely.
            \item $R>1$: the series does not converge.
            \item $R=1$: the test is inconclusive.
        \end{itemize}
    \end{method}

    \begin{method}[Cauchy's root test]\index{convergence!root test}\index{Cauchy!root test|see{convergence}}
        Define the quantity
        \begin{gather}
            R := \limsup_{n\rightarrow\infty}\sqrt[n]{|a_n|}
        \end{gather}
        The following cases can be distinguished:
        \begin{itemize}
            \item $R<1$: the series converges absolutely.
            \item $R>1$: the series does not converge.
            \item $R=1$ and the limit approaches strictly from above: the series diverges.
            \item $R=1$: the test is inconclusive.
        \end{itemize}
    \end{method}
    \newdef{Radius of convergences}{\index{convergence!radius}
        The number $1/R$ is called the radius of convergence.
    }
    \begin{remark}
        The root test is stronger than the ratio test. However, if the ratio test can determine the convergence of a series, the radius of convergence of both tests will coincide and, hence, it is a well-defined quantity.
    \end{remark}

    \begin{method}[Gauss's test]\index{convergence!Gauss's test}
        If $a_n>0$ for all $n$, one can write the ratio of successive terms as follows:
        \begin{gather}
            \label{series:gauss_test}
            \left|\stylefrac{a_n}{a_{n+1}}\right| = 1 + \stylefrac{h}{n} + \stylefrac{B(n)}{n^k},
        \end{gather}
        where $k>1$ and $B(n)$ is a bounded function when $n\rightarrow\infty$. The series converges if $h>1$ and diverges otherwise.
    \end{method}

    \newdef{Asymptotic expansion}{\index{asymptotic!expansion}
        Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a continuous function. A series $\sum_{i=0}^\infty a_nx^n$ is called an asymptotic expansion of $f$ if there exists an $n\in\mathbb{N}$ such that
        \begin{gather}
            \label{calculus:asymptotic_expansion}
            f(x) - \sum_{i=0}^na_ix^i = O(x^{n+1})
        \end{gather}
        for all $x\in\mathbb{R}$.
    }

\section{Differentiation}\index{differentiation}

    \newformula{Derivative}{\label{calculus:derivative}
        Consider a function $f:\mathbb{R}\rightarrow\mathbb{R}$. The following limit is called the derivative of $f$ (if it exists):
        \begin{gather}
            f'(x) := \lim_{h\rightarrow0}\frac{f(x+h)-f(x)}{h}.
        \end{gather}
    }

    \begin{theorem}[Mean value theorem]\index{mean!value theorem}\label{calculus:mean_value_theorem}
        Let $f$ be a continuous function defined on the closed interval $[a,b]$ and differentiable on the open interval $]a,b[$. There exists a point $c\in\ ]a,b[$ such that
        \begin{gather}
            f'(c) = \frac{f(b)-f(a)}{b-a}.
        \end{gather}
    \end{theorem}

    \newdef{Differentiablity class}{\label{calculus:differentiablity_class}
        Let $I$ be a set and let $f$ be a function defined on $I$. If $f$ is $n$ times continuously differentiable on $I$ (i.e. $f^{(i)}$ exists and is continuous for $i=1,\dotso,n$), then $f$ is said to be of class $C^n(I)$.
    }
    \newdef{Smooth function}{\index{smooth!function}\label{calculus:smooth}
        A function $f$ is said to be smooth if it is of class $C^\infty$.
    }

    \begin{theorem}[Boman]\index{Boman}
        Consider a function $f:\mathbb{R}^d\rightarrow\mathbb{R}$. If for every smooth function $g:\mathbb{R}\rightarrow\mathbb{R}^d$ the composition $f\circ g$ is smooth, then the function $f$ is also smooth.
    \end{theorem}

    \begin{property}[Taylor expansion]\index{Taylor!expansion}\index{Maclaurin|see{Taylor expansion}}
        Let $f:\mathbb{R}\rightarrow\mathbb{R}$ be a smooth function. Around every point $x\in\mathbb{R}$ one can express $f$ as the following series:
        \begin{gather}
            f(y) = f(x) + f'(x)(y-x) + \frac{f''(x)}{2}(y-x)^2 + \cdots = \sum_{n=0}^\infty\frac{f^{(n)}(x)}{n!}(y-x)^n.
        \end{gather}
        For the special case $x=0$ the name \textbf{Maclaurin series} is sometimes used.
    \end{property}

    \newdef{Analytic function}{\index{analytic}\label{calculus:analytic}
        \nomenclature[S_Comega]{$C^\omega(V)$}{the set of all analytic functions defined on the set $V$}
        A function $f$ is said to be analytic if it is smooth and if its Taylor series expansion around any point $x$ converges to $f$ in some neighbourhood of $x$. The set of analytic functions defined on $V$ is denoted by $C^\omega(V)$.
    }

    \begin{theorem}[Hadamard lemma]\index{Hadamard!lemma}
        Let $f:\mathbb{R}^n\rightarrow\mathbb{R}$ be a smooth function defined on an open, star-convex set $U$. One can expand the function as follows:
        \begin{gather}
            f(x) = f(x_0) + \sum_{i=1}^n(x^i-x^i_0)g_i(x_0),
        \end{gather}
        where all functions $g_i$ are also smooth on $U$.
    \end{theorem}
    From this expression one can also see that the functions $g_i$, evaluated at 0, give the partial derivatives of $f$. These functions are sometimes called the \textbf{Hadamard quotients}.
    \remark{This lemma gives a finite order approximation of the Taylor expansion of $f$.}

    \begin{theorem}[Schwarz\footnotemark]\index{Schwarz!theorem for second derivatives}\index{Clairaut}\label{calculus:schwarz_theorem}
        \footnotetext{Also called \textbf{Clairaut's theorem}.}
        Consider a twice differentibale function $f\in C^2(\mathbb{R}^n,\mathbb{R})$. The mixed partial derivatives of $f$ coincide for all indices $i,j\leq n$:
        \begin{gather}
            \pderiv{}{x_i}\left(\pderiv{f}{x_j}\right) = \pderiv{}{x_j}\left(\pderiv{f}{x_i}\right).
        \end{gather}
    \end{theorem}

    \begin{formula}[Derivative of \texorpdfstring{$f(x)^{g(x)}$}{f(x)^g(x)}]
        Consider a function of the form \[u(x)=f(x)^{g(x)}.\] To find the derivative of this function one can use the derivative of the natural logarithm: \[\ln[u(x)] = g(x)\ln[f(x)].\] Taking the derivative gives: \[\deriv{\ln[u(x)]}{x} = \deriv{}{x}\Big(g(x)\ln[f(x)]\Big) = \deriv{g(x)}{x}\ln[f(x)] + \frac{g(x)}{f(x)}\deriv{f(x)}{x}.\] At the same time the derivative of a logarithm also satisfies \[\deriv{\ln[u(x)]}{x} = \frac{1}{u(x)}\deriv{u}{x}.\] Combining these two equations finally gives
        \begin{gather}
            \label{calculus:derivative_f^g}
            \deriv{}{x}\left[f(x)^{g(x)}\right] = f(x)^{g(x)}\left[\deriv{g}{x}(x)\ln[f(x)] + \frac{g(x)}{f(x)}\deriv{f}{x}(x)\right].
        \end{gather}
    \end{formula}

    \newdef{Euler operator}{\index{Euler!operator}\label{calculus:euler_operator}
        On the space $C^r(\mathbb{R}^n,\mathbb{R})$, where $r>1$, the Euler operator $\mathbb{E}$ is defined as follows:
        \begin{gather}
            \mathbb{E} := \sum_{i=1}^nx_i\pderiv{}{x^i}.
        \end{gather}
    }
    \begin{theorem}[Euler]\index{homogeneous!function}\index{Euler!homogeneous function theorem}\label{calculus:euler_homogeneous_functions}
        Let $f$ be a homogeneous function, i.e.
        \begin{gather}
            f(\lambda x_1,\ldots,\lambda x_n) = \lambda^nf(x_1,\ldots,x_n).
        \end{gather}
        This function satisfies the following equality:
        \begin{gather}
            \mathbb{E}(f) = nf(x_1,\ldots,x_n).
        \end{gather}
    \end{theorem}

    ?? COMPLETE (add multidimensional extensions) ??

\section{Integration theory}\index{Riemann!integral}

    \newdef{Improper Riemann integral}{
        \begin{gather}
            \label{calculus:improper_integral}
            \int_{-\infty}^\infty f(x)dx = \lim_{\substack{a\rightarrow-\infty\\b\rightarrow\infty}}\int_a^bf(x)dx
        \end{gather}
        One-sided improper integrals are defined in a similar fashion.
    }

    \begin{theorem}[First fundamental theorem of calculus]\index{fundamental theorem!of calculus}
        Let $f$ be a continuous function defined on an open interval $I$ and consider an element $c\in I$. The following theorem establishes the relation between integration and differentiation:
        \begin{gather}
            \exists F\in C^1(I):\forall x\in I:F'(x)=f(x)
        \end{gather}
        Furthermore, the function $F$ is uniformly continuous on $I$ and it is given by the following integral:
        \begin{gather}
            \label{calculus:first_fundamental_theorem}
            F(x) = \int_c^xf(x')dx'.
        \end{gather}
    \end{theorem}

    \begin{remark}
        The function $F$ in the previous theorem is called a \textbf{primitive (function)} of $f$. Remark that $F$ is just ``a'' primitive function since adding a constant to $F$ does not change anything because the derivative of a constant is zero.
    \end{remark}

    \begin{theorem}[Second fundamental theorem of calculus]
        Let $f$ be a $C^1$-function defined on the interval $[a,b]$.
        \begin{gather}
            \label{calculus:second_fundamental_theorem}
            \int_a^bf'(x)dx = f(b) - f(a)
        \end{gather}
    \end{theorem}

    \begin{formula}[Differentiation under the integral sign\footnotemark]\index{Leibniz!integral rule}
        \footnotetext{This is a more general version of the \textit{Leibniz integral rule}.}
        \begin{gather}
            \label{calculus:diff_under_integral}
            \deriv{}{x}\int_{a(x)}^{b(x)}f(x,y)dy = f(x,b(x))\cdot b'(x) - f(x,a(x))\cdot a'(x) + \int_{a(x)}^{b(x)}\pderiv{f(x,y)}{x}dy
        \end{gather}
    \end{formula}

    \newmethod{Borel transform$^\dag$}{\index{Borel!transform}\label{calculus:borel_transform}
        Consider the following function: \[F(x) := \sum_{n=0}^\infty\frac{a_n}{n!}x^n.\] If the integral
        \begin{gather}
            \int_0^\infty e^{-t}F(xt)dt<\infty
        \end{gather}
        for all $x\in\mathbb{R}$, then $F$ is called the Borel transform of $f$. Furthermore, the integral will give a convergent expression for $f$.
    }
    \begin{theorem}[Watson]\index{Watson}
        The uniqueness of the function $F$ is guaranteed if the function $f$ is holomorphic on the domain $\{z\in\mathbb{C}:|\arg(z)| < \frac{\pi}{2} + \varepsilon\}$.
    \end{theorem}

\subsection{Euler integrals}\index{Euler!integral}

   \newformula{Beta function}{\index{beta function}\label{calculus:beta_function}
       The beta function (also known as the \textbf{Euler integral of the first kind}) is defined as follows:
        \begin{gather}
            B(x,y) := \int_0^1t^{x-1}(1-t)^{y-1}dt.
        \end{gather}
    }

   \newformula{Gamma function}{\index{gamma function}\label{calculus:gamma_function}
       The gamma function (also known as the \textbf{Euler integral of the second kind}) is defined as follows:
        \begin{gather}
            \Gamma(x) := \int_0^\infty t^{x-1}e^{-t}dt.
        \end{gather}
    }

    \begin{formula}
        The following formula relates the gamma and beta functions:
        \begin{gather}
            B(x,y) = \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}.
        \end{gather}
    \end{formula}

    \begin{property}[Recursion]
        The gamma function satisfies the following recursion relation for all points $x$ in its domain:
        \begin{gather}
            \Gamma(x+1)=z\Gamma(x).
        \end{gather}
    \end{property}

    \newformula{Factorial}{
        For integers $n\in\mathbb{N}$ the gamma function can be expressed in terms of the factorial:
        \begin{gather}
            \label{calculus:gamma_factorial_relation}
            \Gamma(n) = (n-1)!\,.
        \end{gather}
    }
    \newformula{Stirling}{\index{Stirling}
        This formula (originally stated for the factorial of natural numbers) gives an asymptotic expansion of the gamma function:
        \begin{gather}
            \label{calculus:stirling}
            \ln\Gamma(z) \approx z\ln z - z + \frac{1}{2}\ln\left(\frac{2\pi}{z}\right).
        \end{gather}
    }

\subsection{Gaussian integrals}\index{Gauss!integral}

    \newformula{$n$-dimensional Gaussian integral}{
        A general Gaussian integral is an integral of the form
        \begin{gather}
            I\left(A,\vector{b}\right) = \int_{-\infty}^\infty\exp\left(-\frac{1}{2}\vector{x}\cdot A\vector{x} + \vector{b}\cdot\vector{x}\right)d^nx,
        \end{gather}
        where $A$ is a real symmetric matrix. By performing the transformation $\vector{x}\rightarrow A^{-1}\vector{b} - \vector{x}$ and diagonalizing $A$, one can obtain the following expression:
        \begin{gather}
            \label{calculus:gaussian_integral}
            I\left(A,\vector{b}\right) = (2\pi)^{n/2}\det(A)^{-1/2}\exp\left(\frac{1}{2}\vector{b}\cdot A^{-1}\vector{b}\right).
        \end{gather}
    }
    \begin{result}
        A functional generalization is given by:
        \begin{align}
            I(iA,iJ) &= \int[d\varphi]\exp\left(-i\int d^nxd^ny\ \varphi(x)A(x, y)\varphi(y) + i\int d^nx\ \varphi(x)J(x)\right)\nonumber\\
            &= C\det(A)^{-1/2}\exp\left(\frac{i}{2}\int d^nxd^ny\ J(x)A^{-1}(x, y)J(y)\right),
        \end{align}
        where the analytic continuation $I(iA,iJ)$ of Equation \eqref{calculus:gaussian_integral} was used. One should pay attention to the normalization factor $C$ which is infinite in general.
    \end{result}

\section{Convexity}

    \newdef{Convex set}{\index{convex}\index{hull}\label{calculus:convex}
        A subset of $X$ of a vector space $V$ (Definition \ref{linalgebra:vector_space}) is said to be convex if $x,y\in X$ implies that $\{\lambda x+(1-\lambda)y\mid\lambda\in[0,1]\}\subset X$. The \textbf{convex hull} of a subset $X$ is defined as the smallest convex subset containing $X$.
    }

    \newdef{Convex function}{
        Let $X$ be a convex set. A function $f:X\rightarrow \mathbb{R}$ is said to be convex if for all $x,y\in X$ and $\lambda\in[0,1]$:
        \begin{gather}
            f\big(\lambda x + (1-\lambda)y\big)\leq t\lambda(x) + (1-\lambda)f(y).
        \end{gather}
        For the definition of a \textbf{concave} function the inequality has to be turned around.
    }
    \begin{property}[Linear map]
        A function $f:X\rightarrow\mathbb{R}$ is linear if and only if it is both convex and concave.
    \end{property}

    \begin{theorem}[Karamata's inequality]\index{Karamata}
        Consider an interval $I\subset\mathbb{R}$ and let $f:I\rightarrow\mathbb{R}$ be a convex function. If $(x_1,\ldots,x_n)$ is a tuple that majorizes $(y_1,\ldots,y_n)$, i.e.
        \begin{gather}
            \sum_{i=1}^nx_i = \sum_{i=1}^ny_i
        \end{gather}
        and
        \begin{gather}
            x_{(1)} + \cdots + x_{(k)}\geq y_{(1)} + \cdots + y_{(k)}
        \end{gather}
        for all $k\leq n$, where $x_{(i)}$ denotes the $i^{th}$ largest element of $(x_1,\ldots,x_n)$, then
        \begin{gather}
            \sum_{i=1}^nf(x_i)\geq\sum_{i=1}^nf(y_i).
        \end{gather}
    \end{theorem}
    The following inequality can be derived directly from the definition of convexity by induction:
    \begin{theorem}[Jensen's inequality]\index{Jensen's inequality}\label{calculus:jensen_inequality}
        Let $f$ be a convex function and consider a point $\{a_i\}_{i\leq n}$ in the probability simplex $\Delta^n$ (Definition \ref{topology:standard_simplex}). Jensen's equality states that
        \begin{gather}
            f\left(\sum_ia_ix_i\right)\leq\sum_ia_if(x_i).
        \end{gather}
    \end{theorem}

    \newdef{Legendre transformation}{\index{Legendre!transformation}\label{calculus:legendre}
        Consider a function $f:\mathbb{R}\rightarrow\mathbb{R}$. In certain cases (especially in physics) it is sometimes useful to replace the argument $x$ by the slope of $f$ at $x$, i.e. perform the transformation
        \begin{gather}
            x\longrightarrow\deriv{f}{x}\equiv f'(x).
        \end{gather}
        However, it should be clear that this transformation is not always well-defined and even if it is, it does not always preserve all the information in $f$.

        These conditions are satisfied exactly if $f$ is convex (or concave). In this case the Legendre transform of $f$ is defined as
        \begin{gather}
            f^*(x^*) := \sup_x\big(x^*x - f(x)\big).
        \end{gather}
        Consider the case where $f$ is differentiable. The above supremum can then be obtained by differentiating the right-hand side and equating it to zero. This results in $x^* = f'(x)$, which is exactly the transformation that was required. By expressing everything in terms of the Legendre tranformed quantity $x^*$, one can also find the derivative of $f^*$:
        \begin{gather}
            \deriv{f^*}{x^*}(x^*) = x(x^*).
        \end{gather}
    }
    \begin{remark}
        Although the previous derivation used only 2 coordinates, the definition of Legendre transformations can easily be generalized to more coordinates.
    \end{remark}
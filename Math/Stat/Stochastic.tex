\chapter{Stochastic Calculus}\label{chapter:stochastic_calculus}

\section{Stochastic processes}

    \newdef{Stochastic process}{\index{stochastic!process}
        A sequence of random variables $\tseq{X}$ for some index set $T$. In practice, $T$ will often be a totally ordered set, e.g.~$(\mathbb{R},\leq)$ in the case of a time series.
    }
    \newdef{Jump}{\index{jump}
        The jump of a stochastic process $\tseq{X}$ at $t\in T$ is defined as
        \begin{gather}
            \Delta X_t := X_t - X_{t^-}\,,
        \end{gather}
        where $X_{t^-} := \lim_{s<t}X_s$.
    }

    \newdef{Equivalence}{\index{modification}\index{version}\index{evanescence}
        Stochastic process can be be considered equivalent in different ways. The two most common cases are considered here:
        \begin{itemize}
            \item Two stochastic processes $\tseq{X}$ and $\tseq{Y}$ are said to be \textbf{stochastically equivalent} if $X_t=Y_t$ a.s.~for all $t\in T$. Moreover, the processes are called \textbf{modifications} or \textbf{versions}.
            \item Two stochastic processes $\tseq{X}$ and $\tseq{Y}$ are said to be \textbf{indistinguishable} or \textbf{equivalent up to evanescence} if $X_t=Y_t$ for all $t\in T$ almost surely. Equivalently, they are indistinguishable if their sample paths coincide almost surely.
        \end{itemize}
    }

    \newdef{Continuity}{\index{continuity}\index{sample}\index{path}
        A stochastic process $\tseq{X}$ on a measurable space $(\Omega,\Sigma)$, where $T$ is a topological space (\cref{chapter:topology}), is said to be \textbf{(sample path) continuous} if the functions $t\mapsto X_t(\omega)$ are continuous for almost all $\omega\in\Omega$.
    }
    \begin{property}
        All continuous stochastic processes are \textbf{jointly measurable} when regarded as functions on the product space $T\times\Omega$, where $T$ is equipped with the Borel $\sigma$-algebra.
    \end{property}

    \newdef{Filtered probability space}{\index{probability!space}\index{usual conditions}\index{standard!filtration}
        Consider a probability space $(\Omega,\Sigma,P)$ together with a filtration (\cref{set:filtration}) of $\Sigma$, i.e.~a collection of $\sigma$-algebras $\mathbb{F}\equiv\tseq{\mathbb{F}}$, such that $i\leq j\implies\mathbb{F}_i\subseteq\mathbb{F}_j$. The quadruple $(\Omega,\Sigma,\mathbb{F},P)$ is called a filtered probability space.

        Often, the filtration is required to be exhaustive and separated (where $\emptyset$ is replaced by $\mathbb{F}_0=\{\emptyset,\Omega\}$ since any $\sigma$-algebra has to contain the total space). Moreover, the filtration will often be required to `\textbf{satisfy the usual conditions}' (also called \textbf{standard}): $\mathbb{F}_0$ turns the space into a complete measurable space and $\mathbb{F}$ is right-continuous, i.e.~$\mathbb{F}_t = \bigcap_{s>t}\mathbb{F}_s$.
    }

    \newdef{Adapted process}{\index{adapted!process}
        A stochastic process $\tseq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is said to be adapted to the filtration $\mathbb{F}$ if $X_t$ is $\mathbb{F}_t$-measurable for all $t\in T$.
    }

    \newdef{Progressively measurable}{\index{measurable!progressively}\index{progressive|see{measurable}}
        An $\mathcal{X}$-valued stochastic process $\tseq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is said to be progressively measurable (or simply \textbf{progressive}) if for all $t\in T$, the map $T_{\leq t}\times\Omega\rightarrow\mathcal{X}$ is measurable with respect to the product $\sigma$-algebra $\Sigma_{T_{\leq t}}\otimes\mathbb{F}_t$, where the first factor denotes a suitable $\sigma$-algebra on the index set.
    }

    \newdef{Predictable process}{\index{predictable}\label{stoch:predictable_process}
        First, consider $T=\mathbb{N}$. A discrete-time stochastic process $\seq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is said to be predictable if $X_{n+1}$ is $\mathbb{F}_n$-measurable for all $n\in\mathbb{N}$.

        More generally, for arbitrary $T$, consider the \textbf{predictable $\sigma$-algebra}, i.e.~the $\sigma$-algebra on $T\times\Omega$ generated by all (left-)continuous, adaptive processes. A process $\tseq{X}$ is said to be predictable if it is measurable with respect to the predictable $\sigma$-algebra. 
    }
    \begin{example}[Elementary predictable process]\label{stoch:elementary_process}
        \begin{gather}
            X_t = f_0\mathbbm{1}_{\{0\}}(t) + \sum_{i=1}^nf_i\mathbbm{1}_{]\tau_{i-1},\tau_i]}(t)
        \end{gather}
        for a finite sequence of bounded stopping times $\{\tau_i\}_{i\leq n}$ and bounded $\mathbb{F}_{\tau_i}$-measurable functions $f_i$ (with $\tau_0 = 0$).
    \end{example}
    \begin{property}
        The predictable $\sigma$-algebra is generated by the elemntary predictable processes.
    \end{property}

    \newdef{Increasing}{\index{increasing}\index{integrable}
        An adapted process $\tseq{X}$, where $T$ is linearly ordered and has a minimal element $0$, is called increasing if:
        \begin{enumerate}
            \item $X_0=0$ a.s.
            \item $t\mapsto X_t(\omega)$ is almost surely right-continuous and increasing.
        \end{enumerate}
        Often, integrability of all $X_t$ is also required. If $\lim_tX_t$ is integrable, the increasing process itself is called \textbf{integrable}.
    }
    \begin{property}[Naturality]\index{natural}
        An increasing process $\rseq{A}$ is predictable if and only if it is \textbf{natural}, i.e.~when
        \begin{gather}
            \expect{\Intt{0}{t}X_s\,dA_s} = \expect{\Intt{0}{t}X_{s^-}\,dAs}
        \end{gather}
        for all $t\in T$ and every bounded, right-continuous martingale $\rseq{X}$.
    \end{property}

    \begin{property}[Measurability hierarchy]
        The following hierarchy shows how the different notions of measurability of stochastic processes are related (from strong to weak):
        \begin{enumerate}
            \item Continuous and adapted,
            \item predictable,
            \item \textit{optional},
            \item progressively measurable, and
            \item adapted (and jointly measurable).
        \end{enumerate}
    \end{property}

    \newdef{Stopping time}{\index{stopping time}
        Consider a random variable $\tau$ on filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ where the codomain of $\tau$ coincides with the index set of $\mathbb{F}$. This variable is called a stopping time for $\mathbb{F}$ if
        \begin{gather}
            \{\tau\leq t\}\in\mathbb{F}_t
        \end{gather}
        for all $t\in T$. The stopping time is a `time indicator' that only depends on the knowledge of the process up to time $t\in T$.
    }
    \newdef{Stopped process}{
        Consider a stochastic process $\tseq{X}$ and a stopping time $\tau$. The stopped process $\tseq{X^\tau}$ is defined as follows:
        \begin{gather}
            X^\tau_t := X_{t\land\tau}\,.
        \end{gather}
    }

    The notions of convergence from \cref{section:probability_distributions} can be generalized to stochastic processes in different ways. The following is the most common one.
    \newdef{UCP convergence}{\index{convergence!ucp}
        A sequence of jointly measurable stochastic processes $(X_{t,n})_{t\in T,n\in\mathbb{N}}$ is said to convergence \textbf{uniformly on compacta} (ucp) to a stochastic process $\tseq{X}$ if
        \begin{gather}
            \Prob\left(\sup_{s\leq t}|X_{s,n}-X_s|>K\right)\longrightarrow0
        \end{gather}
        when $n\longrightarrow+\infty$ for all $t\in T$ and $K>0$.
    }

\section{Brownian motion}\index{Brownian motion}

    \newdef{L\'evy process}{\index{L\'evy!process}
        A stochastic process $\rseq{X}$ satisfying:
        \begin{enumerate}
            \item\textbf{Initial condition}: $X_0=0$ a.s.
            \item\textbf{Independent increments}: For all $t_1\leq\cdots\leq t_n$, $\{X_{t_2}-X_{t_1},\ldots,X_{t_n}-X_{t_{n-1}}\}$ are independent.
            \item\textbf{Stationary increments}: For all $s\leq t$, $X_t-X_s\overset{d}{=}X_{t-s}$.
            \item\textbf{Continuity in probability}: $\rseq{X}$ is almost surely \cdlgg. 
        \end{enumerate}
    }

    A famous example of a L\'evy process is Brownian motion.
    \newdef{Brownian motion}{
        A continuous-time stochastic process $\tseq{W}$ satisfying:
        \begin{enumerate}
            \item $W_0$ is almost surely 0.
            \item $W$ has independent Gaussian increments.
            \item $W$ is almost surely continuous.
        \end{enumerate}
    }

    \begin{remark}\index{Wiener process}
        A Brownian motion is also called a \textbf{Wiener process} (especially in the mathematics literature).
    \end{remark}

    \newdef{Geometric Brownian motion}{
        \begin{gather}
            M_t := \exp\left(W_t - \frac{t}{2}\right)\,,
        \end{gather}
        where $\rseq{W}$ is a standard Brownian motion.
    }

\section{Martingales}

    From here on, the index set $T$ will be $\mathbb{N}$ or $\mathbb{R}^+\equiv[0,+\infty[$, so that the index $t$ can be interpreted as a time parameter. The explicit choice will be made clear if necessary.

\subsection{Proper martingales}

    \newdef{Martingale}{\index{martingale}\label{prob:martingale}
        A stochastic process $\tseq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is called a martingale (relative to $\mathbb{F}$) if it satisfies the following conditions:
        \begin{enumerate}
            \item $\tseq{X}$ is adapted to $\mathbb{F}$.
            \item Each random variable $X_t$ is integrable, i.e.~$X_t\in L^1(P)$ for all $t\in T0$.
            \item For all $t>s\geq0:\expect{X_{t}\,\middle\vert\,\mathbb{F}_s}=X_s$.
        \end{enumerate}
        If the equality in the last condition is replaced by the inequality $\leq$ (resp.~$\geq$), the stochastic process is called a \textbf{supermartingale} (resp.~\textbf{submartingale}).
    }
    \begin{example}[Doob martingale]\index{Doob!martingale}
        Consider an integrable random variable $X$ and a filtration $\mathbb{F}$. The associated Doob martingale (with respect to $\mathbb{F}$) is given by
        \begin{gather}
            Y_t := \expect{X\,\middle\vert\,\mathbb{F}_t}\,.
        \end{gather}
    \end{example}

    \begin{remark}
        It can be shown that almost surely right-continuous submartingales (and supermartingales) with respect to a filtration that satisfies the usual conditions, always admit a \cdlg modification. From here one, all submartingales will assumed to be \cdlg unless mentioned otherwise.
    \end{remark}

    \begin{theorem}[Optional stopping]\index{optional stopping}
        Let $\tseq{X}$ be a martingale. If $\tau$ is a stopping time satisfying either of the following conditions:
        \begin{enumerate}
            \item $\tau$ is almost surely bounded, or
            \item the stopped process $\tseq{X^\tau}$ is almost surely bounded,
        \end{enumerate}
        then the stopped process $\tseq{X^\tau}$ is again a martingale.
    \end{theorem}

    \begin{property}[Doob--Ville inequality]\index{Doob--Ville!inequality}\index{Ville|seealso{Doob}}\label{prob:doob_inequality}
        Consider a \cdlg submartingale $\tseq{X}$.
        \begin{gather}
            \Prob\left(\sup_{t\leq\tau}X_t\geq C\right)\leq\frac{\expect{\max(0,X_\tau)}}{C}
        \end{gather}
        for all $C\geq1$ and $\tau\in T$.
    \end{property}

    The following property generalizes the Hoeffding inequalities~\cref{prob:hoeffding_inequality}.
    \begin{property}[Hoeffding--Azuma inequality]\index{Hoeffding--Azuma inequality}\index{McDiarmid inequality}\label{prob:hoeffding_azuma}
        Let $\seq{X}$ be a (super)martingale with bounded differences, i.e.~there exist constants $c_k>0$ such that
        \begin{gather}
            |X_k-X_{k-1}|\leq c_k\,.
        \end{gather}
        The following inequality holds for all $\lambda\geq0$:
        \begin{gather}
            \Prob(X_N-X_0\geq\lambda)\leq\exp\left(-\frac{\lambda^2}{2\sum_{i=1}^Nc_i^2}\right)\,.
        \end{gather}
        A symmetric result for the lower tail holds for (sub)martingales. Moreover, if there exist predictable processes $\seq{A},\seq{B}$ such that
        \begin{gather}
            A_k\leq X_k-X_{k-1}\leq B_k
        \end{gather}
        and
        \begin{gather}
            B_k-A_k\leq c_k
        \end{gather}
        for all $k\in\mathbb{N}$, the inequality can be sharpened:
        \begin{gather}
            \Prob(X_N-X_0\geq\lambda)\leq\exp\left(-\frac{2\lambda^2}{\sum_{i=1}^Nc_i^2}\right)\,.
        \end{gather}
        Now, consider a function $f:\Omega^n\rightarrow\mathbb{R}$ such that
        \begin{gather}
            \sup_{x_1,\ldots,x_n,x'_k}|f(x_1,\ldots,x_k,\ldots,x_n)-f(x_1,\ldots,x'_k,\ldots,x_n)|\leq c_k
        \end{gather}
        for all $k\in\mathbb{N}$. By applying the above inequalities to the Doob martingale
        \begin{gather}
            Z_m:=\expect{f(X_1,\ldots,X_n)\mid X_1,\ldots,X_m}\,,
        \end{gather}
        one obtains the following inequality:
        \begin{gather}
            \Prob\bigl(f(X_1,\ldots,X_n)-\expect{f}\geq\lambda\bigr)\leq\exp\left(-\frac{2\lambda^2}{\sum_{i=1}^nc_i^2}\right)\,.
        \end{gather}
        This inequality is sometimes called the \textbf{McDiarmid inequality}.
    \end{property}

    \begin{theorem}[Doob decomposition]\index{Doob!decomposition}
        Any integrable adapted process $\seq{X}$ can be decomposed (almost surely uniquely) as $X_n=X_0+M_n+A_n$, where $\seq{M}$ is a martingale and $\seq{A}$ is an integrable, predictable process. These two processes are constructed iteratively as follows:
        \begin{align}
            A_0 = 0\qquad&\qquad M_0 = 0\\
            \Delta A_n = \expect{\Delta X_n\mid\mathbb{F}_{n-1}}\qquad&\qquad\Delta M_n = \Delta X_n - \Delta A_n\,.
        \end{align}
        Furthermore, $\seq{X}$ is a submartingale if and only if $\seq{A}$ is (almost surely) increasing.\footnote{Replacing increasing by decreasing gives a similar statement for supermartingales.}
    \end{theorem}
    \newdef{Quadratic variation}{\index{variation!quadratic}
        Consider the special case $X_n=Y_n^2$ for some integrable martingale $\seq{Y}$. By Jensen's inquality~\ref{calculus:jensen_inequality}, $\seq{X}$ is an integrable submartingale. The process $\seq{A}$ in the Doob decomposition of $\seq{X}$ is often called the \textbf{quadratic variation process} of $\seq{Y}$ and is denoted by $\seq{[Y]}$.
    }

    The Doob decomposition has an analogue for $\mathbb{R}^+$-indexed processes.
    \begin{theorem}[Doob--Meyer]\index{Doob--Meyer}\index{DL}
        Consider the class $\mathcal{T}_{\!\!a}$ of stopping times which are almost surely bounded by $a\in\mathbb{R}$ and a right-continuous submartingale $\tseq{T}$ such that $\{X_\tau\}_{\tau\in\mathcal{T}_{\!\!a}}$ is uniformly integrable\footnote{Stochastic processes which satisfy this condition for some $a\in\mathbb{R}$ are said to be of \textbf{class DL}}. Then $\tseq{X}$ can be decomposed (almost surely uniquely) as $X_t = X_0 + M_t + A_t$, where $\tseq{M}$ is a right-continuous martingale and $\tseq{A}$ is increasing and natural.
    \end{theorem}
    \begin{remark}
        The DL condition can be replaced by requiring (almost sure) nonnegativity.
    \end{remark}

    As in the case of discrete-time martingales, the quadratic variation could be defined through the Doob--Meyer decomposition of $X^2$. However, an alternative definition goes as follows.
    \newadef{Quadratic variation}{\index{variation!quadratic}\label{stoch:quadratic_variation}
        Let $\tseq{X}$ be a martingale. For every stochastic partition $P=\{0=\tau_0\leq\tau_1\leq\cdots\nearrow+\infty\}$ of $\mathbb{R}$, i.e.~sequence of stopping times starting at zero and going to infinity, define the quadratic variation as
        \begin{gather}
            \langle X \rangle^P_t := \sum_{i=1}^{+\infty}(X_{t\land \tau_i}-X_{t\land\tau_{i-1}})^2\,.
        \end{gather}
        The quadratic variation $\langle X \rangle$ is obtained by taking the limit over all stochastic partitions as the mesh size
        \begin{gather}
            \label{stoch:quadratic_variation_formula}
            |P| := \max_{n\in\mathbb{N}}(t\land\tau_n - t\land\tau_{n-1})
        \end{gather}
        goes to zero in probability. (The limit converges in probability and even ucp.\footnote{For more general processes, the quadratic variation is well-defined exactly if this limit exists.}) Moreover, if $X$ is continuous and square-integrable, so is $\langle X \rangle$ and this construction coincides with that through the Doob--Meyer decomposition.
    }
    \begin{remark}[Quadratic covariation]\index{covariation}
        The formula for the quadratic variation can easily be modified to obtain the quadratic covariation:
        \begin{gather}
            \langle X,Y \rangle^P_t := \sum_{i=1}^{+\infty}(X_{t\land \tau_i}-X_{t\land\tau_{i-1}})(Y_{t\land \tau_i}-Y_{t\land\tau_{i-1}})\,.
        \end{gather}
    \end{remark}

\subsection{Local martingales}\index{martingale}

    \newdef{Local martingale}{
        Consider a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$. A stochastic process $\tseq{X}$ is called a local martingale (relative to $\mathbb{F}$) if there exists stopping times $\seq{\tau}$ (with respect to $\mathbb{F}$) satisfying the following conditions:
        \begin{enumerate}
            \item $\seq{\tau}$ is almost surely increasing.
            \item $\seq{\tau}$ is almost surely divergent.
            \item The stopped process $\{X^{\tau_k}\}_{t\in T}$ is a martingale (relative to $\mathbb{F}$) for all $k\in\mathbb{N}$.
        \end{enumerate}
    }

    This idea can be generalized to any kind of property of stochastic processes.
    \newdef{Localization}{\index{localization}
        Consider a class $\mathcal{P}$ of stochastic processes. A stochastic process $\tseq{X}$ is said to be locally in $\mathcal{P}$ if there exists a sequence $\seq{\tau}$ of stopping times, with $\tau_n\nearrow+\infty$ almost surely, such that the stopped process $\tseq{X^{\tau_n}}$ is in $\mathcal{P}$ for all $n\in\mathbb{N}$.

        Localization can be shown to be commutative with respect to intersections and, if $\mathcal{P}$ is a vector space, to be idempotent.
    }

    \newdef{Local integrability}{\index{integrable!locally}
        A stochastic process is said to be locally integrable if its maximum process $X_t^*:=\sup_{s\leq t}X_s$ is locally in the class of integrable stochastic processes.
    }
    \begin{property}
        A \cdlgg, adapted stochastic process is of class D(L) if and only if it is locally integrable
    \end{property}
    \begin{property}
        Every local martingale is locally integrable and a local martingale is a martingale if and only if it is of class DL. (Note that, by the preceeding property, this happens exactly when the local martingale is \cdlg and adapted.)
    \end{property}

    \begin{property}[Convergence]
        The limit of a sequence of continuous local martingales that converges ucp is itself a  continuous local martingale.
    \end{property}

    \begin{property}[Covariation]
        If $\tseq{X},\tseq{Y}$ are local martingales, then $\tseq{\langle X,Y \rangle}$ is the unique FV process that starts at 0 and such that
        \begin{enumerate}
            \item $(X_tY_t - \langle X,Y \rangle_t)_{t\in T}$ is a local martingale, and
            \item $\Delta\langle X,Y\rangle = \Delta X\Delta Y$.
        \end{enumerate}
    \end{property}

    \begin{property}[Square-integrability]
        A local martingale $\rseq{X}$ is an $L^2$-martingale if and only if $\expect{X_0^2}<+\infty$ and $\langle X \rangle$ is integrable. More generally, a local martingale is a martingale if it is dominated by an integrable random variable.
    \end{property}

    Although (local) martingales are often the most interesting objects in practice, they can be generalized in a Doob-like manner. Moreover, these generalized martingales are of major importance for the stochastic calculus to be introduced in the next section.
    \newdef{Semimartingale}{\label{stoch:semimartingale}
        A real-valued stochastic process that can be decomposed as the sum of a local martingale and a \cdlgg, adapted process of locally bounded variation\footnote{This means that the sample paths are almost surely of locally bounded variation.}.
    }
    \begin{remark}
        The \cdlgg, adapted processes of locally bounded variation are also called \textbf{FV processes}.
    \end{remark}

    \begin{property}
        If $\tseq{X}$ is a semimartingale, then $\tseq{\langle X \rangle}$ is \cdlgg, adapted and increasing. Moreover, if $\tseq{Y}$ is also a semimartingale, then $\tseq{\langle X,Y \rangle}$ is an FV process.
    \end{property}

    \newdef{\'Emery topology}{\index{topology!\'Emery}\label{stoch:emery_topology}
        The space of semimartingales on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ admits a natural topology (\cref{chapter:topology}). Consider the following metric (\cref{chapter:metric}):
        \begin{gather}
            d_{\text{sm}}(S,T) := \sup_{H\in\mathcal{E},\|H\|_\infty\leq 1}\expect{\sup_{t\in\mathbb{R}^+}|H\cdot(S-T)_t|\land 1}\,,
        \end{gather}
        where $\mathcal{E}$ denotes the set of elementary predictable process on $(\Omega,\Sigma,\mathbb{F},P)$. This metric turn $\Omega$ into a complete metric space (\cref{metric:complete_space}).
    }

\section{It\^o calculus}\label{section:stochastic_integral}

    Two approaches exist to extending integration theory to stochastic processes. One is through the It\^o isometry (see \cref{stoch:ito_isometry} below) and the other is through a more axiomatic approach like for the ordinary Lebesgue integral. Both approaches will be explored in this section, with the latter coming first. For simplicity (and unless stated otherwise), all filtered probability spaces will be assumed to satisfy the usual conditions and all martingales will be assumed to be \cdlgg.

\subsection{Stochastic integral}

    Recall \cref{stoch:elementary_process} for the definition of elementary predictable process. The \textbf{stochastic integral} of such a process $\rseq{P}$ with respect to another stochastic process $\rseq{X}$ is defined as follows:\index{integral!stochastic}\index{stochastic|seealso{integral}}
    \begin{gather}
        \label{stoch:elementary_integral}
        \Intt{0}{t}P\,dX := \sum_{i=1}^nf_i(X_{t\land\tau_i} - X_{t\land\tau_{i-1}})\,.
    \end{gather}

    \begin{example}[Discrete stochastic integral\footnotemark]\index{martingale!transform|see{integral, stochastic}}
    \footnotetext{Sometimes called the \textbf{martingale transform}.}
        Let $\seq{M}$ be a discrete-time martingale and let $\seq{X}$ be a predictable stochastic process. The (discrete) stochastic integral of $X$ with respect to $M$ is defined as follows:
        \begin{gather}
            X\cdot M_n := \sum_{i=1}^nX_i\,\Delta M_i\,.
        \end{gather}
        For $n=0$, the convention $X\cdot M_0=0$ is used. If $\seq{X}$ is bounded, the stochastic integral defines a martingale.
    \end{example}

    \begin{property}
        An integrable, adapted stochastic process $\rseq{X}$ is a martingale if and only if
        \begin{gather}
            \expect{\int_0^{+\infty}P\,dX}=0
        \end{gather}
        for all elementary predictable processes $\rseq{P}$. If this only holds after replacing $=$ by $\geq$, then $\rseq{X}$ is a submartingale.
    \end{property}

    \begin{property}
        If $\rseq{X}$ is a martingale and $\rseq{P}$ a bounded elementary predictable process, then $\Intt{0}{t}P\,dX$ is also a martingale.
    \end{property}

    Since, the elementary predictable processes are dense in the space of all predictable processes, bounded convergence (in probability) would allow to extend the stochastic integral to all (bounded) predictable processes.
    \newdef{Stochastic integral}{\index{integral!stochastic}\index{convergence!bounded}
        An $L^0$-valued functional
        \begin{gather}
            P\mapsto\Intt{0}{t}P\,dX
        \end{gather}
        on the space of bounded predictable processes such that
        \begin{enumerate}
            \item it coincides with \cref{stoch:elementary_integral} for elementary predictable processes, and
            \item it satisfies bounded convergence in probability, i.e.~if $(P_{t,n})_{t\in T,n\in\mathbb{N}}$ is a uniformly bounded sequence of elementary predictable processes that converges pointwise to a stochastic process $\rseq{P}$, then
            \begin{gather}
                \Intt{0}{t} P_n\,dX\longrightarrow\Intt{0}{t}P\,dX
            \end{gather}
            in probability.
        \end{enumerate}
    }

    The following property states necessary conditions on the \textbf{integrator} $\rseq{X}$ for all integrals to exist. This property (uniquely) defines the stochastic integral through a procedure from the integration theory of \textit{Daniell}.\index{integral!Daniell}
    \begin{property}\index{integrator}
        If adapted stochastic process $\rseq{X}$ is a well-behaved integrator, i.e.~the stochastic integral with respect to $\rseq{X}$ exists, then:
        \begin{enumerate}
            \item $\rseq{X}$ is right-continuous in probability\footnote{For this notion of continuity, replace the convergence in \cref{topology:sequential_continuity} with convergence in probability.}.
            \item The set
            \begin{gather}
                \label{stoch:bounded_elementary_set}
                \left\{\Intt{0}{t}P\,dX\,\middle\vert\, P\text{ is elementary predictable}\land|P|\leq1\right\}
            \end{gather}
            is bounded in probability for all $t\in T$.
        \end{enumerate}
    \end{property}
    The first item can actually be strengthened, since good integrators always admit a \cdlg modification. As such, all integrators will be assumed to be \cdlg from here on. It can also be shown that these necessary conditions are also necessary. The following theorem says that these integrators coincide with a previously defined object.

    \begin{theorem}[Bichteler--Dellacherie]\index{Bichteler--Dellacherie}
        The semimartingales are exactly the well-behaved integrators for the stochastic integral.
    \end{theorem}

    Boundedness is, of course, a rather strong property and it would be better to have a more general class of integrands. To this end, bounded convergence should be weakened to dominated convergence (cf.~\cref{measure:dominated_convergence_theorem}).
    \newdef{Integrability}{\index{integrable}
        Let $\rseq{X}$ be a semimartingale. The space $L^1(X)$ of $X$-integrable stochastic processes consists of those predictable processes $\rseq{Y}$ such that if $(P_{t,n})_{t\in T,n\in\mathbb{N}}$ is a sequence of bounded predictable processes converging to 0 with $|P_t|\leq|Y_t|$ for all $t\in T$, then
        \begin{gather}
            \Intt{0}{t}P_n\,dX\longrightarrow0
        \end{gather}
        in probability for all $t\in T$.
    }
    \begin{remark}
        An equivalent definition uses an approach that is similar to the definition of well-behaved integrators. $L^1(X)$ consists exactly of those predictable stochastic processes $\rseq{Y}$ for which the set in \cref{stoch:bounded_elementary_set}, where $\rseq{P}$ is replaced by a bounded and $Y$-dominated process, is bounded in probability for all $t\in T$.
    \end{remark}

    \begin{notation}[Differential]\index{differential}
        A very common notation in stochastic calculus is the differential notation (also common in applied sciences). An equation of the form
        \begin{gather}
            \dr Y = \alpha\,\dr X
        \end{gather}
        means that
        \begin{gather}
            Y_t = Y_0 + \alpha\cdot X_t
        \end{gather}
        for some constant $Y_0\in\mathbb{R}$. For the quadratic (co)variation, a potentially more confusing notation is sometimes used:
        \begin{gather}
            \begin{aligned}
                \dr X^2 &:= \dr\langle X \rangle\,,\\
                \dr X\dr Y &:= \dr\langle X,Y \rangle\,.
            \end{aligned}
        \end{gather}
    \end{notation}

    \newdef{It\^o process}{\index{It\^o!process}\index{SDE}\index{differential equation!stochastic}\label{stoch:ito_process}
        A stochastic process $\rseq{X}$ satisfying the following stochastic differential equation (SDE):
        \begin{gather}
            \dr X = \mu\dr t + \sigma\dr W\,,
        \end{gather}
        where $\rseq{\sigma},\rseq{\mu}$ are adapted. Such processes are actually semimartingales.
    }

    \newdef{$\sigma$-martingale}{\index{martingale!$\sigma$-}
        An adapted stochastic process $\rseq{X}$ such that
        \begin{gather}
            X_t = H\cdot Y_t
        \end{gather}
        for some predictable stochastic process $\rseq{H}$ and martingale $\rseq{Y}$.
    }
    \begin{property}
        All (local) martingales are also $\sigma$-martingales.
    \end{property}

    \newdef{Admissible process}{\index{admissible}\label{stoch:admissible_process}
        Let $\rseq{S}$ be a semimartingale. A predictable stochastic process $\rseq{P}$ is said to be ($\lambda$-)admissible, where $\lambda\in\mathbb{R}^+$, with respect to $\rseq{S}$ if $P\cdot S_t\geq -\lambda$ for all $t\in\mathbb{R}^+$.
    }

    \newdef{Dol\'eans-Dade exponential}{\index{exponential!Dol\'eans-Dade}\label{stoch:stochastic_exponential}
        The \textbf{stochastic exponential} of a semimartingale $\rseq{X}$ is the unique (strong) solution of the stochastic differential equation
        \begin{gather}
            \dr Y_t = Y_{t^-}\,\dr X_t
        \end{gather}
        with initial value condition $Y_0=1$.

        If $\rseq{X}$ is a.s.~continuous, the stochastic exponential is given by
        \begin{gather}
            \label{stoch:continuous_stochastic_exponential}
            \mathcal{E}(X)_t = \exp\left(X_t - X_0 - \frac{1}{2}\langle X \rangle_t\right)\,.
        \end{gather}
        More generally, when continuity is not assumed, it is given by
        \begin{gather}
            \mathcal{E}(X)_t = \exp\left(X_t - X_0 - \frac{1}{2}\langle X \rangle_t^c\right)\prod_{s\leq t}(1+\Delta X_s)\exp(-\Delta X_s)\,,
        \end{gather}
        where $\langle\cdot\rangle^c$ denotes the continuous part of the quadratic variation.
    }
    \begin{property}[Stochastic logarithm]\label{stoch:stochastic_logarithm}\index{logarithm}
        The stochastic exponential and its left-continuous version of a semimartingale $\rseq{X}$ are strictly positive if and only if the jumps of $\rseq{X}$ are strictly greater than -1.

        In such cases, the exponential can be inverted to obtain the \textbf{stochastic logarithm}. This is given by
        \begin{gather}
            \mathcal{L}(Y)_t = \frac{1}{Y_-}\cdot Y_t\,.
        \end{gather}
    \end{property}

\subsection{Properties}

    Note that $L^0$ is the set of equivalence classes of random variables that are almost surely equal. The consequence is that the stochastic process given by
    \begin{gather}
        Y\cdot X_t := \Intt{0}{t}Y\,dX
    \end{gather}
    has sample paths that are not necessarily well-defined. However, they admit well-behaved modifications.
    \begin{property}[Change of variables]
        Let $\rseq{X}$ be a semimartingale and consider a stochastic process $\rseq{Y}\in L^1(X)$. $Z_t := Y\cdot X_t$ is an adapted stochastic process admitting a \cdlg modification and, moreover, is a semimartingale such that
        \begin{gather}
            \Intt{0}{t}P\,dZ = \Intt{0}{t}PY\,dX
        \end{gather}
        for all $t\in T$ and bounded, predictable processes $\rseq{P}$. Any \cdlgg, adapted process satisfying this property will be called `the' stochastic integral of $\rseq{Y}$ with respect to $\rseq{X}$.

        Moreover, a predictable process $\rseq{Q}$ is $Z$-integrable if and only if
        \begin{gather}
            \Intt{0}{t}Q\,dZ = \Intt{0}{t}QY\,dX\,.
        \end{gather}
    \end{property}

    \begin{property}[Optional stopping]
        Consider a semimartingale $\rseq{X}$ and a stopping time $\tau$. If $\rseq{P}$ is an $X$-integrable process, it is also $X^\tau$-integrable and
        \begin{gather}
            \left(P\cdot X\right)^\tau = P\cdot X^\tau\,.
        \end{gather}
    \end{property}

    \begin{property}
        A predictable process is $X$-integrable for some semimartingale $\rseq{X}$ if and only if it is locally $X$-integrable. Moreover, a stochastic process is a semimartingale if and only if it is a semimartingale.

        This property also implies that all locally bounded predictable processes are integrable with respect to any semimartingale. In fact, for every \cdlgg, adapted stochastic process $\rseq{Y}$, the left-limit process $(Y_{t^-})_{t\in T}$ is integrable with respect to any semimartingale.
    \end{property}

    \begin{theorem}[Dominated convergence]\index{convergence!dominated}
        Let $(P_{t,n})_{t\in T,n\in\mathbb{N}}$ be a convergent sequence of predictable stochastic process with limit $\rseq{P}$ and let $\rseq{X}$ be a semimartingale. If the sequence is dominated by an $X$-integrable stochastic process, then
        \begin{gather}
            \Intt{0}{t}P_n\,dX\overset{\text{ucp}}{\longrightarrow}\Intt{0}{t}P\,dX
        \end{gather}
        for all $t\in T$.
    \end{theorem}

    \begin{property}[Linearity]
        The set of semimartingales is a (real) vector space and, moreover, the stochastic integral is linear with respect to this structure.
    \end{property}

    The following formula should be compared to \cref{measure:integration_by_parts} for Lebesgue--Stieltjes integrals (a further relation is also given in the next section).
    \begin{formula}[Integration by parts]\index{integration!by parts}
        Let $\rseq{X},\rseq{Y}$ be semimartingales.
        \begin{gather}
            X_tY_t = X_0Y_0 + \Intt{0}{t}X_{s^-}\,dY_s + \Intt{0}{t}Y_{s^-}\,dX_s + \langle X,Y \rangle_t
        \end{gather}
        In differential notation, this becomes:
        \begin{gather}
            \dr(XY) = X_-\dr Y + Y_-\dr X + \dr X\dr Y\,.
        \end{gather}
        Note that this formula could be used as an alternative definition of the quadratic variation process.
    \end{formula}

    \begin{formula}[Jump process]
        If $\rseq{X}$ is a semimartingale and $\rseq{P}\in L^1(X)$, then
        \begin{gather}
            \dr Y = P\,\dr X\implies \Delta Y = P\Delta X\,.
        \end{gather}
        Moreover, the continuity (resp.~predictability) of $\rseq{X}$ implies the continuity (resp.~predictability) of $\rseq{Y}$. Moreover,
        \begin{gather}
            \Delta\langle X,Y \rangle = \Delta X\Delta Y\,.
        \end{gather}
    \end{formula}
    \begin{result}
        If $\rseq{X}$ is a semimartingale, then
        \begin{gather}
            \sum_{s\leq t}\Delta X_s^2\leq\langle X \rangle_t<+\infty\,.
        \end{gather}
    \end{result}

    The following inequality should be compared to the Cauchy--Schwarz inequality (\cref{measure:schwarz_inequality}).
    \begin{formula}[Kunita--Watanabe inequality]\index{Kunita--Watanabe inequality}
        Let $\rseq{X},\rseq{Y}$ be semimartingales and consider two stochastic processes $\rseq{\alpha},\rseq{\beta}$.
        \begin{gather}
            \Intt{0}{t}|\alpha_s\beta_s|\,|d\langle X,Y \rangle_s| \leq \sqrt{\Intt{0}{t}\alpha_s^2\,d\langle X \rangle_s\Intt{0}{t}\beta_s^2\,d\langle Y \rangle_s}\,,
        \end{gather}
        where $|d\langle X,Y \rangle_s|$ denotes the total variation measure (\cref{measure:total_variation}) and all integrals are Lebesgue--Stieltjes integrals.
    \end{formula}

    \begin{result}[Brownian motion]
        Let $\rseq{W},\rseq{\overline{W}}$ be standard Brownian motions. The Kunita--Watanabe inequality implies that
        \begin{gather}
            \Intt{0}{t}\alpha_s^2|d\langle W,\overline{W}| \rangle_s \leq \Intt{0}{t}\alpha_s^2\,ds\,.
        \end{gather}
        By the Radon--Nikodym theorem~\ref{measure:radon_nikodym}, there exists a predictable process $\rseq{\rho}$, bounded by 1, such that
        \begin{gather}
            \dr W\dr\overline{W} = \rho\dr t\,.
        \end{gather}
        $\rseq{\rho}$ is called the \textbf{instantaneous correlation} of the Brownian motions.
    \end{result}

    \begin{formula}[It\^o lemma]\index{It\^o!lemma}
        Consider an It\^o process $\rseq{X}$:
        \begin{gather}
            \dr X = \mu\dr t + \sigma\dr W\,.
        \end{gather}
        For $f\in C^2(\mathbb{R}^2,\mathbb{R})$, one has
        \begin{gather}
            \dr f(t,X) = \left(\pderiv{f}{t}+\mu\pderiv{f}{x}+\mpderiv{2}{f}{x}\right)\dr t + \sigma\pderiv{f}{x}\dr W\,.
        \end{gather}
        This also implies that $f(t,X)$ is again an It\^o process.
        
        More generally, consider a $d$-dimensional continuous semimartingale $\rseq{X}$ with a differentiable function $g\in C^2(\mathbb{R}^d,\mathbb{R})$.
        \begin{gather}
            \dr f(X) = \pderiv{f}{x^i}(X)\dr X^i + \frac{1}{2}\frac{\partial^2f}{\partial x^i\partial x^j}g(X)\dr\langle X^i,X^j \rangle\,.
        \end{gather}
        If $\rseq{X}$ is not continuous, a correction has to be applied:
        \begin{gather}
            \dr f(X) = \pderiv{f}{x^i}(X_-)\,\dr X^i + \frac{1}{2}\frac{\partial^2f}{\partial x^i\partial x^j}g(X)\,\dr\langle X^i,X^j \rangle^c + \left(\Delta f(X) - \pderiv{f}{x^i}(X_-)\Delta X^i\right)\,.
        \end{gather}
    \end{formula}

    \begin{property}[It\^o isometry]\index{It\^o!isometry}\label{stoch:ito_isometry}
        Consider a local martingale $\rseq{M}$ and a predictable process $\rseq{P}$ such that $\expect{\int_0^{+\infty}P^2\,d\langle X \rangle}<+\infty$. Then $P\in L^1(P)$ and 
        \begin{gather}
            \expect{\left(P\cdot M\right)^2} = \expect{\int_0^{+\infty}P^2\,d\langle M \rangle}\,.
        \end{gather}
    \end{property}

    \begin{property}[Ansel--Stricker]\index{Ansel--Stricker}
        Let $rseq{M}$ be a local martingale and consider $P\in L^1(M)$. If $\rseq{P\cdot M}$ is uniformlly bounded from below by an integrable random variable, then $\rseq{P\cdot M}$ is a local martingale and even a supermartingale.
    \end{property}

\subsection{Lebesgue--Stieltjes integration}\index{integral!Lebesgue--Stieltjes}

    \begin{property}
        Let $\rseq{X}$ be a continuous stochastic process. If for each $t>0$, the $p$-variation\footnote{The stochastic process obtained by replacing the square in \cref{stoch:quadratic_variation_formula} by the power $p>0$.} converges in probability to a random variable taking values in $\mathbb{R}^+$ almost surely, then the $q$-variations for all $q<p$ vanish in probability, and the $q$-variations for all $q>p$ diverge in probability (on the event where the quadratic variation is nonzero).
    \end{property}
    By \cref{stoch:quadratic_variation}, the continuous, square-integrable martingales have a well-defined quadratic variation process. Then, by the property above, this means that their first variation diverges almost surely and that their higher variations are almost surely zero. This shows that it is impossible to obtain a well-defined integration theory with (square-integrable) martingales as integrators. However, instead of looking at the martingales themselves, one can look at their quadratic variation process. These are continuous and increasing and, hence, are equal to their own first variation process. This allows us to define the Lebesgue--Stieltjes integral
    \begin{gather}
        I(\omega) = \Intt{0}{t} Y_s(\omega)\,d\langle X \rangle_s(\omega)
    \end{gather}
    along sample paths. The following property shows that in good cases, the stochastic integral and pathwise Lebesgue--Stieltjes integral coincide.
    \begin{property}
        Let $\rseq{X}$ be a semimartingale and a predictable stochastic process $\rseq{P}$. If
        \begin{gather}
            \Intt{0}{t}|P_s|\,|dX_s| < +\infty
        \end{gather}
        almost surely for all $t\in T$, where $|dX_s|$ denotes the total variation measure (\cref{measure:total_variation}), then $\rseq{P}\in L^1(X)$ and
        \begin{gather}
            \Intt{0}{t}P_s\,dX_s = P\cdot X_t
        \end{gather}
        for all $t\in T$.
    \end{property}

    \begin{formula}
        Let $\rseq{X}$ be a semimartingale and let $\rseq{V}$ be an FV process.
        \begin{gather}
            \langle X,V \rangle_t = \Intt{0}{t}\Delta X\,dV = \sum_{s\leq t}\Delta X_s\Delta V_s\,,
        \end{gather}
        where the integral with respect to $V$ is a Lebesgue--Stieltjes integral. In particular, if either process is continuous, their quadratic covariation vanishes. This property is the reason why quadratic variations are a rare sight in ordinary calculus.
    \end{formula}
    \begin{result}
        Let $\rseq{X}$ be a semimartingale and let $\rseq{V}$ be an FV process.
        \begin{gather}
            X_tV_t = X_0V_0 + \Intt{0}{t}X_s\,dV_s + \Intt{0}{t}V_{s^-}\,dX_s\,,
        \end{gather}
        where the integral with respect to $V$ is again a Lebesgue--Stieltjes integral.
    \end{result}

    \begin{theorem}[Girsanov]\index{Girsanov}\label{measure:girsanov}
        Consider a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ and an adapted process $\rseq{X}$. Moreover, let $\rseq{W}$ be a Brownian motion. If
        \begin{gather}
            Z_t := \exp\left(-\Intt{0}{t}X_s\,dW_s - \frac{1}{2}\Intt{0}{t}|W_s|^2\,ds\right)
        \end{gather}
        is a martingale (relative to $\mathbb{F}$), then
        \begin{gather}
            \widetilde{X}_t := X_t + \Intt{0}{t}W_s\,ds
        \end{gather}
        is a Brownian motion with respect to the transformed measure $Z_t\,dP$.
    \end{theorem}

    @@ COMPLETE SECTION

\section{Markov processes}

    \newdef{Markov process}{\index{Markov!process}
        A Markov process (or chain) is a stochastic process $\tseq{X}$ adapted to a filtration $\tseq{\mathbb{F}}$ such that
        \begin{gather}
            \Prob(X_t\mid\mathbb{F}_s) = \Prob(X_t\mid X_s)
        \end{gather}
        for all $t,s\in T$. For discrete-time processes, the first-order Markov chains are the most common. These satisfy
        \begin{gather}
            \Prob(X_t\mid X_{t-1},\ldots,X_{t-r}) = \Prob(X_t\mid X_{t-1})
        \end{gather}
        for all $t,r\in\mathbb{N}$.
    }
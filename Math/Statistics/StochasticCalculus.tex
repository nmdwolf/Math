\chapter{Stochastic Calculus}\label{chapter:stochastic_calculus}

    References for this chapter are~\citet{jeanblanc_mathematical_2009,karatzas_brownian_1991,salez_introduction_2024,elliott_mathematics_2005}. The section on abstract Wiener spaces is mainly based on~\citet{hairer_introduction_2023,dudley_seminorms_1971,berger_infinitesimal_2002,stroock_abstract_2008}.

    \minitoc

\section{Stochastic processes}

    \newdef{Stochastic process}{\index{stochastic!process}
        A sequence of random variables $\tseq{X}$ for some index set $T$. In practice, $T$ will often be a totally ordered set, e.g.~$(\mathbb{R},\leq)$ in the case of a continuous time series.
    }
    \newdef{Jump}{\index{jump}
        The jump of a stochastic process $\tseq{X}$ at $t\in T$ is defined as
        \begin{gather}
            \Delta X_t := X_t - X_{t^-}\,,
        \end{gather}
        where $X_{t^-} := \lim_{s<t}X_s$.
    }

    \newdef{Equivalence}{\index{modification}\index{version}\index{evanescence}
        Stochastic process can be be considered equivalent in different ways. The two most common cases are considered here:
        \begin{itemize}
            \item Two stochastic processes $\tseq{X}$ and $\tseq{Y}$ are said to be \textbf{stochastically equivalent} if $X_t=Y_t$ a.s.~for all $t\in T$. Such processes are also called \textbf{modifications} or \textbf{versions}.
            \item Two stochastic processes $\tseq{X}$ and $\tseq{Y}$ are said to be \textbf{indistinguishable} or \textbf{equivalent up to evanescence} if $X_t=Y_t$ for all $t\in T$ almost surely. Equivalently, they are indistinguishable if their sample paths coincide almost surely.
        \end{itemize}
    }

    \newdef{Continuity}{\index{continuity}\index{sample}\index{path}
        A stochastic process $\tseq{X}$ on a measurable space $(\Omega,\Sigma)$, where $T$ is a topological space (\cref{topology:topology}), is said to be \textbf{(sample path) continuous} if the functions $t\mapsto X_t(\omega)$ are continuous for almost all $\omega\in\Omega$.
    }
    \begin{property}
        All continuous stochastic processes are \textbf{jointly measurable} when regarded as functions on the product space $T\times\Omega$, where $T$ is equipped with the Borel $\sigma$-algebra.
    \end{property}

    \newdef{Filtered probability space}{\index{probability!space}\index{usual conditions}\index{standard!filtration}
        Consider a probability space $(\Omega,\Sigma,P)$ together with a filtration (\cref{set:filtration}) of $\Sigma$, i.e.~a collection of $\sigma$-algebras $\mathbb{F}\equiv\tseq{\mathbb{F}}$, such that $i\leq j\implies\mathbb{F}_i\subseteq\mathbb{F}_j$. The quadruple $(\Omega,\Sigma,\mathbb{F},P)$ is called a filtered probability space. Often, only the filtration and the probability measure are indicated $(\mathbb{F},P)$, e.g.~when the underlying measurable space is of lesser importance.

        Often, the filtration is required to be exhaustive and separated (where $\emptyset$ is replaced by $\mathbb{F}_0=\{\emptyset,\Omega\}$ since any $\sigma$-algebra has to contain the total space). Moreover, the filtration will often be required to `\textbf{satisfy the usual conditions}' (also called \textbf{standard}): $\mathbb{F}_0$ turns the space into a complete measurable space and $\mathbb{F}$ is right-continuous, i.e.~$\mathbb{F}_t = \bigcap_{s>t}\mathbb{F}_s$.
    }

    \newdef{Adapted process}{\index{adapted!process}
        A stochastic process $\tseq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is said to be adapted to the filtration $\mathbb{F}$ if $X_t$ is $\mathbb{F}_t$-measurable for all $t\in T$. The smallest filtration with respect to which a stochastic process is adapted, is called its \textbf{natural filtration} $\mathbb{F}^X$. For a linearly ordered index set, this is simply the filtration generated as follows:
        \begin{gather}
            \mathbb{F}_t^X = \sigma\left(\{X_s\}_{s\leq t}\right)\,.
        \end{gather}
    }

    \newdef{Progressively measurable}{\index{measurable!progressively}\index{progressive|see{measurable}}\label{stoch:progressive}
        An $\mathcal{X}$-valued stochastic process $\tseq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is said to be progressively measurable (or simply \textbf{progressive}) if for all $t\in T$, the map $T_{\leq t}\times\Omega\rightarrow\mathcal{X}$ is measurable with respect to the product $\sigma$-algebra $\Sigma_{T_{\leq t}}\otimes\mathbb{F}_t$, where the first factor denotes a suitable $\sigma$-algebra on the index set.
    }
    \begin{property}
        Every adapted process with left- (or right-)continuous paths is progressively measurable. Moreover, every adapted process adapts a progressively measurable modification.
    \end{property}

    \newdef{Predictable process}{\index{predictable}\label{stoch:predictable_process}
        First, consider $T=\mathbb{N}$. A discrete-time stochastic process $\seq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is said to be predictable if $X_{n+1}$ is $\mathbb{F}_n$-measurable for all $n\in\mathbb{N}$.

        More generally, for arbitrary $T$, consider the \textbf{predictable $\sigma$-algebra}, i.e.~the $\sigma$-algebra on $T\times\Omega$ generated by all (left-)continuous, adaptive processes. A process $\tseq{X}$ is said to be predictable if it is measurable with respect to the predictable $\sigma$-algebra. 
    }
    \begin{example}[Elementary predictable process]\label{stoch:elementary_process}
        \begin{gather}
            X_t = f_0\mathbbm{1}_{\{0\}}(t) + \sum_{i=1}^nf_i\mathbbm{1}_{]\tau_{i-1},\tau_i]}(t)
        \end{gather}
        for a finite sequence of bounded stopping times $\{\tau_i\}_{i\leq n}$, with $\tau_0 \equiv 0$, and bounded $\mathbb{F}_{\tau_i}$-measurable functions $f_i$. The vector space of elementary predictable processes will be denoted by $\mathcal{E}$.
    \end{example}
    \begin{property}
        The predictable $\sigma$-algebra is generated by the elementary predictable processes.
    \end{property}

    \newdef{Increasing}{\index{increasing}\index{integrable}
        An adapted process $\tseq{X}$, where $T$ is linearly ordered and has a minimal element $0$, is called increasing if:
        \begin{enumerate}
            \item $X_0=0$ a.s.
            \item $t\mapsto X_t(\omega)$ is almost surely right-continuous and increasing.
        \end{enumerate}
        Often, integrability of all $X_t$ is also required. If $\lim_tX_t$ is integrable, the increasing process itself is called \textbf{integrable}.
    }
    \begin{property}[Naturality]\index{natural}
        An increasing process $\rseq{A}$ is predictable if and only if it is \textbf{natural}, i.e.~when
        \begin{gather}
            \expect{\Intt{0}{t}X_s\,dA_s} = \expect{\Intt{0}{t}X_{s^-}\,dA_s}
        \end{gather}
        for all $t\in T$ and every bounded, right-continuous martingale $\rseq{X}$.
    \end{property}

    \begin{property}[Measurability hierarchy]
        The following hierarchy shows how the different notions of measurability of stochastic processes are related (from strong to weak):
        \begin{enumerate}
            \item Continuous and adapted,
            \item predictable,
            \item \textit{optional},
            \item progressively measurable, and
            \item adapted (and jointly measurable).
        \end{enumerate}
    \end{property}

    \newdef{Stopping time}{\index{stopping time}
        Consider a random variable $\tau$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ where the codomain of $\tau$ coincides with the index set of $\mathbb{F}$. This variable is called a stopping time for $\mathbb{F}$ if
        \begin{gather}
            \{\tau\leq t\}\in\mathbb{F}_t
        \end{gather}
        for all $t\in T$. The stopping time is a `time indicator' that only depends on the knowledge of the process up to time $t\in T$.
    }
    \newdef{Stopped process}{
        Consider a stochastic process $\tseq{X}$ and a stopping time $\tau$. The stopped process $\tseq{X^\tau}$ is defined as follows:
        \begin{gather}
            X^\tau_t := X_{t\land\tau}\,.
        \end{gather}
    }

    The notions of convergence from \cref{section:probability_distributions} can be generalized to stochastic processes in different ways. The following is the most common one.
    \newdef{UCP convergence}{\index{convergence!ucp}
        A sequence of jointly measurable stochastic processes $(X_{t,n})_{t\in T,n\in\mathbb{N}}$ is said to converge \textbf{uniformly on compacta} (ucp) to a stochastic process $\tseq{X}$ if
        \begin{gather}
            \Prob\left(\sup_{s\leq t}|X_{s,n}-X_s|>K\right)\longrightarrow0
        \end{gather}
        when $n\longrightarrow+\infty$ for all $t\in T$ and $K>0$.
    }

\section{Brownian motion}\index{Brownian motion}
\subsection{Classical Wiener space}\label{section:classical_wiener_space}

    Consider the space $C([0,1])$ of continuous functions on the unit interval. A $\sigma$-algebra $\Sigma$ on the function space $C([0,1])$ can be generated by the following sets, called \textbf{cylinder sets}:\index{cylinder!set}
    \begin{gather}
        \mathcal{C}_{t_1,\ldots,t_n}(B) := \left\{f\in X^Y\,\middle\vert\,\bigl(f(t_1),\ldots,f(t_n)\bigr)\in B\right\}\,,
    \end{gather}
    where $B$ is a Borel set, $n\in\mathbb{N}$ and $\{t_1,\ldots,t_n\}\subset[0,1]$. Moreover, for every choice of $\{t_1,\ldots,t_n\}$, one obtain a $\sigma$-algebra $\mathcal{C}_{t_1,\ldots,t_n}$ generated by evaluation at these points. On this measurable space $\bigl(C([0,1]),\mathcal{C}_{t_1,\ldots,t_n}\bigr)$ one can define the Gaussian measure (see also \cref{statistics:normal_distr})
    \begin{gather}
        \mu_{t_1,\ldots,t_n}(A) := \frac{1}{(2\pi)^{n/2}\sqrt{t_1(t_2-t_1)\cdots(t_n-t_{n-1})}}\Int_{f^n(A)}\exp\left(-\frac{x_1^2}{2t_1}-\cdots\frac{(x_n-x_{n-1})^2}{2(t_n-t_{n-1})}\right)\,d^nx
    \end{gather}
    if $t_1>0$ and
    \begin{gather}
        \mu_{t_1,\ldots,t_n}(A) := \frac{1}{(2\pi)^{\frac{n-1}{2}}\sqrt{t_2\cdots(t_n-t_{n-1})}}\Int_{A_0}\exp\left(-\frac{x_2^2}{2t_2}-\cdots\frac{(x_n-x_{n-1})^2}{2(t_n-t_{n-1})}\right)\,d^{n-1}x
    \end{gather}
    if $t_1=0$, where $A_0 := \left\{x\in\mathbb{R}^{n-1}\,\middle\vert\,(0,x)\in f^{n}(A)\right\}$. In the case $n=0$, the measure fully degenerates to a $\delta$-measure at 0.

    Given these constructions, it can be shown that there exists a unique measure $P^W$ on $\bigl(C([0,1]),\Sigma\bigr)$, called the \textbf{Wiener measure}\index{Wiener!measure}, such that
    \begin{gather}
        P^W(A) = \mu{t_1,\ldots,t_n}(A)
    \end{gather}
    for all $A\in\mathcal{C}_{t_1,\ldots,t_n}$.

    This is an application of a more general theorem.
    \begin{theorem}[Kolmogorov extension theorem\footnotemark]\index{Kolmogorov!extension theorem}\index{Kolmogorov--Daniell|see{Kolmogorov extension theorem}}
        \footnotetext{Also called the \textbf{Kolmogorov--Daniell theorem}.}
        \todo{ADD KOLMOGOROV EXTENSION THEOREM (in general)}
    \end{theorem}

    \begin{theorem}[Kolmogorov continuity theorem]\index{Kolmogorov!continuity theorem}\label{stoch:kolmogorov_continuity_theorem}
        Consider a stochastic process $\rseq{X}$ with
        \begin{gather}
            \expect{|X_t-X_s|^\beta}\leq C\|t-s\|^{1+\alpha}
        \end{gather}
        for some $\alpha,\beta,C\in\mathbb{R}^+_0$. There exists a version $\rseq{\widetilde{X}}$ with a.s.~H\"older-continuous paths for H\"older-exponent $\gamma<\frac{\alpha}{\beta}$ (\cref{calculus:holder_continuity}).
    \end{theorem}

\subsection{Wiener process}

    \newdef{L\'evy process}{\index{L\'evy!process}\index[author]{L\'evy}
        A stochastic process $\rseq{X}$ satisfying:
        \begin{enumerate}
            \item\textbf{Initial condition}: $X_0=0$ a.s.
            \item\textbf{Independent increments}: For all $t_1\leq\cdots\leq t_n$, $\{X_{t_2}-X_{t_1},\ldots,X_{t_n}-X_{t_{n-1}}\}$ are independent.
            \item\textbf{Stationary increments}: For all $s\leq t$, $X_t-X_s\overset{d}{=}X_{t-s}$.
            \item\textbf{Continuity in probability}: $\rseq{X}$ is almost surely \cdlgg. 
        \end{enumerate}
    }

    A famous example of a L\'evy process is Brownian motion.
    \newdef{Brownian motion}{\label{stoch:brownian_motion}
        A continuous-time stochastic process $\rseq{W}$ satisfying:
        \begin{enumerate}
            \item $W_0$ is almost surely 0.
            \item $W$ has independent Gaussian increments.
            \item $W$ is almost surely continuous.
        \end{enumerate}
    }

    \begin{remark}[Wiener process]\index{Wiener!process}
        A Brownian motion is also called a Wiener process (especially in the mathematics literature). The reason for this terminology is that an explicit construction of Brownian motion can be given through the Wiener measure $P^W$ defined in the previous section. The process
        \begin{gather}
            B_t:\mathbb{R}^{[0,1]}\rightarrow\mathbb{R}:f\mapsto f(t)
        \end{gather}
        is a Brownian motion on $[0,1]$, i.e.~$P^W$ is the law of the $\mathbb{R}^{[0,1]}$-valued random variable $B$.
    \end{remark}

    \newdef{Geometric Brownian motion}{
        \begin{gather}
            M_t := \exp\left(W_t - \frac{t}{2}\right)\,,
        \end{gather}
        where $\rseq{W}$ is a standard Brownian motion.
    }

    \newdef{Wiener measure}{\label{Wiener!measure}
        \Cref{stoch:kolmogorov_continuity_theorem} implies that there exists a continuous version $\rseq{\widetilde{B}}$ of Brownian motion. The induced map
        \begin{gather}
            \widetilde{B}:\mathbb{R}^{[0,1]}\rightarrow C([0,1]):f\mapsto \bigl(t\mapsto\widetilde{B}_t(f)\bigr)
        \end{gather}
        is measurable. As such, one obtains the pushforward measure $\gamma^W:=\widetilde{B}_*P^W$ on $C([0,1])$, also called the Wiener measure. The measure space $\bigl(C([0,1]),\mathcal{B}\bigl(C([0,1])\bigr),\gamma^W\bigr)$ is also called the \textbf{classical Wiener space}.
    }

\subsection{Abstract Wiener space}

    \begin{theorem}[Cameron--Martin]\index{Cameron--Martin}\label{stoch:cameron_martin}
        Consider the Gaussian measure
        \begin{gather}
            \gamma_n(A) := \frac{1}{(2\pi)^{n/2}}\Int_A\exp\left(-\frac{\|x\|^2}{2}\right)\,d^nx\,.
        \end{gather}
        By Haar's theorem~\ref{distribution:haar_theorem}, the Lebesgue measure is the only measure that is translation invariant. The pushforward of $\gamma_n$ under translation over $v\in\mathbb{R}^n$ is given by the following Radon--Nikodym derivative:
        \begin{gather}
            \deriv{v_*\gamma_n}{\gamma_n}(x) = \exp\left(\langle v,x \rangle - \frac{\|v\|^2}{2}\right)\,.
        \end{gather}
    \end{theorem}

    This theorem can be generalized to locally convex vector spaces $X$ (separable Hilbert spaces, in particular). To this end, a measure $\gamma$ on an LCTVS $X$ is said to be \textbf{Gaussian} if, for every $f\in X'$, $f_*\gamma$ is a normal distribution on $\mathbb{R}$.\index{Gauss!distribution} However, on a general infinite-dimensional separable Hilbert space, the definition of the Gaussian measure does not make sense. Since, by the \textit{(strong) law of large numbers} (see \cref{prob:strong_lln}), the norm
    \begin{gather}
        \|x\| = \sum_{n=1}^{+\infty}\braket{x}{e_i}^2
    \end{gather}
    would diverge almost surely because the individual coefficients, where $e_i$ are orthonormal, would be independent under the Gaussian measure.

    The first step in solving this issue is to generalize the notion of cylinder sets (\cref{section:classical_wiener_space}) has to be generalized by replacing pointwise evaluations with linear functionals\footnote{In fact, one could consider any dual pair $(M,N)$.} $\phi\in X'$. Two equivalent approaches exist, through finite collections of anchor points or through finite-dimensional projections.
    \newdef{Cylinder set}{\index{cylinder!set}\index{cylinder!set measure}
        Consider a locally convex vector space $X$ (\cref{functional:locally_convex}) and its topological dual $X'$. A cylinder set in $X$ is a subset of the form
        \begin{gather}
            C_{\phi_1,\ldots,\phi_n}(B) := \left\{x\in X\,\middle\vert\,\bigl(\phi_1(x),\ldots,\phi_n(x)\bigr)\in B\right\}\,,
        \end{gather}
        where $\{\phi_1,\ldots,\phi_n\}\subset X'$ and $B\in\mathcal{B}(\mathbb{R}^n)$. The $\sigma$-algebra generated by all cylinder sets will be denoted by $\mathcal{C}(X)$, whereas the $\sigma$-algebra consisting of cylinder sets for a fixed choice of $\{\phi_1,\ldots,\phi_n\}\subset X'$ will be denoted by $\mathcal{C}_{\phi_1,\ldots,\phi_n}(X)$.\footnote{Note the terminology. For fixed indexing functionals, one readily obtains a $\sigma$-algebra, whereas the collection of all cylinder sets is only an algebra of sets (\cref{set:algebra_of_sets}). It is sometimes called a \textbf{cylindrical algebra}.} $\mathcal{C}(X)$ is, equivalently, the minimal $\sigma$-algebra that turns all linear functionals measurable.

        The cylinder sets can be defined equivalently as follows. Consider a finite-dimensional subspace $K\leq X'$ and the associated projection $\pi_K:X\rightarrow X/K^\perp$, where $K^\perp$ is the orthogonal complement as in \cref{linalgebra:dual_complement}. Cylinder sets are equivalently of the form $\pi_K^{-1}(B)\cong B+K^\perp$ for $B\in\mathcal{B}(K')$.

        A \textbf{cylinder set measure} is a finitely additive function $\mathcal{C}(X)\rightarrow\mathbb{R}^+$ that restricts to a proper measure on any sub-$\sigma$-algebra $\mathcal{C}_{\phi_1,\ldots,\phi_n}(X)$.
    }

    \begin{property}
        On a separable Banach space $X$, the Borel $\sigma$-algebra $\mathcal{B}(X)$ coincides with the cylindrical $\sigma$-algebra $\mathcal{C}(X)$ with respect to its topological dual $X'$.
    \end{property}

    Now, given a separable Hilbert space $\mathcal{H}$ and a Gaussian cylinder set measure $\mu$, one can try to find a separable Banach space $X\supseteq\mathcal{H}$ such that $\mu$ extends to a proper measure $\gamma$ satisfying
    \begin{gather}
        \gamma(B)=\mu(B\cap\mathcal{H})
    \end{gather}
    for all $B\in\mathcal{B}(X)$. To construct $X$, one takes the completion of $\mathcal{H}$ with respect to a norm that interacts nicely with $\mu$.\footnote{The following property of norms is merely a sufficient condition for the extension to be possible.}

    \newdef{Measurable norm}{\index{norm!measurable}\index{Gross|see{norm!measurable}}
        A (continuous) norm $\|\cdot\|$ on a topological vector space $X$ is said to be (Gross-)measurable (with respect to a cylinder set measure $\mu$) if, for every $\varepsilon>0$, there exists a finite-dimensional subspace $V_\varepsilon\leq X$ such that for all finite-dimensional subspaces $V\leq X$ the following holds:
        \begin{gather}
            V\perp V_\varepsilon\implies\mu\bigl(\{v\in V\mid\|v\|>\varepsilon\}\bigr)\varepsilon\,.
        \end{gather}
    }
    \begin{example}[Hilbert--Schmidt operators]
        Consider a separable Hilbert space $\mathcal{H}$ with norm $\|\cdot\|$. For every Hilbert--Schmidt operator $T:\mathcal{H}\rightarrow\mathcal{H}$ (\cref{functional:hilbert_schmidt}), the induced norm
        \begin{gather}
            \|\cdot\|_T := \|T(\cdot)\|
        \end{gather}
        is measurable with respect to the canonical Gaussian measure on $\mathcal{H}$. Moreover, any other measurable Hilbert norm on $\mathcal{H}$ is exactly of this form.
    \end{example}

    \begin{property}
        Every separable Banach space is the Gross-completion of a separable Hilbert space with respect to some measurable norm. 
    \end{property}

    Now, given a Gaussian measure $\gamma$ on an LCTVS $X$, one can define the moments of functionals $\phi\in X'$ in analogy with \cref{section:moments} and \cref{prob:unconscious_statistician}:
    \begin{gather}
        \begin{aligned}
            \expect{\phi} &:= \Int_X\phi\,d\gamma\,,\\
            \mathrm{Cov}[\phi,\psi] &:= \Int_X\bigl(\phi-\expect{\phi}\bigr)\bigl(\psi-\expect{\psi}\bigr)\,d\gamma\,.
        \end{aligned}
    \end{gather}
    These are, respectively linear and symmetric, bilinear and nondegenerate on $X'$. Moreover, if $X$ is a separable Banach space, they are continuous as well. The centered functionals (or \textbf{measurable linear functionals}), i.e.~those with $\expect{\phi}=0$, form a designated subspace:
    \begin{gather}
        X'_\gamma := \overline{\{\phi-\expect{\phi}\mid\phi\in X'\}}\vphantom{\expect{\phi}}^{L^2}\,.
    \end{gather}
    The $L^2$-closure makes sense since the inner product induced by the covariance operator reduces to the standard $L^2(\gamma)$-inner product when restricting to centered elements.

    \begin{theorem}\index{Gauss!distribution}
        A measure $\gamma$ on a locally convex measurable space $(X,\mathcal{C}(X))$ is Gaussian if and only if its Fourier transformation (i.e.~its characteristic function~\ref{prob:characteristic_function}) has the form
        \begin{gather}
            \widetilde{\gamma}(f) = \exp\left(i\expect{f} - \frac{\mathrm{Cov}[f,f]}{2}\right)\,.
        \end{gather}
    \end{theorem}
    \begin{remark}
        In the literature, one often focuses on centered Gaussian measures, i.e.~where the characteristic function only contains the covariance operator. In this situation, $X'_\gamma=X'$.
    \end{remark}

    \newdef{Cameron--Martin space}{\index{Cameron--Martin!space}\index{norm!Gross}
        Consider a Gaussian measure $\gamma$ on a locally convex vector space $X$. The covariance operator $\mathrm{Cov}$ induces a norm on $X$:
        \begin{gather}
            \|x\|_\gamma := \sup\{\phi(x)\mid \phi\in X',\mathrm{Cov}[\phi,\phi]\leq 1\}\,.
        \end{gather}
        The Cameron--Martin space of $\gamma$ is defined as follows:
        \begin{gather}
            H(\gamma) := \{x\in X\mid \|x\|_\gamma<+\infty\}\,.
        \end{gather}
    }
    \begin{remark}
        If $X$ was obtained as the Gross-completion of a separable Hilbert space $\mathcal{H}$, then $\mathcal{H}\cong H(\gamma)$ and $\|\cdot\|_\gamma=\|\cdot\|_{\mathcal{H}}$.
    \end{remark}

    \begin{property}\label{stoch:cameron_martin_characterization}
        Let $X$ be a separable Banach space. For every centered element $h\in X'_\gamma$, there exists an $x\in X$ such that
        \begin{gather}
            \mathrm{Cov}[h,\cdot] = \langle\cdot,x\rangle\,.
        \end{gather}
        More specifically, $\mathrm{Cov}:X'_\gamma\rightarrow X$ characterizes $H(\gamma)$:
        \begin{gather}
            H(\gamma) = \mathrm{Im}(\mathrm{Cov})\,.
        \end{gather}
        An explicit map is given by the Bochner integral (\cref{section:bochner_integral}). The image of $\phi\in X'_\gamma$ is given by
        \begin{gather}
            \Int_X(x-\expect{\gamma})\phi(x)\,d\gamma(x)\,.
        \end{gather}
    \end{property}
    \begin{remark}
        This property follows from the general fact that, given a dense embedding $\mathcal{H}\hookrightarrow\mathcal{B}$ of a Hilbert space in a Banach space, the dual $\mathcal{B}'$ can be densely embedded into $\mathcal{H}$. Every linear form on $\mathcal{B}$ gives a form on $\mathcal{H}$ by restriction. By Riesz's representation theorem~\ref{functional:riesz}, one obtains for every such form $\phi|_{\mathcal{H}}$ an element $x_\phi$ such that
        \begin{gather*}
            \phi|_{\mathcal{H}}(x) = \braket{x}{x_\phi}\,.
        \end{gather*}
        Now, since $\mathcal{H}$ is dense in $\mathcal{B}$, this extends uniquely to $\mathcal{B}$.
    \end{remark}

    \begin{property}
        $H(\gamma)$ is a separable Hilbert subspace of $X$ and, in particular, a \textit{reproducing kernel Hilbert space} (see \cref{data:kernel_methods}). However, $\|\cdot\|_X$ and $\|\cdot\|_\gamma$ are not equivalent (the former giving an RKHS, the latter giving it the structure of the Cameron--Martin space).
    \end{property}

    \Cref{stoch:cameron_martin} can now be generalized to separable Banach spaces.
    \begin{theorem}[Cameron--Martin]\index{Cameron--Martin}
        Let $X$ be a separable Banach space. For $x\in X$ and a Gaussian measure $\gamma$ on $X$, the translated measure
        \begin{gather}
            x_*\gamma(B) := \gamma(B-x)
        \end{gather}
        is equivalent to $\gamma$ if and only if $x\in H(\gamma)$ and, in this case, the associated Radon--Nikodym derivative is given by
        \begin{gather}
            \deriv{x_*\gamma}{\gamma} = \exp\left(h(x) - \frac{\|x\|_\gamma^2}{2}\right)\,,
        \end{gather}
        where $h(x)\in X'_\gamma$ is the centered element corresponding to $x$ by \cref{stoch:cameron_martin_characterization}.
    \end{theorem}

    The ideas above can be abstracted and formalized as follows.
    \newdef{Abstract Wiener space}{\index{Wiener!space (abstract)}
        A triple $(\mathcal{H},\mathcal{B},\gamma)$ such that:
        \begin{enumerate}
            \item $\mathcal{H}$ is a separable Hilbert space, called the Cameron--Martin space.
            \item $\mathcal{B}$ is a separable Banach space containing $\mathcal{H}$ as a dense subspace.
            \item $\gamma$ is a Gaussian measure on $\mathcal{B}$ with characteristic functional
            \begin{gather}
                \widetilde{\gamma}(\phi) \equiv \Int_{\mathcal{B}}\exp(i\phi)\,d\gamma := \exp\left(-\frac{\|\iota^*(\phi)\|_{\mathcal{H}}^2}{2}\right)\,,
            \end{gather}
            where $\iota^*:\mathcal{B}'\rightarrow\mathcal{H}'\cong\mathcal{H}$ is the dual of the canonical injection.
        \end{enumerate}
        Note that it is the Cameron--Martin space that determines the structure.
    }

    Although the Cameron--Martin space determines the structure of an abstract Wiener space, it is small in the following sense.
    \begin{property}
        Consider an abstract Wiener space $(\mathcal{H},\mathcal{B},\gamma)$. If $\mathcal{H}$ is infinite dimensional, then $\gamma(\mathcal{H})=0$.
    \end{property}

\section{Martingales}

    From here on, the index set $T$ will be $\mathbb{N}$ or $\mathbb{R}^+\equiv[0,+\infty[$, so that the index $t$ can be interpreted as a time parameter. The explicit choice will be made clear if necessary.

\subsection{Proper martingales}

    \newdef{Martingale}{\index{martingale}\label{prob:martingale}
        A stochastic process $\tseq{X}$ on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ is called an $(\mathbb{F},P)$-martingale if it satisfies the following conditions:
        \begin{enumerate}
            \item $\tseq{X}$ is $\mathbb{F}$-adapted.
            \item For all $t\in T$: $X_t\in L^1(P)$.
            \item For all $t>s\geq0:\expect{X_{t}\,\middle\vert\,\mathbb{F}_s}=X_s$.
        \end{enumerate}
        If the equality in the last condition is replaced by the inequality $\leq$ (resp.~$\geq$), the stochastic process is called a \textbf{supermartingale} (resp.~\textbf{submartingale}).
    }
    \begin{example}[Doob martingale]\index{Doob!martingale}
        Consider an integrable random variable $X$ and a filtration $\mathbb{F}$. The associated Doob martingale with respect to $(\mathbb{F},P)$ is given by
        \begin{gather}
            Y_t := \expect{X\,\middle\vert\,\mathbb{F}_t}\,.
        \end{gather}
        The fact that this is a martingale follows from the law of iterated expectations.
    \end{example}

    \begin{remark}[C\`adl\`ag]
        It can be shown that almost surely right-continuous submartingales (and supermartingales) with respect to a filtration that satisfies the usual conditions, always admit a \cdlg modification. From here one, all submartingales will assumed to be \cdlg unless mentioned otherwise.
    \end{remark}

    \begin{theorem}[Optional stopping]\index{optional stopping}
        Let $\tseq{X}$ be a martingale. If $\tau$ is a stopping time satisfying either of the following conditions:
        \begin{enumerate}
            \item $\tau$ is almost surely bounded, or
            \item the stopped process $\tseq{X^\tau}$ is almost surely bounded,
        \end{enumerate}
        then the stopped process $\tseq{X^\tau}$ is again a martingale.
    \end{theorem}

    The following result is an example of weak type inequalities (\cref{measure:weak_type}).
    \begin{property}[Doob--Ville inequality]\index{Doob--Ville!inequality}\index{Ville|seealso{Doob}}\label{prob:doob_inequality}
        Consider a \cdlg submartingale $\tseq{X}$.
        \begin{gather}
            \Prob\left(\sup_{t\leq\tau}X_t\geq\lambda\right)\leq\frac{\expect{\max(0,X_\tau)}}{\lambda}
        \end{gather}
        for all $\lambda\geq1$ and $\tau\in T$.
    \end{property}

    The following property generalizes the Hoeffding inequalities~\cref{prob:hoeffding_inequality}.
    \begin{property}[Hoeffding--Azuma inequality]\index{Hoeffding--Azuma inequality}\index{McDiarmid inequality}\label{prob:hoeffding_azuma}
        Let $\seq{X}$ be a (super)martingale with bounded differences, i.e.~there exist constants $c_k\in\mathbb{R}$ such that
        \begin{gather}
            |X_k-X_{k-1}|\leq c_k\,.
        \end{gather}
        The following inequality holds for all $\lambda\geq0$:
        \begin{gather}
            \Prob\bigl(X_N-X_0\geq\lambda\bigr)\leq\exp\left(-\frac{\lambda^2}{2\sum_{i=1}^Nc_i^2}\right)\,.
        \end{gather}
        A symmetric result for the lower tail holds for (sub)martingales. Moreover, if there exist predictable processes $\seq{A},\seq{B}$ such that
        \begin{gather}
            A_k\leq X_k-X_{k-1}\leq B_k
        \end{gather}
        and
        \begin{gather}
            B_k-A_k\leq c_k
        \end{gather}
        for all $k\in\mathbb{N}$, the inequality can be sharpened:
        \begin{gather}
            \Prob\bigl(X_N-X_0\geq\lambda\bigr)\leq\exp\left(-\frac{2\lambda^2}{\sum_{i=1}^Nc_i^2}\right)\,.
        \end{gather}
        Now, consider a function $f:\Omega^n\rightarrow\mathbb{R}$ such that
        \begin{gather}
            \sup_{x_1,\ldots,x_n,x'_k}|f(x_1,\ldots,x_k,\ldots,x_n)-f(x_1,\ldots,x'_k,\ldots,x_n)|\leq c_k
        \end{gather}
        for all $k\in\mathbb{N}$. By applying the above inequalities to the Doob martingale
        \begin{gather}
            Z_m:=\expect{f(X_1,\ldots,X_n)\mid X_1,\ldots,X_m}\,,
        \end{gather}
        one obtains the following inequality:
        \begin{gather}
            \Prob\bigl(f(X_1,\ldots,X_n)-\expect{f}\geq\lambda\bigr)\leq\exp\left(-\frac{2\lambda^2}{\sum_{i=1}^nc_i^2}\right)\,.
        \end{gather}
        This inequality is sometimes called the \textbf{McDiarmid inequality}.
    \end{property}

    \begin{theorem}[Doob decomposition]\index{Doob!decomposition}
        Any integrable, adapted process $\seq{X}$ can be decomposed (almost surely uniquely) as
        \begin{gather}
            X_n=X_0+M_n+A_n\,,
        \end{gather}
        where $\seq{M}$ is a martingale and $\seq{A}$ is an integrable, predictable process. These two processes are constructed iteratively as follows:
        \begin{gather}
            \begin{aligned}
                A_0 = 0\qquad&\qquad M_0 = 0\\
                \Delta A_n = \expect{\Delta X_n\mid\mathbb{F}_{n-1}}\qquad&\qquad\Delta M_n = \Delta X_n - \Delta A_n\,.
            \end{aligned}
        \end{gather}
        Furthermore, $\seq{X}$ is a submartingale if and only if $\seq{A}$ is (almost surely) increasing.\footnote{Replacing increasing by decreasing gives a similar statement for supermartingales.}
    \end{theorem}
    \newdef{Quadratic variation}{\index{variation!quadratic}
        Consider the special case $X_n=Y_n^2$ for some integrable martingale $\seq{Y}$. By Jensen's inquality~\ref{calculus:jensen_inequality}, $\seq{X}$ is an integrable submartingale. The process $\seq{A}$ in the Doob decomposition of $\seq{X}$ is often called the \textbf{quadratic variation process} of $\seq{Y}$ and is denoted by $\seq{[Y]}$.
    }

    The Doob decomposition has an analogue for $\mathbb{R}^+$-indexed processes.
    \begin{theorem}[Doob--Meyer]\index{Doob--Meyer}\index{DL}
        Consider the class $\mathcal{T}_{\!\!a}$ of stopping times which are almost surely bounded by $a\in\mathbb{R}$ and a right-continuous submartingale $\tseq{T}$ such that $\{X_\tau\}_{\tau\in\mathcal{T}_{\!\!a}}$ is uniformly integrable\footnote{Stochastic processes that satisfy this condition for some $a\in\mathbb{R}$ are said to be of \textbf{class DL}}. Then $\tseq{X}$ can be decomposed (almost surely uniquely) as
        \begin{gather}
            X_t = X_0 + M_t + A_t\,,
        \end{gather}
        where $\tseq{M}$ is a right-continuous martingale and $\tseq{A}$ is increasing and natural.
    \end{theorem}
    \begin{remark}
        The DL condition can be replaced by requiring (almost sure) nonnegativity.
    \end{remark}

    As in the case of discrete-time martingales, the quadratic variation could be defined through the Doob--Meyer decomposition of $X^2$. However, an alternative definition goes as follows.
    \newadef{Quadratic variation}{\index{variation!quadratic}\label{stoch:quadratic_variation}
        Let $\rseq{X}$ be a martingale. For every stochastic partition $P=\{0=\tau_0\leq\tau_1\leq\cdots\nearrow+\infty\}$ of $\mathbb{R}^+$, i.e.~sequence of stopping times starting at zero and going to infinity, define the quadratic variation as
        \begin{gather}
            [X]^P_t := \sum_{i=1}^{+\infty}(X_{t\land \tau_i}-X_{t\land\tau_{i-1}})^2\,.
        \end{gather}
        The quadratic variation $[X]$ is obtained by taking the limit over all stochastic partitions as the mesh size
        \begin{gather}
            \label{stoch:quadratic_variation_formula}
            |P| := \max_{n\in\mathbb{N}}(t\land\tau_n - t\land\tau_{n-1})
        \end{gather}
        goes to zero in probability. (The limit converges in probability and even ucp.\footnote{For more general processes, the quadratic variation is well defined exactly if this limit exists.}) Moreover, if $X$ is continuous and square-integrable, so is $[X]$ and this construction coincides with that through the Doob--Meyer decomposition.
    }
    \begin{remark}[Quadratic covariation]\index{covariation}
        The formula for the quadratic variation can easily be modified to obtain the quadratic covariation:
        \begin{gather}
            [X,Y]^P_t := \sum_{i=1}^{+\infty}(X_{t\land \tau_i}-X_{t\land\tau_{i-1}})(Y_{t\land \tau_i}-Y_{t\land\tau_{i-1}})\,.
        \end{gather}
    \end{remark}

    \begin{property}[Linearity]
        Consider three processes $\rseq{X},\rseq{Y}$ and $\rseq{Z}$. For any two real numbers $a,b\in\mathbb{R}$, the following relation holds:
        \begin{gather}
            [aX+bY,Z]_t = a[X,Z]_t+b[Y,Z]_t\,.
        \end{gather}
    \end{property}

    \newdef{Orthogonality}{\index{orthogonality}
        Two stochastic processes are said to be orthogonal if their quadratic covariation vanishes:
        \begin{gather}
            X\perp Y \iff [X,Y] = 0\,.
        \end{gather}
    }

\subsection{Local martingales}\index{martingale}

    \newdef{Local martingale}{
        Consider a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$. A stochastic process $\tseq{X}$ is called a local martingale (relative to $\mathbb{F}$) if there exists stopping times $\seq{\tau}$ (with respect to $\mathbb{F}$) satisfying the following conditions:
        \begin{enumerate}
            \item $\seq{\tau}$ is almost surely increasing.
            \item $\seq{\tau}$ is almost surely divergent.
            \item The stopped process $\{X^{\tau_n}\}_{t\in T}$ is a martingale (relative to $\mathbb{F}$) for all $n\in\mathbb{N}$.
        \end{enumerate}
    }

    This idea can be generalized to any kind of property of stochastic processes.
    \newdef{Localization}{\index{localization}
        Consider a class $\mathcal{P}$ of stochastic processes. A stochastic process $\tseq{X}$ is said to be locally in $\mathcal{P}$ if there exists a sequence $\seq{\tau}$ of stopping times, with $\tau_n\nearrow+\infty$ almost surely, such that the stopped process $\tseq{X^{\tau_n}}$ is in $\mathcal{P}$ for all $n\in\mathbb{N}$.
    }

    \newdef{Local integrability}{\index{integrable!locally}
        A stochastic process is said to be locally integrable if its maximum process $X_t^*:=\sup_{s\leq t}X_s$ is locally in the class of integrable stochastic processes.
    }
    \begin{property}
        A \cdlgg, adapted stochastic process is of class D(L) if and only if it is locally integrable
    \end{property}
    \begin{property}
        Every local martingale is locally integrable and a local martingale is a martingale if and only if it is of class DL. (Note that, by the preceding property, this happens exactly when the local martingale is \cdlg and adapted.)
    \end{property}

    \begin{property}[Convergence]
        The limit of a sequence of continuous local martingales that converges ucp is itself a  continuous local martingale.
    \end{property}

    \begin{property}[Covariation]\index{covariation}\label{stoch:covariation}
        If $\tseq{X},\tseq{Y}$ are local martingales, then $\tseq{[X,Y]}$ is the unique FV process that starts at 0 and such that
        \begin{enumerate}
            \item $\bigl(X_tY_t - [X,Y]_t\bigr)_{t\in T}$ is a local martingale, and
            \item $\Delta[X,Y] = \Delta X\Delta Y$.
        \end{enumerate}
    \end{property}

    \begin{property}[Square-integrability]
        A local martingale $\rseq{X}$ is an $L^2$-martingale if and only if $\expect{X_0^2}<+\infty$ and $[X]$ is integrable. More generally, a local martingale is a martingale if it is dominated by an integrable random variable.
    \end{property}

    \Cref{stoch:brownian_motion} was rephrased by \indexauthor{L\'evy} in terms of martingale properties.
    \newadef{Brownian motion}{\index{Brownian motion}\label{stoch:levy_characterization}
        A local martingale $\rseq{X}$ such that:
        \begin{enumerate}
            \item $X_0=0$,
            \item $X$ is continuous, and
            \item $(X_t^2-t)_{t\in\mathbb{R}^+}$ is a local martingale or, equivalently by \cref{stoch:covariation}, $[X]_t=t$.
        \end{enumerate}
    }

    Although (local) martingales are often the most interesting objects in practice, they can be generalized in a Doob-like manner. Moreover, these generalized martingales are of major importance for the stochastic calculus that will introduced in the next section.
    \newdef{Semimartingale}{\label{stoch:semimartingale}
        A real-valued stochastic process that can be decomposed as the sum of a local martingale and a \cdlgg, adapted process of locally bounded variation\footnote{This means that the sample paths are almost surely of locally bounded variation.}.
    }
    \begin{remark}
        The \cdlgg, adapted processes of locally bounded variation are also called \textbf{FV processes}.
    \end{remark}

    \begin{property}
        If $\tseq{X}$ is a semimartingale, then $\tseq{\langle X \rangle}$ is \cdlgg, adapted and increasing. Moreover, if $\tseq{Y}$ is also a semimartingale, then $\tseq{\langle X,Y \rangle}$ is an FV process.
    \end{property}

    \newdef{\'Emery topology}{\index{topology!\'Emery}\label{stoch:emery_topology}
        The space of semimartingales on a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ admits a natural topology (\cref{topology:topology}). Consider the following metric (\cref{metric:metric}):
        \begin{gather}
            d_{\text{sm}}(S,T) := \sup_{H\in\mathcal{E},\|H\|_\infty\leq 1}\expect{\sup_{t\in\mathbb{R}^+}|H\cdot(S-T)_t|\land 1}\,,
        \end{gather}
        where $\mathcal{E}$ denotes the set of elementary predictable process on $(\Omega,\Sigma,\mathbb{F},P)$. This metric turn $\Omega$ into a complete metric space (\cref{metric:complete_space}).
    }

\section{It\^o calculus}\label{section:stochastic_integral}

    Two approaches exist to extending integration theory to stochastic processes. One is through the \textit{It\^o isometry} (see \cref{stoch:ito_isometry} below) and the other is through a more axiomatic approach as for the ordinary Lebesgue integral. Both approaches will be explored in this section, with the latter coming first. For simplicity (and unless stated otherwise), all filtered probability spaces will be assumed to satisfy the usual conditions and all martingales will be assumed to be \cdlgg.

\subsection{Wiener--Paley integral}\index{integral!Wiener--Paley}\index{Wiener|seealso{integral}}

    The first step towards defining a notion of stochastic integral will consists of the subclass of integrators on Brownian motions/Wiener processes (\cref{stoch:brownian_motion}).

    As for the Lebesgue measure, one starts with the simple functions (\cref{measure:simple_function}) as integrands:
    \begin{gather}
        f\equiv\sum_{i=1}^na_i\mathbbm{1}_{]t_{i-1},t_i]}\,.
    \end{gather}
    If $\rseq{W}$ denotes a Brownian motion on a standard probability space $(\Omega,\Sigma,P)$, the Wiener integral of $f:\mathbb{R}^+\rightarrow\mathbb{R}$ with respect to $W$ is then given by
    \begin{gather}
        \label{stoch:elementary_wiener_integral}
        \Intt{0}{+\infty}f(s)\,dW_s := \sum_{i=1}^na_i\left(W_{t_i} - W_{t_{i-1}}\right)\,.
    \end{gather}
    It is not hard to show, using the definition of Brownian motion, that the stochastic integral defines a partial isometry on the subspace of $L^2(\mathbb{R}^+)$ of simple functions. By \cref{functional:isometry_extension}, one obtains an isometry $L^2(\mathbb{R}^+)\rightarrow L^2(\Omega)$. In fact, by generalizing to locally integrable functions, one can define a new stochastic process
    \begin{gather}
        f\cdot W_t \equiv \Intt{0}{t}f\,dW \equiv \Intt{0}{t}f_s\,dW_s := \Intt{0}{+\infty}f\mathbbm{1}_{[0,t]}\,dW_s\,.
    \end{gather}

    \begin{formula}
        The process $\rseq{f\cdot W}$ is a continuous, square-integrable martingale.
    \end{formula}

    \begin{formula}[Covariance]
        \begin{gather}
            \mathrm{Cov}\left[\Intt{0}{t}f(s)\,dW_s,\Intt{0}{t'}g(s)\,dW_s\right] = \Intt{0}{\min(s,t)}f(x)g(x)\,dx
        \end{gather}
    \end{formula}

    To extend this construction to stochastic integrands, one has to require that the integrand $\rseq{\phi}$ is progressive (\cref{stoch:progressive}). Progressive measurability ensures that, by Fubini's theorem (\cref{section:fubini}), $\Intt{0}{t}\phi_s\,ds$ is adapted if and only if $\Intt{0}{t}|\phi_s|\,ds$ is a.s.~bounded. Let $M^2(\mathbb{R}^+)$ denote the space of square-integrable progressive processes $\rseq{\phi}$:
    \begin{gather}
        \expect{\Intt{0}{+\infty}\phi^2_s\,ds}<+\infty\,.
    \end{gather}
    Note that $M^2(\mathbb{R}^+)$ contains random step functions
    \begin{gather}
        X\equiv\sum_{i=1}^nX_i\mathbbm{1}_{]t_{i-1},t_i]}\,,
    \end{gather}
    where the coefficients $X_i\in L^2(\Omega)$. The Wiener--Paley integral of such a function is defined similarly:
    \begin{gather}
        \label{stoch:random_elementary_wiener_integral}
        \Intt{0}{+\infty}X\,dW_s(\omega) := \sum_{i=1}^nX_i(\omega)\left(W_{t_i} - W_{t_{i-1}}\right)\,.
    \end{gather}
    Extending this partial isometry, gives the \textbf{It\^o integral} of $\phi$ with respect to $W$.\index{integral!It\^o} The space of progressively measurable stochastic processes satisfying
    \begin{gather}
        \expect{\Intt{0}{+\infty}\phi_s^2\,ds}<+\infty
    \end{gather}
    is denoted by $L^2(W)$.

    \begin{property}[Centrality]\label{stoch:wiener_integral_central}
        Consider a Brownian motion $\rseq{W}$ with natural filtration $\mathbb{F}$. For all $\mathbb{F}$-progressive processes $\rseq{\phi}$, the following equation holds for all $t\in\mathbb{R}^+$:
        \begin{gather}
            \expect{\Intt{0}{t}\phi_s\,dW_s} = 0\,.
        \end{gather}
    \end{property}

\subsection{Stochastic integral}

    Recall \cref{stoch:elementary_process} for the definition of the space of elementary predictable process $\mathcal{E}$. The \textbf{stochastic integral} of such a process $\rseq{\phi}$ with respect to another stochastic process $\rseq{M}$, usually a martingale (see further on) is defined as follows:\index{integral!stochastic}\index{stochastic|seealso{integral}}
    \begin{gather}
        \label{stoch:elementary_integral}
        \phi\cdot M_t \equiv \Intt{0}{t}\phi\,dM \equiv\footnotemark \Intt{0}{t}\phi_s\,dM_s := \sum_{i=1}^nf_i(M_{t\land\tau_i} - M_{t\land\tau_{i-1}})\,.
    \end{gather}

    \footnotetext{This abuse of notation will be explained in \cref{section:stochastic_lebesgue_stieltjes}.}

    For discrete-time processes, the stochastic integral attains a simple form.
    \begin{example}[Martingale transform]\index{martingale!transform|see{integral, stochastic}}
        Let $\seq{M}$ be a discrete-time martingale and let $\seq{\phi}$ be predictable. The (discrete) stochastic integral of $\phi$ with respect to $M$ is given by:
        \begin{gather}
            \phi\cdot M_n := \sum_{i=1}^n\phi_i\,\Delta M_i\,.
        \end{gather}
        For $n=0$, the convention $\phi\cdot M_0=0$ is used.
    \end{example}

    Since, the elementary predictable processes are dense in the space of all predictable processes, bounded convergence (in probability) allows to extend the stochastic integral to all (bounded) predictable processes.
    \newdef{Stochastic integral}{\index{integral!stochastic}\index{convergence!bounded}
        An $L^0$-valued functional
        \begin{gather}
            \rseq{\phi}\mapsto\phi\cdot M_t
        \end{gather}
        on the space of bounded predictable processes such that
        \begin{enumerate}
            \item it coincides with \cref{stoch:elementary_integral} for elementary predictable processes, and
            \item it satisfies bounded convergence in probability, i.e.~if $(\phi_{n,t})_{t\in T,n\in\mathbb{N}}\subset\mathcal{E}$ is a uniformly bounded sequence that converges pointwise to a stochastic process $\rseq{\phi}$, then
            \begin{gather}
                \phi_n\cdot M_t\longrightarrow\phi\cdot M_t
            \end{gather}
            in probability.
        \end{enumerate}
    }

    The following property states necessary conditions on the \textbf{integrator} $\rseq{M}$ for all integrals to exist. This property (uniquely) defines the stochastic integral as in the integration theory of \textit{Daniell}.\index{integral!Daniell}\index[author]{Daniell}
    \begin{property}\index{integrator}
        If an adapted stochastic process $\rseq{M}$ is a well-behaved integrator, i.e.~the stochastic integral with respect to $\rseq{M}$ exists, then:
        \begin{enumerate}
            \item $\rseq{M}$ is right continuous in probability\footnote{For this notion of continuity, replace the convergence in \cref{topology:sequential_continuity} with convergence in probability.}, and
            \item the set
            \begin{gather}
                \label{stoch:bounded_elementary_set}
                \{\phi\cdot X_t\mid \phi\in\mathcal{E}\land|\phi|\leq1\}
            \end{gather}
            is bounded in probability for all $t\in T$.
        \end{enumerate}
    \end{property}
    The first item can actually be strengthened, since good integrators always admit a \cdlg modification. As such, all integrators will be assumed to be \cdlg from here on. It can also be shown that these necessary conditions are also sufficient.

    The following theorem gives an alternative characterization of the integrators satisfying the above property.
    \begin{theorem}[Bichteler--Dellacherie]\index{Bichteler--Dellacherie}
        The semimartingales are exactly the well-behaved integrators for the stochastic integral.
    \end{theorem}

    Boundedness is, of course, a rather strong property and it would be better to have a more general class of integrands. To this end, bounded convergence should be weakened to dominated convergence (cf.~\cref{measure:dominated_convergence_theorem}).
    \newdef{Integrability}{\index{integrable}
        Let $\rseq{M}$ be a semimartingale. The space $L^1(M)$ of $M$-integrable stochastic processes consists of those predictable processes $\rseq{\phi}$ such that if $(\phi_{t,n})_{t\in T,n\in\mathbb{N}}$ is a sequence of bounded predictable processes converging to 0 with $|\phi_{n,t}|\leq|\phi_t|$ for all $t\in T$ and $n\in\mathbb{N}$, then
        \begin{gather}
            \phi\cdot M_t\longrightarrow0
        \end{gather}
        in probability for all $t\in T$.
    }
    \begin{remark}
        An equivalent definition uses an approach that is similar to the definition of well-behaved integrators. $L^1(M)$ consists exactly of those predictable stochastic processes $\rseq{X}$ for which the set in \cref{stoch:bounded_elementary_set}, where $\rseq{\phi}$ is replaced by a bounded and $X$-dominated process, is bounded in probability for all $t\in T$.
    \end{remark}
    \begin{property}
        For the subclass of integrators belonging to Brownian motions, the space $L^1(M)$ can, equivalently, be described as the space of progressively measurable processes.
    \end{property}

    \begin{notation}[Differential]\index{differential}
        A very common notation in stochastic calculus is the differential notation (also common in applied sciences). An equation of the form
        \begin{gather}
            \dr Y = \alpha\,\dr X
        \end{gather}
        means that
        \begin{gather}
            Y_t = Y_0 + \alpha\cdot X_t
        \end{gather}
        for some constant $Y_0\in\mathbb{R}$. For the quadratic (co)variation, a potentially more confusing notation is sometimes used:
        \begin{gather}
            \begin{aligned}
                \dr X^2 &:= \dr[X]\,,\\
                \dr X\dr Y &:= \dr[X,Y]\,.
            \end{aligned}
        \end{gather}
    \end{notation}

    \newdef{It\^o process}{\index{It\^o!process}\index{SDE}\index{differential equation!stochastic}\label{stoch:ito_process}
        A stochastic process $\rseq{X}$ satisfying the following stochastic differential equation (SDE):
        \begin{gather}
            \label{stoch:ito_process_eq}
            \dr X = \mu\dr t + \sigma\dr W\,,
        \end{gather}
        where $\rseq{\sigma},\rseq{\mu}$ are adapted. Such processes are actually semimartingales.
    }

    \begin{property}
        The quadratic variation of the It\^o process in \cref{stoch:ito_process_eq} is given by
        \begin{gather}
            [X]_t = \Intt{0}{t}\mu_s^2\,ds\,.
        \end{gather}
    \end{property}

    \newdef{$\sigma$-martingale}{\index{martingale!$\sigma$-}
        An adapted stochastic process $\rseq{X}$ such that
        \begin{gather}
            X_t = \phi\cdot M_t
        \end{gather}
        for some predictable stochastic process $\rseq{\phi}$ and martingale $\rseq{M}$.
    }
    \begin{property}
        All (local) martingales are also $\sigma$-martingales.
    \end{property}

    \newdef{Admissible process}{\index{admissible!process}\label{stoch:admissible_process}
        Let $\rseq{M}$ be a semimartingale. A predictable process $\rseq{\phi}$ is said to be ($\lambda$-)admissible, where $\lambda\in\mathbb{R}^+$, with respect to $\rseq{M}$ if $\phi\cdot M_t\geq -\lambda$ for all $t\in\mathbb{R}^+$.
    }

    \newdef{Dol\'eans-Dade exponential}{\index{exponential!Dol\'eans-Dade}\label{stoch:stochastic_exponential}
        The \textbf{stochastic exponential} of a semimartingale $\rseq{M}$ is the unique (strong) solution of the stochastic differential equation
        \begin{gather}
            \dr X_t = X_{t^-}\,\dr M_t
        \end{gather}
        with initial value condition $X_0=1$.

        If $\rseq{M}$ is a.s.~continuous, the stochastic exponential is given by
        \begin{gather}
            \label{stoch:continuous_stochastic_exponential}
            \mathcal{E}(M)_t = \exp\left(M_t - M_0 - \frac{1}{2}[M]_t\right)\,.
        \end{gather}
        More generally, when continuity is not assumed, it is given by
        \begin{gather}
            \mathcal{E}(M)_t = \exp\left(M_t - M_0 - \frac{1}{2}[M]_t^c\right)\prod_{s\leq t}(1+\Delta M_s)\exp(-\Delta M_s)\,,
        \end{gather}
        where $[\cdot]^c$ denotes the continuous part of the quadratic variation.
    }
    \begin{property}[Stochastic logarithm]\label{stoch:stochastic_logarithm}\index{logarithm}
        The stochastic exponential (and its left-continuous version) of a semimartingale $\rseq{M}$ are strictly positive if and only if the jumps of $\rseq{M}$ are strictly greater than -1.

        In such cases, the exponential can be inverted to obtain the \textbf{stochastic logarithm}. This is given by
        \begin{gather}
            \mathcal{L}(X)_t = \frac{1}{X_-}\cdot X_t\,.
        \end{gather}
    \end{property}

\subsection{Properties}

    Note that $L^0$ is the set of equivalence classes of random variables that are almost surely equal. The consequence is that the stochastic process given by
    \begin{gather}
        \phi\cdot M_t \equiv \Intt{0}{t}\phi_s\,dM_s
    \end{gather}
    has sample paths that are not necessarily well defined. However, they admit well-behaved modifications.

    \begin{property}[Continuity]
        If $\tseq{M}$ is an a.s.~continuous semimartingale, then any stochastic integral with respect to $M$ is also a.s.~continuous.
    \end{property}

    Martingales can also be characterized in terms of the centrality of their stochastic integral. (This generalizes \cref{stoch:wiener_integral_central}.)
    \begin{property}[Centrality]
        An integrable, adapted stochastic process $\rseq{X}$ is a martingale if and only if
        \begin{gather}
            \expect{\Intt{0}{+\infty}\phi_s\,d\!X_s}=0
        \end{gather}
        for all $\rseq{\phi}\in\mathcal{E}$. If this only holds after replacing $=$ by $\geq$, then $\rseq{X}$ is a submartingale.
    \end{property}

    \begin{property}[Stability]
        If $\rseq{M}$ is a martingale and $\rseq{\phi}$ a bounded predictable process, then $\rseq{\phi\cdot M}$ is also a martingale.
    \end{property}

    \begin{property}[Change of variables]
        Let $\rseq{M}$ be a semimartingale and consider a stochastic process $\rseq{X}\in L^1(M)$. $Z_t := X\cdot M_t$ is an adapted stochastic process admitting a \cdlg modification and, moreover, is a semimartingale such that
        \begin{gather}
            \Intt{0}{t}\phi\,dZ = \Intt{0}{t}\phi X\,dM
        \end{gather}
        for all $t\in T$ and bounded, predictable processes $\rseq{\phi}$. Any \cdlgg, adapted process satisfying this property will be called `the' stochastic integral of $\rseq{X}$ with respect to $\rseq{M}$.

        Moreover, a predictable process $\rseq{Y}$ is $Z$-integrable if and only if
        \begin{gather}
            \Intt{0}{t}Y\,dZ = \Intt{0}{t}YX\,dM\,.
        \end{gather}
    \end{property}

    \begin{property}[Optional stopping]
        Consider a semimartingale $\rseq{M}$ and a stopping time $\tau$. If $\rseq{X}$ is an $M$-integrable process, it is also $M^\tau$-integrable and
        \begin{gather}
            \left(X\cdot M\right)^\tau = X\cdot M^\tau\,.
        \end{gather}
    \end{property}

    \begin{property}
        A predictable process is $M$-integrable for some semimartingale $\rseq{M}$ if and only if it is locally $M$-integrable. Moreover, a stochastic process is a semimartingale if and only if it is a semimartingale.

        This property also implies that all locally bounded predictable processes are integrable with respect to any semimartingale. In fact, for every \cdlgg, adapted stochastic process $\rseq{X}$, the left-limit process $(X_{t^-})_{t\in T}$ is integrable with respect to any semimartingale.
    \end{property}

    \begin{theorem}[Dominated convergence]\index{convergence!dominated}
        Let $(\phi_{t,n})_{t\in T,n\in\mathbb{N}}$ be a convergent sequence of predictable processes with limit $\rseq{\phi}$ and let $\rseq{M}$ be a semimartingale. If the sequence is dominated by an $M$-integrable stochastic process, then
        \begin{gather}
            \Intt{0}{t}\phi_n\,dM\overset{\text{ucp}}{\longrightarrow}\Intt{0}{t}\phi\,dM
        \end{gather}
        for all $t\in T$.
    \end{theorem}

    \begin{property}[Linearity]
        The set of semimartingales is a (real) vector space and, moreover, the stochastic integral is linear with respect to this structure.
    \end{property}

    The following formula should be compared to \cref{measure:integration_by_parts} for Lebesgue--Stieltjes integrals (an additional relation is given in the next section).
    \begin{formula}[Integration by parts]\index{integration!by parts}
        Let $\rseq{X},\rseq{Y}$ be semimartingales.
        \begin{gather}
            X_tY_t = X_0Y_0 + \Intt{0}{t}X_{s^-}\,dY_s + \Intt{0}{t}Y_{s^-}\,d\!X_s + [X,Y]_t
        \end{gather}
        In differential notation, this becomes:
        \begin{gather}
            \dr(XY) = X_-\dr Y + Y_-\dr X + \dr X\dr Y\,.
        \end{gather}
        Note that this formula could be used as an alternative definition of the quadratic variation process.
    \end{formula}

    \begin{formula}[Jump process]
        If $\rseq{X}$ is a semimartingale and $\rseq{P}\in L^1(X)$, then
        \begin{gather}
            \dr Y = P\,\dr X\implies \Delta Y = P\Delta X\,.
        \end{gather}
        Moreover, the continuity (resp.~predictability) of $\rseq{X}$ implies the continuity (resp.~predictability) of $\rseq{Y}$. Moreover,
        \begin{gather}
            \Delta[X,Y] = \Delta X\Delta Y\,.
        \end{gather}
    \end{formula}
    \begin{result}
        If $\rseq{M}$ is a semimartingale, then
        \begin{gather}
            \sum_{s\leq t}\Delta M_s^2\leq[M]_t<+\infty\,.
        \end{gather}
    \end{result}

    The following inequality should be compared to the Cauchy--Schwarz inequality (\cref{measure:schwarz_inequality}).
    \begin{formula}[Kunita--Watanabe inequality]\index{Kunita--Watanabe!inequality}
        Let $\rseq{X},\rseq{Y}$ be semimartingales and consider two stochastic processes $\rseq{\alpha},\rseq{\beta}$.
        \begin{gather}
            \Intt{0}{t}|\alpha_s\beta_s|\,|d[X,Y]_s| \leq \sqrt{\Intt{0}{t}\alpha_s^2\,d[X]_s\Intt{0}{t}\beta_s^2\,d[Y]_s}\,,
        \end{gather}
        where $|d[X,Y]_s|$ denotes the total variation measure (\cref{measure:total_variation}) and all integrals are Lebesgue--Stieltjes integrals (by \cref{section:stochastic_lebesgue_stieltjes}).
    \end{formula}

    \begin{result}[Brownian motion]\index{correlation}
        Let $\rseq{W},\rseq{\overline{W}}$ be standard Brownian motions. The Kunita--Watanabe inequality implies that
        \begin{gather}
            \Intt{0}{t}\alpha_s^2|d[W,\overline{W}]_s| \leq \Intt{0}{t}\alpha_s^2\,ds\,.
        \end{gather}
        By the Radon--Nikodym theorem~\ref{measure:radon_nikodym}, there exists a predictable process $\rseq{\rho}$, bounded by 1, such that
        \begin{gather}
            \dr W\dr\overline{W} = \rho\dr t\,.
        \end{gather}
        $\rseq{\rho}$ is called the \textbf{instantaneous correlation} of the Brownian motions.
    \end{result}

    An equivalent way of defining general stochastic integrals would be by mirroring the previous section on Wiener integrals through the following isometry.
    \begin{property}[It\^o isometry]\index{It\^o!isometry}\label{stoch:ito_isometry}
        Consider a local martingale $\rseq{M}$ and a predictable process $\rseq{\phi}$ such that
        \begin{gather}
            \expect{\Intt{0}{t}\phi^2_s\,d[M]_s}<+\infty\,.
        \end{gather}
        Then $\phi\in L^1(M)$ and 
        \begin{gather}
            \expect{\left(\phi\cdot M_t\right)^2} = \expect{\Intt{0}{t}\phi^2_s\,d[M]_s}\,.
        \end{gather}
    \end{property}

    \begin{property}[Ansel--Stricker]\index{Ansel--Stricker}
        Let $\rseq{M}$ be a local martingale and consider $X\in L^1(M)$. If $\rseq{X\cdot M}$ is uniformly bounded from below by an integrable random variable, then $\rseq{X\cdot M}$ is a local martingale and even a supermartingale.
    \end{property}

    \begin{theorem}[Girsanov]\index{Girsanov}\label{stoch:girsanov}
        Consider a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ and an a.s.~continuous semimartingale $\rseq{M}$. Moreover, let $\rseq{W}$ be a Brownian motion. If
        \begin{gather}
            M_t := \mathcal{E}(M)_t = \exp\left(\Intt{0}{t}M_s\,dW_s - \frac{1}{2}\Intt{0}{t}[M]_s\,ds\right)
        \end{gather}
        is an $\mathbb{F}$-martingale, then
        \begin{gather}
            \widetilde{W}_t := W_t - \Intt{0}{t}M_s\,ds
        \end{gather}
        is a Brownian motion with respect to the transformed measure $M_t\,dP$.
    \end{theorem}
    \begin{example}[It\^o process]\index{Novikov!condition}
        A specific case, which is often taken to be Girsanov's theorem, is given by considering the It\^o process $\dr X_t = \mu_t\dr t + \sigma_t \dr W_t$, where $\rseq{W}$ is a standard Brownian motion with respect to some base measure $P$. If the ratio $\eta_t := \mu_t/\sigma_t$ satisfies the \textbf{Novikov condition}
        \begin{gather}
            \expect{\exp\left(\frac{1}{2}\Intt{0}{t}|\eta_s|^2\,ds\right)}<+\infty
        \end{gather}
        for all $t\in\mathbb{R}^+$, then $M_t:=\mathcal{E}\left(\Intt{0}{t}\eta_s\,dW_s\right)$ is a martingale\footnote{This is ensured by the Novikov condition.} and
        \begin{gather}
            \widetilde{W}_t := W_t - \Intt{0}{t}\eta_s\,ds
        \end{gather}
        is a standard Brownian motion with respect to the transformed measure $M_t\dr P$. A generalization to higher dimensions is straightforward.
    \end{example}

    A more general statement is the following.
    \begin{theorem}
        Let $P,Q$ be (locally) equivalent measures on a filtered measurable space such that the associated Radon--Nikodym derivatives $\rseq{L}$ are continuous. If $\rseq{M}$ is an a.s.~continuous $P$-local martingale, the process
        \begin{gather}
            \dr\widetilde{M}_t := \dr M_t - \frac{1}{L_t}\dr\left[M,L\right]_t
        \end{gather}
        is an a.s.~continuous $Q$-local martingale. Moreover, the process $\rseq{L}$ can be written as a Dol\'eans-Dade exponential of a local martingale $\rseq{\xi}$ and $M_t-[M,\xi]_t$ is also a $Q$-local martingale.
    \end{theorem}
    \begin{result}
        The transformed process $\rseq{\widetilde{M}}$ will be a $Q$-local martingale if and only if $M$ and $L$ are orthogonal.
    \end{result}

\subsection{Lebesgue--Stieltjes integration}\index{integral!Lebesgue--Stieltjes}\label{section:stochastic_lebesgue_stieltjes}

    \begin{property}
        Let $\rseq{X}$ be a continuous stochastic process. If for each $t>0$, the $p$-variation\footnote{The stochastic process obtained by replacing the square in \cref{stoch:quadratic_variation_formula} by the power $p>0$.} converges in probability to a random variable taking values in $\mathbb{R}^+$ almost surely, then the $q$-variations for all $q<p$ vanish in probability, and the $q$-variations for all $q>p$ diverge in probability (on the event where the quadratic variation is nonzero).
    \end{property}
    By \cref{stoch:quadratic_variation}, the continuous, square-integrable martingales have a well-defined quadratic variation process. Then, by the property above, this means that their first variation diverges almost surely and that their higher variations are almost surely zero. This shows that it is impossible to obtain a well-defined integration theory with (square-integrable) martingales as integrators. However, in general, instead of looking at the martingales themselves, one can look at their quadratic variation process. These are continuous and increasing and, hence, are equal to their own first variation process. This allows one to define the Lebesgue--Stieltjes integral
    \begin{gather}
        I(\omega) := \Intt{0}{t}Y_s(\omega)\,d[X]_s(\omega)
    \end{gather}
    along sample paths. The following property shows that, in good cases, the stochastic integral and pathwise Lebesgue--Stieltjes integral coincide.
    \begin{property}
        Let $\rseq{M}$ be a semimartingale and a predictable process $\rseq{\phi}$. If
        \begin{gather}
            \Intt{0}{t}|\phi_s|\,|dM_s| < +\infty
        \end{gather}
        almost surely for all $t\in T$, where $|dM_s|$ denotes the total variation measure (\cref{measure:total_variation}), then $\rseq{\phi}\in L^1(M)$ and
        \begin{gather}
            \Intt{0}{t}\phi_s(\omega)\,dM_s(\omega) = \phi\cdot M_t(\omega)
        \end{gather}
        for all $t\in T$ and $\omega\in\Omega$.
    \end{property}

    \begin{formula}
        Let $\rseq{M}$ be a semimartingale and let $\rseq{X}$ be an FX process.
        \begin{gather}
            [M,X]_t = \Intt{0}{t}\Delta M_s\,d\!X_s = \sum_{s\leq t}\Delta M_s\Delta X_s\,,
        \end{gather}
        where the integral with respect to $X$ is a Lebesgue--Stieltjes integral. In particular, if either process is continuous, their quadratic covariation vanishes. This property is the reason why quadratic variations are a rare sight in ordinary calculus.
    \end{formula}
    \begin{result}
        Let $\rseq{M}$ be a semimartingale and let $\rseq{X}$ be an FX process.
        \begin{gather}
            M_tX_t = M_0X_0 + \Intt{0}{t}M_s\,d\!X_s + \Intt{0}{t}X_{s^-}\,dM_s\,,
        \end{gather}
        where the integral with respect to $X$ is, again, a Lebesgue--Stieltjes integral.
    \end{result}

\subsection{Representation theorems}\index{martingale!representation theorem}

    \begin{theorem}[Dudley]\index{Dudley}\label{stoch:dudleys_theorem}
        Let $\rseq{W}$ be a standard Brownian motion and consider its natural filtration $\mathbb{F}$. For every $\mathbb{F}_\infty$-measurable random variable $\xi$, there exists an $\mathbb{F}$-progressive process $\rseq{\phi}\in L^2(W)$ such that
        \begin{gather}
            \xi = \Intt{0}{+\infty}\phi_s\,dW_s\,.
        \end{gather}
    \end{theorem}

    \begin{theorem}[Martingale representation theorem]
        Let $\rseq{W}$ be a standard Brownian motion with its natural filtration $\mathbb{F}$. Every $\mathbb{F}$-local martingale $\rseq{X}$ can be written as
        \begin{gather}
            X_t = X_0 + \phi\cdot W_t
        \end{gather}
        for a unique predictable $\rseq{\phi}\in L^1_{\emph{loc}}(W)$.
    \end{theorem}
    This theorem can generalized in the setting of Giransov's theorem~\ref{stoch:girsanov} as follows. If $\rseq{W}$ is a standard Brownian motion with respect to a measure $P$ and $Q$ is (locally) equivalent to $P$, then every $Q$-local martingale $\rseq{M}$ can be written as
    \begin{gather}
        M_t = M_0 + \phi\cdot\widetilde{W}_t\,,
    \end{gather}
    where $\rseq{\phi}$ is $\mathbb{F}^W$-predictable and $\rseq{\widetilde{W}}$ is the martingale part of $W$ when regarded as a $Q$-semimartingale.

    The following theorem gives an orthogonal decomposition of local martingales.
    \begin{theorem}[Kunita--Watanabe]\index{Kunita--Watanabe}
        Let $\rseq{M}$ be a continuous $\mathbb{F}$-local martingale with respect to some filtration $\mathbb{F}$. Every other continuous $\mathbb{F}$-local martingale $\rseq{X}$ that vanishes at $t=0$ can be written as
        \begin{gather}
            X_t = N_t + \phi\cdot M_t
        \end{gather}
        where $\rseq{\phi}$ is predictable and $\rseq{N}$ is an $\mathbb{F}$-local martingale orthogonal to $M$.
    \end{theorem}

    Comparing the previous two statements, the question becomes when the orthogonal part $\rseq{N}$ is a constant.
    \begin{theorem}[Predictable representation theorem]\label{stoch:prp}
        Let $\rseq{M}$ be a continuous $\mathbb{F}$-local martingale with respect to a filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$ and consider its natural filtration $\mathbb{F}^M$. Any $\mathbb{F}^M$-local martingale $\rseq{X}$ can be decomposed as
        \begin{gather}
            X_t = X_0 + \phi\cdot M_t
        \end{gather}
        for some constant $X_0\in\mathbb{R}$ and $\mathbb{F}^M$-predictable process $\rseq{\phi}$ if and only if $P$ is extremal (\cref{calculus:extreme_point}) in the set of probability measures for which $M$ is a continuous, local martingale.
    \end{theorem}

    \begin{remark}[Generalization]
        More generally, a collection of $(\mathbb{F},P)$-local martingales (or even semimartingales) $\bigl\{\rseq{M^1},\ldots\rseq{M^d}\bigr\}$, for a general filtered probability space $(\Omega,\Sigma,\mathbb{F},P)$, is said to satisfy the (strong) predictable representation property (PRP) if every $(\mathbb{F},P)$-local\footnote{In fact, one can relax this to the existence of measure $Q$ (locally) equivalent to $P$.} martingale $\rseq{X}$ can be written as
        \begin{gather}
            X_t = X_0 + \symbf{\phi}\cdot\symbf{M}_t = X_0 + \sum_{i=1}^d\phi^i\cdot M^i_t
        \end{gather}
        for some $\mathbb{F}_0$-measurable function $X_0$ and $\mathbb{F}$-predictable process $\rseq{\symbf{\phi}}$ satisfying
        \begin{gather}
            \Intt{0}{t}\phi_s^{i,2}\,d[M]_s<+\infty
        \end{gather}
        for all $i\leq d$.
    \end{remark}

    \begin{remark}[Brownian motion]
        The martingale representation theorem in terms of Brownian motion can be recovered by noting that the Wiener measure is an extremal martingale law on the space $C(\mathbb{R}^+,\mathbb{R})$ by the L\'evy characterization of Brownian motion (\cref{stoch:levy_characterization}).
    \end{remark}

    Whereas stability under change of distribution was already treated above, the change of filtrations (refinement, in particular) will be treated here.
    \newdef{Immersion property}{\index{immersion!property}
        A refinement of filtered probability spaces $(\mathbb{F},P)\hookrightarrow(\mathbb{G},P)$ is said to satisfy the immersion property if every $(\mathbb{F},P)$-martingale is also a $(\mathbb{G},P)$-martingale. A corollary of this property is that also all $(\mathbb{F},P)$-semimartingales are $(\mathbb{G},P)$-semimartingales.
    }

    \begin{property}\label{stoch:prp_refinement}
        If $\rseq{\symbf{M}}$ satisfies the PRP with respect to $(\mathbb{F},P)$, then $(\mathbb{F},Q)\hookrightarrow(\mathbb{G},Q)$ satisfies the immersion property for all probability measures $Q$ (locally) equivalent to $P$, for which $M$ is a $(\mathbb{G},Q)$-local martingale.
    \end{property}

    A converse, negative result is the following.
    \begin{property}
        Let $\rseq{\symbf{M}}$ satisfy the PRP with respect to $(\mathbb{F},P)$. If the refinement $(\mathbb{F},P)\hookrightarrow(\mathbb{G},P)$ satisfies $\mathbb{G}_0=\{\emptyset,\Omega\}$, then $\symbf{M}$ does not satisfy the PRP with respect to $(\mathbb{G},P)$.
    \end{property}

\section{Stochastic differential equations}\index{SDE}

    \begin{formula}[It\^o lemma]\index{It\^o!lemma}
        Consider an It\^o process $\rseq{X}$:
        \begin{gather}
            \dr X = \mu\dr t + \sigma\dr W\,.
        \end{gather}
        For $f\in C^2(\mathbb{R}^2,\mathbb{R})$, one has
        \begin{gather}
            \dr f(t,X) = \left(\pderiv{f}{t}+\mu\pderiv{f}{x}+\mpderiv{2}{f}{x}\right)\dr t + \sigma\pderiv{f}{x}\dr W\,.
        \end{gather}
        This also implies that $f(t,X)$ is again an It\^o process.
        
        More generally, consider a $d$-dimensional continuous semimartingale $\rseq{X}$ as a function $g\in C^2(\mathbb{R}^d,\mathbb{R})$.
        \begin{gather}
            \dr f(X) = \pderiv{f}{x^i}(X)\dr X^i + \frac{1}{2}\frac{\partial^2f}{\partial x^i\partial x^j}g(X)\dr[X^i,X^j]\,.
        \end{gather}
        If $X$ is not continuous, a correction has to be applied:
        \begin{gather}
            \dr f(X) = \pderiv{f}{x^i}(X_-)\,\dr X^i + \frac{1}{2}\frac{\partial^2f}{\partial x^i\partial x^j}g(X)\,\dr[X^i,X^j]^c + \left(\Delta f(X) - \pderiv{f}{x^i}(X_-)\Delta X^i\right)\,.
        \end{gather}
    \end{formula}

\section{Markov processes}

    \newdef{Markov process}{\index{Markov!process}
        A Markov process (or chain) is a stochastic process $\tseq{X}$ adapted to a filtration $\tseq{\mathbb{F}}$ such that
        \begin{gather}
            \Prob(X_t\mid\mathbb{F}_s) = \Prob(X_t\mid X_s)
        \end{gather}
        for all $t,s\in T$. For discrete-time processes, the first-order Markov chains are the most common. These satisfy
        \begin{gather}
            \Prob(X_t\mid X_{t-1},\ldots,X_{t-r}) = \Prob(X_t\mid X_{t-1})
        \end{gather}
        for all $t,r\in\mathbb{N}$.
    }
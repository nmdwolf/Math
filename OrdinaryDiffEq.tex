\chapter{Ordinary differential equations}
\section{Boundary conditions}\index{boundary!conditions}
	Unigue solutions of a differential equation are obtained by supplying additional conditions. These are called boundary conditions.
    
    \subsection{Periodic boundary conditions}\index{periodic!boundary condition}
    	Periodic boundary conditions are conditions of the following form:
    	\begin{equation}
			\label{diffeq:conditions:periodic}
            y(x) = y(x + \varphi)
		\end{equation}
        
        \noindent By induction it follows that for every $n$:
        \begin{equation}
			\label{diffeq:conditions:periodic_n}
            y(x) = y(x + n\varphi)
		\end{equation}
        
	\subsection{Dirichlet boundary conditions}\index{Dirichlet!boundary condition}
    	Dirichlet boundary conditions are conditions of the following form:
    	\begin{equation}
			\label{diffeq:conditions:dirichlet}
            y(x) = f(x)\qquad,\qquad x\in\partial\Omega
		\end{equation}
        where $\Omega$ is the domain of the problem.
        
        \begin{remark}
            When $y$ is a function of multiple variables, $\alpha$ can be a function as well. For example (in spherical coordinates: $\rho, \phi, \theta$):
            \begin{equation}
                \label{diffeq:conditions:dirichlet_multi}
                y(x, \phi, \theta) = \alpha(\phi, \theta)
            \end{equation}
		\end{remark}
        
	\subsection{Neumann boundary conditions}\index{Neumann!boundary condition}
    	Neumann boundary conditions are conditions of the following form:
    	\begin{equation}
			\label{diffeq:conditions:neumann}
            y'(a) = \alpha
		\end{equation}
        
        \begin{remark}
            When $y$ is a function of multiple variables, we obtain the following form (where $S$ is the boundary of the domain and $\hat{n}$ a normal vector to this boundary):
            \begin{equation}
                \label{diffeq:conditions:neumann_multi}
                \pderiv{y}{\hat{n}}(\vec{x}) = f(\vec{x})\qquad,\qquad\vec{x}\in S
            \end{equation}
		\end{remark}
        
\section{First order ODE's}
	\newformula{First order ODE}{
        \begin{equation}
            \label{diffeq:first_order_ODE}
            \boxed{y'(t) + a(t)y(t) = R(t)}
        \end{equation}
        If the function $R(t)$ is identically zero, then the ODE is said to be \textbf{homogenous}.
    }
    \begin{theorem}
		Let $U\subseteq\mathbb{R}$ be an open set. Let the functions $a(t), R(t):U\rightarrow\mathbb{R}$ be continuous. The solutions $\varphi(t):U\rightarrow\mathbb{R}$ of equation \ref{diffeq:first_order_ODE} are given by:
        \begin{equation}
			\label{diffeq:first_order_general_solution}
            \boxed{\varphi(t) = e^{-\int a(t)dt}\left(c + \int R(t)e^{\int a(t)dt}dt\right)}
		\end{equation}
        where $c$ is a constant.
	\end{theorem}
        
\section{Second order ODE's}
	\newformula{Second order ODE}{
        \begin{equation}
            \label{diffeq:second_order_ODE}
            \boxed{y''(t) + a(t)y'(t) + b(t)y(t) = R(t)}
        \end{equation}
    }
    \newformula{Homogeneous second order ODE}{
        \begin{equation}
            \label{diffeq:homogeneous_second_order_ODE}
            y''(t) + a(t)y'(t) + b(t)y(t) = 0
        \end{equation}
    }
    
    \subsection{General solution}
    	\begin{formula}
			Let $\varphi:U\rightarrow\mathbb{R}$ be a nowhere zero solution of the homogeneous equation \ref{diffeq:homogeneous_second_order_ODE}. The general solution of equation \ref{diffeq:second_order_ODE} is then given by:
            \begin{equation}
				\label{diffeq:second_order_general_solution}
                \boxed{y(t) = c_1\ \varphi +  c_2\ \varphi\int\stylefrac{e^{-\int a}}{\varphi^2} + \psi_0}
			\end{equation}
            where $\psi_0$ is a particular solution of equation \ref{diffeq:second_order_ODE}.
		\end{formula}
        
        \begin{theorem}
			Let $\psi_0$ be a solution of equation \ref{diffeq:second_order_ODE}. The set of all solutions is given by the affine space:
            \begin{equation}
				\left\{\psi_0 + \chi\text{ : $\chi$ is a solution of the homogeneous equation \ref{diffeq:homogeneous_second_order_ODE}}\right\}
			\end{equation}
		\end{theorem}
        \begin{theorem}\index{Wronskian}
			Two solutions of the homogeneous equation \ref{diffeq:homogeneous_second_order_ODE} are independent if the wronskian is nonzero:
            \begin{equation}
            	\label{diffeq:wronskian}
				W\left(\varphi_1(x), \varphi_2(x)\right) = \left|
                \begin{array}{cc}
					\varphi_1(x)&\varphi_2(x)\\
                    \varphi_1'(x)&\varphi_2'(x)
				\end{array}
                \right|
                \neq 0
			\end{equation}
		\end{theorem}
        
        \newformula{Abel's identity}{\index{Abel!differential equation identity}
        	An explicit formula for the wronskian is given by:
        	\begin{equation}
				\label{diffeq:abels_identity}
                \boxed{W(x) = W(x_0)\exp\left(-\int^x_{x_0}a(x')dx'\right)}
			\end{equation}
        }        

	\subsection{Constant coefficients}
    	\begin{theorem}
			A map $\varphi:U\rightarrow \mathbb{C}$ is a complex solution of equation \ref{diffeq:homogeneous_second_order_ODE} if and only if $Re\{\varphi\}$ and $Im\{\varphi\}$ are real solutions of equation \ref{diffeq:homogeneous_second_order_ODE}.
		\end{theorem}
    
    	\newformula{Characteristic equation}{\index{characteristic!equation}
        	When having an ODE of the form\footnotemark\ :
            \begin{equation}
              \label{diffeq:homogeneous_2_ODE_constant_coeff}
              y''(t) + py'(t) + qy(t) = 0
            \end{equation}
            \footnotetext{Any other form of homogeneous second order ODE's with constant coefficients can be rewritten in this form.}
            where $p$ and $q$ are constants, we define the characteristic equation as follows:
            \begin{equation}
				\label{diffeq:characteristic_equation}
                \lambda^2 + p\lambda + q = 0
			\end{equation}
            This polynomial equation generally\footnotemark\ has two distinct (complex) roots $\lambda_1$ and $\lambda_2$.
            From these roots we can derive the solutions of equation \ref{diffeq:homogeneous_2_ODE_constant_coeff} using the following rules ($c_1$ and $c_2$ are constants):
            
            \begin{itemize}
				\item $\lambda_1 \neq \lambda_2$, $\lambda_1$ and $\lambda_2 \in \mathbb{R}$: $y(t) = c_1\ e^{\lambda_1t} + c_2\ e^{\lambda_2t}$
                \item $\lambda_1 = \lambda_2$: $y(t) = c_1\ e^{\lambda t} + c_2\ te^{\lambda t}$
                \item $\lambda_1 = \lambda_2^*$, where $\lambda_1 = a + ib$: $y(t) = c_1\ e^{at}\cos(bt) + c_2\ e^{at}\sin(bt)$
			\end{itemize}
        }
        \footnotetext{See theorem \ref{linalgebra:fundamental_theorem_of_algebra}\ ("Fundamental theorem of algebra").}
        	
            
	\subsection{Method of Frobenius}
    	\newformula{Method of Frobenius}{\index{Frobenius!series}
        	To find a solution of the homogeneous equation \ref{diffeq:homogeneous_second_order_ODE} we assert a solution of the form:
            \begin{equation}
            	\label{diffeq:frobenius_power_series}
				\boxed{y(x) = \sum_{i=0}^\infty a_i(x-x_0)^{i+k}}
			\end{equation}
            where $k$ is a constant.
        }
        \newdef{Indicial equation}{\index{indicial equation}
        	After inserting the solution \ref{diffeq:frobenius_power_series} into the homogeneous equation \ref{diffeq:homogeneous_second_order_ODE} we obtain\footnotemark\ an equation of the form $\sum_{i=n}^\infty H_i(k)x^i= 0$ where $n\in\mathbb{R}$ and $H_i(k)$ is a polynomial in $k$. This means that for every $i$ we obtain an equation of the form $H_i(k) = 0$, due to the independence of polynomial terms. The equation for the lowest power will be quadratic in $k$ and it is called the indicial equation.
        }
        \footnotetext{It is important to 'sync' the power of all terms in order to obtain one 'large' coefficient.}
        
        \begin{theorem}
        	The indicial equation generally has two roots $k_1, k_2$. The following possibilities arise:
            \begin{itemize}
				\item $k_1 = k_2$: Only one solution will be found with the method of Frobenius (another one can be found as in the second term of equation \ref{diffeq:second_order_general_solution})
                \item $k_1 - k_2 \in\mathbb{Z}$: A second independent solution might be obtained using this method. If not, then a second solution can be found as mentioned in the previous case.
                \item $k_1 - k_2 \not\in\mathbb{Z}$: Two independent solutions can be found using this method.
			\end{itemize}
		\end{theorem}
        
        \begin{theorem}[Fuch's theorem]\index{Fuch!Theorem}
        	If $a(z)$ and $b(z)$ are analytic at $z=z_0$ then the general solution $y(z)$ can be expressed as a Frobenius' series.
		\end{theorem}
        
\section{Sturm-Liouville theory}\index{Sturm-Liouville theory}

	\newdef{Sturm-Liouville boundary value problem}{
    	The following ODE,\newline subject to mixed boundary conditions, is called a Sturm-Liouville boundary value problem:
        \begin{equation}
			\label{ode:Sturm_Liouville}
            \boxed{\deriv{}{x}\left[p(x)\deriv{y}{x}\right] + \left[g(x) + \lambda r(x)\right]y(x) = 0}
		\end{equation}
        where $p(x), q(x)$ and $r(x)$ are continuous on $a\leq x\leq b$. $p(x)\in C^1(a,b)$ with $p(x)<0$ or $p(x)>0$ for $a\leq x\leq b$. $r(x)\geq0$ or $r(x)\leq0$ for $a\leq x\leq b$ and $r(x)$ is not identically zero on any subinterval.\par
        The boundary conditions are given by
        \begin{equation}
			\left\{
            \begin{array}{c}
				\alpha_1y(a) + \beta_1y'(a) = 0\\
                \alpha_2y(b) + \beta_2y'(b) = 0
			\end{array}
            \right.
		\end{equation}
        where at least one of the constants $\alpha_1,\alpha_2,\beta_1$ or $\beta_2$ is non-zero.
    }
    
    \begin{formula}
    	The solutions are of the form
    	\[
    		y(x) = c_1u_1(\lambda;x) + c_2u_2(\lambda;x)
	    \]
        Only for certain values of $\lambda$ will these solutions $(u_1,u_2)$ be non-trivial. The values of $\lambda$ for which the solutions are non-trivial are called \textbf{eigenvalues} and the associated solutions are called \textbf{eigenfunctions}. Substituting this form in the boundary conditions gives the following determinant condition for non-trivial solutions, which is also the defining equation of the eigenvalues $\lambda$:
        \begin{equation}
			\left|
            \begin{array}{cc}
				\alpha_1u_1(a;\lambda) + \beta_1u_1'(a;\lambda)&\alpha_1u_2(a;\lambda) + \beta_1u_2'(a;\lambda)\\
                \alpha_1u_1(b;\lambda) + \beta_1u_1'(b;\lambda)&\alpha_1u_2(b;\lambda) + \beta_1u_2'(b;\lambda)
			\end{array}
            \right|=0
		\end{equation}
        The independent eigenfunctions can be found by substituting the found eigenvalues in the ODE \ref{ode:Sturm_Liouville}.
    \end{formula}

    \begin{definition}[Self-adjoint form]
		The SL-problem can be rewritten as \[\left[\hat{\mathcal{L}} + \lambda r(x)\right]y(x) = 0\]The operator $\hat{\mathcal{L}} = \deriv{}{x}\left[p(x)\deriv{}{x} + g(x)\right]$ is called the self-adjoint form. Now consider the general linear ODE
        \begin{equation}
			\left[a_2(x)\mderiv{2}{}{x} + a_1(x)\deriv{}{x} + a_0(x)\right]y(x) = 0
		\end{equation}
        This equation can be rewritten in a self-adjoint form by setting:
        \begin{equation}
			p(x) = e^{\int\frac{a_1}{a_2}dx}\qquad\text{and}\qquad g(x) = \stylefrac{a_0}{a_2}e^{\int\frac{a_1}{a_2}dx}
		\end{equation}
	\end{definition}
    
    \begin{property}
		The eigenfunctions corresponding to distinct eigenvalues are orthogonal with respect to the weight function $r(x)$.
	\end{property}

	\begin{theorem}[Oscillation theorem]\index{oscillation theorem}
		Let $f_n$ be the $n^{th}$ eigenfunction of a Sturm-\newline Liouville boundary condition problem. Then $f_n$ has precisely $n-1$ roots.
	\end{theorem}

\chapter{Partial differential equations}
\section{General linear equations}
	\newformula{Cramer's rule}{\index{Cramer's rule}
    	Let $Ax = b$ be a system of linear equations where the matrix $A$ has a nonzero determinant. Then Cramer's rule gives a unique solution where the unknowns are given by;
        \begin{equation}
			\label{diffeq:cramers_rule}
            x_i = \stylefrac{\det(A_i)}{\det(A)}
		\end{equation}
        where $A_i$ is the matrix obtained by replacing the $i^{th}$ column of $A$ by the column matrix $b$.
    }
    
    \newdef{Characteristic curve}{\index{characteristic!curve}
    	Curve along which the highest order partial derivatives are not uniquely defined.
    }
    
\section{First order PDE}

	\newformula{First order quasilinear PDE}{
    	\begin{equation}
        	\label{pde:first_order_pde}
			\boxed{P(x, y, z)\pderiv{z}{x} + Q(x, y, z)\pderiv{z}{y} = R(x, y, z)}
		\end{equation}
    }
    
    \newformula{Characteristic curve}{
    	The PDE will have no unique solution if
    	\begin{equation}
			\left|
            \begin{array}{cc}
				P&Q\\
                dx&dy
			\end{array}
            \right|=0
		\end{equation}
        and will have a non-unique solution if
        \begin{equation}
			\left|
            \begin{array}{cc}
				P&R\\
                dx&dz
			\end{array}
            \right|=0
		\end{equation}
        The characteristic curves are thus defined by $\frac{dx}{P} = \frac{dy}{Q}$ and along thse curves the condition $\frac{dx}{P} = \frac{dz}{R}$ should hold to ensure a solution.
    }
    
    \begin{theorem}
		The general solution of \ref{pde:first_order_pde} is implicitly given by $F(\xi,\eta) = 0$ with $F(\xi, \eta)$ an arbitrary differentiable function where $\xi(x, y, z) = c_1$ and $\eta(x, y, z) = c_2$ are solutions of the equation
        \begin{equation}
			\stylefrac{dx}{P} = \stylefrac{dy}{Q} = \stylefrac{dz}{R}
		\end{equation}
        where $c_1, c_2$ are constants which are fixed by boundary conditions.
	\end{theorem}
    \remark{Looking at the defining equations of the characteristic curve, it is clear that these fix the general solution of the PDE.}
    
\section{Characteristics}
	\newformula{Second order quasilinear PDE}{
    	Consider the following pseudolinear differential equation for the function $u(x, y)$:
        \begin{equation}
        	\label{pde:general_2order_pde}
			R(x,y)u_{xx} + S(x,y)u_{xy} + T(x, y)u_{yy} = W(x, y, u, p, q)
		\end{equation}
        where $p = u_x$ and $q = u_y$.
    }
    
    \newformula{Equation of characteristics}{
    	Consider the following differential equations:
        \begin{equation}
			\left\{
            \begin{array}{c}
				u_{xx}dx + u_{xy}dy = dp\\
                u_{xy}dx + u_{yy}dy = dq\\
			\end{array}
            \right.
		\end{equation}
        According to Cramer's rule \ref{diffeq:cramers_rule} these equations, together with the PDE \ref{pde:general_2order_pde}, give the following condition for the characteristic curves:
        \begin{equation}
			\left|
            \begin{array}{ccc}
				R(x, y)&S(x, y)&T(x, y)\\
                dx&dy&0\\
                0&dx&dy\\
			\end{array}
            \right|=0
		\end{equation}
        which is equivalent to following equation:
        \begin{equation}
        	\label{pde:defining_equation_characteristic_curves}
			\boxed{R\left(\deriv{y}{x}\right)^2 - S\left(\deriv{y}{x}\right) + T = 0}
		\end{equation}
    }
    
    \newdef{Types of characteristics}{
    	Equation \ref{pde:defining_equation_characteristic_curves} is quadratic in $\deriv{y}{x}$. If this equation has two distinct real roots then the PDE is said to be \textbf{hyperbolic}. If the equation has only one root, the PDE is said to be \textbf{parabolic}. In the remaining case, where the equation has two distinct complex roots, the PDE is said to be \textbf{elliptic}.
    }
    
    \newformula{Canonical form}{
    	Consider the general change of variables $\xi = \xi(x, y)$, $\eta = \eta(x, y)$ and $z=\zeta$. With this change, the PDE \ref{pde:general_2order_pde} becomes:
        \begin{equation}
			A(\xi_x,\xi_y)\mpderiv{2}{\zeta}{\xi} + 2B(\xi_x,\xi_y,\eta_x,\eta_y)\stylefrac{\partial^2\zeta}{\partial\xi\partial\eta} + A(\eta_x,\eta_y)\mpderiv{2}{\zeta}{\eta} = F(\xi,\eta,\zeta,\zeta_\xi,\zeta_\eta)
		\end{equation}
        where $A(a,b) = Ra^2 + Sab + Tb^2$ and $B = R\xi_x\eta_x + \frac{1}{2}S(\xi_x\xi_y+\eta_x\eta_y) + Tbd$.
        Solving the quadratic equation \ref{pde:defining_equation_characteristic_curves} will lead to the following three canonical forms:
        \begin{itemize}
			\item \textbf{hyperbolic PDE}: With the solutions $\lambda_1(x, y)$ and $\lambda_2(x, y)$ the defining equation can be separated into two ODE's
            \[
            	\left(\deriv{y}{x} + \lambda_1(x, y)\right)\left(\deriv{y}{x} + \lambda_2(x, y)\right) = 0
            \]
            It is clear that the solutions of these ODE's are also roots of the $A(a,b)$ coefficients such that the change of variables $\xi = f_1(x, y)$ and $\eta = f_2(x, y)$ gives the canonical hyperbolic form
            \begin{equation}
            	\label{pde:hyperbolic_canonical_form}
				\boxed{\stylefrac{\partial^2\zeta}{\partial\xi\partial\eta} = H(\xi,\eta,\zeta,\zeta_\xi,\zeta_\eta)}
			\end{equation}
            where $H = \stylefrac{F}{2B}$.
            
            \item \textbf{parabolic PDE}: As in the hyperbolic case we perform the change of variable $\xi = f(x, y)$, however there is only one root of the defining equation so the second variable can be chosen randomly, yet indepedent of $f_1(x, y)$. From the condition $S^2 + 4RT = 0$ it is alos possible to derive the condition that $B(\xi_x,\xi_y\eta_x\eta_y) = 0$ and $A(\eta_x,\eta_y)\neq0$. This gives the parabolic canonical form
            \begin{equation}
            	\label{pde:parabolic_canonical_form}
				\boxed{\mpderiv{2}{\zeta}{\eta} = G(\xi,\eta,\zeta,\zeta_\xi,\zeta_\eta)}
			\end{equation}
            where $G = \stylefrac{F}{A(\eta_x,\eta_y)}$.
            
            \item \textbf{elliptic PDE}: Again there are two (complex) roots, so the $A$ coefficients will dissappear. Writing $\xi = \alpha + i\beta$ and $\eta = \alpha - i\beta$ gives the following (real) equation
            \[
            	\stylefrac{\partial^2\zeta}{\partial\xi\partial\eta} = \frac{1}{4}\left(\mpderiv{2}{\zeta}{\alpha} + \mpderiv{2}{\zeta}{\beta}\right)
            \]
            Substituting this in the hyperbolic case results in the following elliptic canonical form
            \begin{equation}
				\label{pde:elliptic_canonical_form}
                \boxed{\mpderiv{2}{\zeta}{\alpha} + \mpderiv{2}{\zeta}{\beta} = K(\alpha,\beta,\zeta,\zeta_\alpha,\zeta_\beta)}
			\end{equation}
		\end{itemize}
    }
    
    \begin{theorem}[Maximum principle]\index{maximum!principle}
    	\label{pde:theorem:maximum_principle}
		Consider a PDE of the parabolic or elliptic type. The maximum of the solution on a domain is to be found on the boundary of that domain. 
	\end{theorem}
    
\subsection{D'Alemberts method}

	Consider the wave equation\index{wave!equation}
    \begin{equation}
    	\label{pde:wave_equation}
		\mpderiv{2}{u}{x}(x, t) = \stylefrac{1}{c^2}\mpderiv{2}{u}{t}(x, t)
	\end{equation}
    By applying the method from previous subsection, it is clear that the characteristics are given by
    \begin{equation}
		\xi = x + ct\qquad\text{and}\qquad \eta = x - ct
	\end{equation}
    Furthermore, it follows that the wave equation is a hyperbolic equation which can be rewritten in the canonical form:
    \begin{equation}
		\label{pde:canonical_wave_equation}
        \stylefrac{\partial^2u}{\partial\xi\partial\eta}(\xi,\eta) = 0
	\end{equation}
    Integration with respect to $\xi$ and $\eta$ and rewriting the solution in terms of $x$ and $t$ gives
    \begin{equation}
    	\label{pde:wave_solution}
		u(x, t) = f(x+ct) + g(x-ct)
	\end{equation}
    where $f, g$ are arbitrary functions. This solution represents a superposition of a left-moving wave and a right-moving wave.\par
    
    Now consider the wave equation subject to the general conditions
    \begin{equation}
		u(x, 0) = v(x)\qquad\text{and}\qquad \pderiv{u}{t}(x, 0) = q(x)
	\end{equation}
    By applying these conditions to the general solution \ref{pde:wave_solution} it can be shown that the general solution subject to the given boundary conditions is given by:
    \begin{equation}
		\label{pde:dalembert_solution}
        \boxed {u(x, t) = \frac{1}{2}\left[v(x+ct) + v(x-ct)\right] + \frac{1}{2c}\int_{x-ct}^{x+ct}q(z)dz}
	\end{equation}
    
    \remark{Because $x$ is not bounded, this solution is only valid for infinite strings.}

\section{Separation of variables}
	\sremark{We begin this section with the remark that solutions obtained by this method are generalized Fourier series, which tend to converge rather slowly. For numerical purposes, other techniques are recommended. However, the series solutions often give a good insight in the properties of the obtained solutions.}

\subsection{Cartesian coordinates}
	\begin{method}[Separation of variables]
		Let $\hat{\mathcal{L}}$ be the operator associated with a partial diferential equation such that $\hat{\mathcal{L}}u(\vec{x}) = 0$ where $\vec{x} = (x_1,...,x_n)$ is the set of variables. A useful method is to propose a solution of the form
        \[
        	u(\vec{x}) = \prod_{i=1}^nu_i(x_i)
        \]
        By substituting this form in the PDE and using (basic) algebra it is sometimes (!!) possible to reduce the partial differential equation to a system of $n$ ordinary differential equations.
	\end{method}
    
    \begin{example}
		Consider following PDE:
        \begin{equation}
			\pderiv{u}{t} - a\mpderiv{2}{u}{x} = 0
		\end{equation}
        Substituting a solution of the form $u(x, t) = X(x)T(t)$ gives
        \[
        	X(x)\deriv{T(t)}{t} - aT(t)\mderiv{2}{X(x)}{x} = 0
        \]
        which can be rewritten as (the arguments are dropped for convenience)
        \[
        	\stylefrac{1}{aT}\deriv{T}{t} = \stylefrac{1}{X}\mderiv{2}{X}{x}
        \]
        As both sides are independent, it is clear that they are equal to a constant, say $\lambda$. This results in the following system of ordinary differential equations:
        \[
        	\left\{
            \begin{array}{ccc}
				X''(x) &=& \lambda X(x)\\
                T'(t) &=& a\lambda T(t)
			\end{array}
            \right.
        \]
	\end{example}

\subsection{Dirichlet problem}\index{Dirichlet!problem}
	The (interior) Dirichlet problem\footnotemark\ is the problem of finding a solution to a PDE in a finite region, given the value of the function on the boundary of the region. The uniqueness of this solution can be proven with the maximum principle \ref{pde:theorem:maximum_principle} if the PDE is of the elliptic kind (!!) such as the Laplace equation\footnotemark.
    \footnotetext{Think of the Dirichlet boundary condition \ref{diffeq:conditions:dirichlet}.}
    \footnotetext{The Dirichlet boundary problem originated with the Laplace equation.}
	
    \proof{
    	Let $\phi,\psi$ be two solutions of the interior Dirichlet problem. Due to the linearity both $\psi-\phi$ and $\phi-\psi$ are solutions too (without applying the boundary conditions). According to the maximum principle, these solutions achieve their maximum on the boundary of the domain. Furthermore, due to the Dirichlet boundary conditions, $\phi(x)=\psi(x)$ for all $x\in\partial\Omega$. Combining these two facts gives $\max(\psi-\phi) = \max(\phi-\psi) = 0$ or alternatively $\psi\leq\phi$ and $\phi\leq\psi$ in the complete domain. Which means that $\phi=\psi$ in the complete domain.\qed
    }
    
    \par There is also an exterior Dirichlet problem, where one has to find the solution of the PDE, given the boundary conditions, outside of the boundary.

\section{Non-homogeneous boundary conditions}
	\newformula{Non-homogeneous boundary condition}{
    	\begin{equation}
			\label{pde:non_homogeneous_boundary_condition}
            \alpha u(a,t) + \beta \pderiv{u}{x}(a, t) = h(t)
		\end{equation}
        When $h(t)$ is identically zero, the boundary condition becomes homogeneous.
    }

	\newmethod{Steady-state solution}{\index{steady-state!method for boundary conditions}
    	Assume that the function $h(t)$ is constant. In this case it is useful to rewite the solution as \[u(x, t) = v(x) + w(x, t)\] The 'time'-independent function is called the steady-state solution and the function $w(x, t)$  represents the deviation of this steady-state scenario.\newline
        As the PDE is linear, we require the partial solutions $v(x)$ and $w(x, t)$ to individually satisfy the equation. Furthermore we require the function $v(x)$ to also satisfy the given non-homogeneous boundary conditions. This results in $w(x, t)$ being the solution of a homogeneous PDE with homogeneous boundary conditions. This can be seen in the following proof:
    }
    \proof{
    	Assume a boundary condition of the form $\alpha u(a, t) + \beta\pderiv{u}{x}(a,t) = u_0$. Due to the requirements, we also have $\alpha v(a) + \beta\pderiv{v}{x}(a) = u_0$. Combining these two conditions gives
        \[
        	\alpha\left[v(a) + w(a,t)\right] + \beta\left[\pderiv{v}{x}(a) + \pderiv{w}{x}(a,t)\right] = \alpha v(a) + \beta\pderiv{v}{x}(a)
        \]
        which can be reduced to
        \[
        	\alpha w(a,t) + \beta\pderiv{w}{x}(a, t) = 0
        \]
        The steady-state deviation $w(x, t)$ thus satisfies homogeneous boundary conditions.\qed
    }
    
    \begin{method}
		If the function $h(t)$ is not a constant, we use a different method. Rewrite the solution as $u(x, t) = v(x, t) + w(x, t)$ where we only require $v(x, t)$ to be some function that satisfies the boundary conditions (and not the PDE)\footnotemark. This will lead to $w(x, t)$ satisfying the homogeneous boundary conditions as in the previous method. After substituting the function $v(x, t)$ in the PDE, we obtain a differential equation for $w(x, t)$ but it can be non-homogeneous.
	\end{method}
    \footnotetext{As there are infinitely many possible functions that satisfy the boundary conditions, the best choice for $v(x, t)$ is the one that makes the equation for $w(x, t)$ as simple as possible.}
    
    \begin{method}
		A third, sometimes useful, method is the following. If the problem consists of 3 homogeneous and 1 non-homogeneous boundary condition then the problem can be solved by first applying the homogenous conditions to restrict the values of the separation constant and obtain a series expansion. Afterwards the obtained series can be fitted to the non-homogeneous condition to obtain the final remaining coefficients.\par
        If there is more than 1 non-homogeneous boundary condition, the method can be extended. Let there be $j$ boundary conditions. Rewrite the general solution as $u(x, t) = \sum_{i=1}^jv_j(x, t)$ where $v_j(x, t)$ satisfies the $j^{th}$ non-homogeneous condition and the homogeneous versions of the other conditions. This way the general solution still satisfies all conditions and the first part of the method can be applied to all functions $v_j(x, t)$ to obtain a series expansion.
	\end{method}
    
    \begin{method}[Non-homogeneous PDE]\index{PDE!non-homogeneous}
		A possible way to solve non-homogeneous second order partial differential equations of the form
        \[
        	\hat{\mathcal{L}}u(x, t) = f(x, t)
        \]
        given a set of homogeneous boundary conditions and inital value conditions $w(x, 0) = \psi(x)$, is the following, where we assume all involved functions to be expandable as a generalized Fourier series:
        \begin{enumerate}
			\item Solve the homogeneous version of the PDE, which will result in a series expansion $\sum_nw_n(t)e_n(x)$, where $e_n(x)$ are a complete set of eigenfunctions in the variable $x$. This solution should satisfy the (homogeneous\footnotemark) boundary conditions.
            \item Expand the function $f(x, t)$ in the same way as $u(x, t)$. The coefficients $f_n$ can be found by using the orthogonality realtions of the functions $e_n(x)$.
            \item Inserting these expansions in the original PDE and rewriting the equation will lead to a summation of the form:
            \[
            	\sum_n\left[\left(\hat{D}w_n(t)\right)e_n(x)\right] = 0
            \]
            where $\hat{D}$ is a linear first order differential operator. As all terms are independent, this gives $n$ first order ODE's to obtain the functions $w_n(t)$. These can be generally solved by using formula \ref{diffeq:first_order_general_solution}.
            \item Initial value conditions for the functions $w_n(t)$ are applied by setting $t=0$ in the series expansion of $u(x, t)$ and equating it with the series expansion of $\psi(x)$. This results in $w_n() = \Psi_n$.
            \item The obtained ODE's together with the found boundary conditions $w_n(0) = \Psi_n$ will give the solutions of $w_n(t)$.
            \item Entering these solutions in the series expansion of $u(x, t)$ will give the general solution of the non-homogeneuous PDE.
		\end{enumerate}
	\end{method}
    \footnotetext{Non-homogeneous boundary conditions can be turned into homogeneous ones by the previous two methods.}
    \remark{It is clear that the requirement that all involved functions are expandable as a generalized Fourier series is restricting. Not all non-homogeneous PDE's are solvable with this method.}
    
\section{Higher dimensions}
\subsection{Symbols}

	\newdef{Symbol}{\index{symbol}
		Consider a general $k^{th}$-order differential operator (we use multi-indices $\alpha$)
		\begin{equation}
			\hat{P} = \sum_{|\alpha|\leq k}c_\alpha(x)D^\alpha
		\end{equation}
		The symbol of this operator is defined by replacing the partial derivatives by indeterminates $\xi^i$:
		\begin{equation}
			p(\hat{P}, \xi) = \sum_{|\alpha|\leq k}c_\alpha(x)\xi^\alpha
		\end{equation}
	}
	\newdef{Principal symbol}{\index{principal!symbol}
		The principal symbol of a $k^{th}$-order differential operator $\hat{P}$ is defined as the highest degree component of $p(\hat{P}, \xi)$:
		\begin{equation}
			\sigma_P(\xi) = \sum_{|\alpha|=k}c_\alpha(x)\xi^\alpha
		\end{equation}
	}
	
	\begin{property}
		The principal symbol of a differential operator transforms as a tensor.
	\end{property}
	\begin{property}
		A PDE $\hat{P}f(x) = 0$ is elliptic if and only if $\sigma_P$ is invertible.
	\end{property}

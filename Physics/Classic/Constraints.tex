\chapter{Constrained dynamics}\label{chapter:constrained_dynamics}

    The foundations for this subject were laid down by \textit{Dirac} in \cite{constrained}. By introducing constraints, the coordinates and their momenta are not independent anymore. This implies for example that the Hamiltonian equations of motion have to be modified.

\section{Constraint surface}

    First, recall the Lagrangian equations of motion \eqref{lagrange:second_kind}. By expanding these equations, it can be shown that the accelerations $\ddot{q}$ are uniquely determined by the coordinates and velocities $(q,\dot{q})$ if and only if the Hessian of the Lagrangian is invertible. If the Hessian is not invertible, the definition of the conjugate momenta \ref{lagrange:conjugate_momentum} cannot be inverted to express velocities in terms of momenta. Alternatively, the momenta $p$ and coordinates $q$ are not independent and there must exist relations of the form
    \begin{gather}
        \phi(q,p) = 0.
    \end{gather}
    Constraints of this type constraints are called \textbf{primary constraints}. They do not serve to constrain the range of the coordinates $q$. They only couple the coordinates and the momenta.

    \begin{axiom}[Regularity conditions]
        It will always be assumed that the independent constraints, i.e. the minimal subset of constraints that imply the others, satisfy the following (equivalent) conditions:
        \begin{itemize}
            \item The constraints can locally serve as the first coordinates of a (regular) coordinate system.
            \item The differentials (gradients) $d\phi_m$ are locally linearly independent.
            \item The variations $\delta\phi_m$ are of the order $\varepsilon$ whenever the variations $\delta q^i,\delta p_i$ are of the order $\varepsilon$. (This is the original condition due to \textit{Dirac}.)
        \end{itemize}
    \end{axiom}

    A constrained dynamical system consists of a dynamic system $(M,\omega,H)$ together with a finite collection of constrained equations $\phi_m(q,p)=0,m\in I$, the \textbf{primary constraints}. If this sytem was derived from a Lagrangian $L(q,\dot{q})$, the calculus of variations easily extends to these constrained systems, where it gives the following modified Hamiltonian equations:
    \begin{align}
        \dot{q}^i &= \pderiv{H}{p_i} + \sum_{m\in I}u_m\pderiv{\phi_m}{p_i}\\
        \dot{p}_i &= -\pderiv{H}{q^i} - \sum_{m\in I}u_m\pderiv{\phi_m}{q^i},
    \end{align}
    where the $u_m$ are functions of the coordinates and velocities that play a role similar to ordinary Lagrange multipliers.
    \begin{remark}
        The above relations follow from the general property that the general solutions to $\lambda_i\delta q^i + \mu_i\delta p^i = 0$ for variations $\delta q^i,\delta p_i$ tangent to the constraint surface are of the form
        \begin{gather}
            \begin{cases}
                \lambda_i = \sum_{m\in I}u_m\pderiv{\phi_m}{q^i}&\\
                \mu^i = \sum_{m\in I}u_m\pderiv{\phi_m}{p_i}.&
            \end{cases}
        \end{gather}
        Combining this result with the usual derivation of Hamilton's equations from a Lagrangian action principle gives the above modified equations.
    \end{remark}
    In terms of Poisson brackets the constrained time evolution of a (time-independent) function is given by
    \begin{gather}
        \label{constraint:modified_poisson_evolution}
        \dot{f} = \{H,f\} + \sum_{m\in I}u_m\{\phi_m,f\}.
    \end{gather}

    \begin{method}[General Poisson brackets]
        Until now Poisson brackets were only defined for functions depending on the canonical coordinates $(q,p)$. This definition can be generalized to arbitrary functions through the Poisson algebra properties \ref{lie:poisson_algebra}. Furthermore, after working out the Poisson brackets one can use the constraint equations to drop all terms that are proportional to $\phi_m$.

        For example, Equation \eqref{constraint:modified_poisson_evolution} can be rewritten as
        \begin{gather}
            \dot{f} = \{H + \sum_{m\in I}u_m\phi_m,f\}.
        \end{gather}
        To prove the equivalence, one can use the linearity and Leibniz properties. This involves the following equality
        \begin{gather}
            \{u_m\phi_m, f\} = \{u_m,f\}\phi_m + u_m\{\phi_m,f\}.
        \end{gather}
        The Poisson brackets in the second term only involve functions depending on $(q,p)$ and can be calculated in the usual way. The first term, however, involves a Poisson bracket of the Lagrange multiplier $u_m$. In general these do not simply depend on $q$ and $p$. Luckily, this does not pose a problem because the term is proportional to the constraints and, as such, vanishes on-shell. It is important that the constraints are only applied after the Poisson brackets have been fully worked out.
    \end{method}

    \begin{notation}[Weak equality]
        The constraints $\phi_m$ only vanish on-shell. To distinguish between functional equalities, i.e. equalities that also hold off-shell, and on-shell equalities, also called \textbf{weak equalities}, the latter are often denoted by the $\approx$ symbol. For example, the condition $\phi_m\approx0$ is only a weak equality.
    \end{notation}
    Using the above definitions one can write an arbitrary time derivative as
    \begin{gather}
        \dot{f}\approx\{H_T,f\},
    \end{gather}
    where $H_T := H + \sum_{m\in I}u_m\phi_m$.

    \begin{remark}[Closure]
        An important remark regarding weak equalities can be found by taking a Poisson bracket of a function $f$ that is strongly zero, i.e. a function that vanishes on-shell and whose variation also vanishes. In this case $\{f,g\}\approx0$ for all functions $g$, i.e. the brackets only vanish weakly. Furthermore, if $f\approx0$, then $\{f,g\}$ does not even have to vanish at all.
    \end{remark}

    \begin{property}[Consistency conditions]
        By taking $f=\phi_n$ for any $n\in I$ in Equation \ref{constraint:modified_poisson_evolution} a set of consistency conditions is obtained:
        \begin{gather}
            \{H,\phi_n\} + \sum_{m\in I}u_m\{\phi_m,\phi_n\}\approx 0.
        \end{gather}
        It is possible that this condition reduces to an inconsistency of the type $1\approx0$. In this case the equations of motion are inconsistent and the theory is not physical. If this is not the case, multiple possibilities can arise:
        \begin{itemize}
            \item After imposing the primary constraints, a tautology $0=0$ is found. This gives no new information.
            \item The equation reduces to an equation not involving the Lagrange multipliers $u_m$. This gives an additional constraint
                \begin{gather}
                    \chi(q,p)=0.
                \end{gather}
                These are called \textbf{secondary constraints}.
            \item A condition on the coefficients $u_m$ is obtained.
        \end{itemize}
        After having found a set of secondary constraints, this procedure can be iterated until no new contraints or conditions are found. Because the consistency conditions are linear in the coefficients $u_m$, the general solution can be written as
        \begin{gather}
            u_m = U_m + v_aV^a _m,
        \end{gather}
        where $U_m$ is a solution of the inhomogeneous equation and the $V^a_m$ are linearly independent solutions of the homogeneous equation
        \begin{gather}
            \sum_{m\in I}u_m\{\phi_m,\phi_n\} = 0.
        \end{gather}
        The resulting coefficients $v_a$ are completely arbitrary functions of time. Therefore, the total Hamiltonian can be written in the form
        \begin{gather}
            H_T = H'(q,p) + v^a(t)\phi_a(q,p),
        \end{gather}
        where $\phi_a := \sum_{m\in I}V^a_m\phi_m$. The occurence of arbitrary functions in the Hamiltonian implies that the evolution of the phase space variables is not unique and, accordingly, that the theory has a gauge freedom.
    \end{property}

    \newdef{First- and second-class}{
        A function $f(q,p)$ is said to be first-class if its Poisson bracket with every constraint (both primary and secondary) is weakly zero. The function is said to be second-class otherwise. It can be shown that both the total Hamiltonian $H_T$ and the primary constraints $\phi_a$ are first-class. The number of arbitrary coefficients $v^a$ is equal to the number of primary first-class constraints.
    }
    \begin{notation}
        To distinguish between first- and second-class constraints, the latter are often denoted by a separate symbol $\chi$.
    \end{notation}
    \begin{property}[Closure]
        The Poisson bracket of two primary first-class functions is first-class. So is the Poisson bracket of the total Hamiltonian and a first-class primary constraint.
    \end{property}

    \begin{remark}[Dirac conjecture]\index{Dirac!conjecture}
        The primary first-class constraints $\phi_a$ generate gauge transformations in the sense that variations in the coefficients $v^a$, which are arbitrary, give rise to phase space variations that leave the physical state invariant. Some secondary constraints might also generate gauge transformations and \textit{Dirac} even conjectured that this was the case for all constraints. However, counterexamples have been found. A common workaround is simply to restrict to systems where the conjecture is true and from here on the distinction between primary and secondary will be dropped. From this point of view it makes sense to define the extended Hamiltonian
        \begin{gather}
            H_E := H_T + v^b(t)\phi_b(q,p),
        \end{gather}
        where $b$ ranges over all secondary first-class constraints. For gauge-invariant functions, i.e. those functions whose Poisson bracket with all first-class constraints vanishes, evolution with all three Hamiltonians $H,H_T$ and $H_E$ is identical. For general functions only $H_E$ takes into account the full gauge freedom.\footnote{Note that $H_T$ is the Hamiltonian that corresponds to a Lagrangian approach. $H_E$ gives a more general theory.}
    \end{remark}
    \begin{result}\index{co-isotrope}
        The first-class constraints form a Lie algebra with respect to the Poisson bracket and the associated gauge transformations define a submanifold in phase space by Frobenius's theorem \ref{bundle:frobenius}.
    \end{result}

    \begin{formula}[Degrees of freedom]
        The number of degrees of freedom is given by the following formula:
        \begin{align*}
            2\times\text{number of d.o.f.} = &\text{ number of canonical coordinates}\\
            &- \text{number of second-class constraints}\\
            &- 2\times\text{number of first-class constraints}.
        \end{align*}
    \end{formula}

    \newdef{Dirac bracket}{\index{Dirac!bracket}
        To take care of second-class constraints, \textit{Dirac} introduced a modification of the Poisson bracket:
        \begin{gather}
            \{f,g\}_D := \{f,g\} - \{f,\chi_a\}C^{ab}\{\chi_b,g\},
        \end{gather}
        where the $\chi_a$'s are the second-class constraints and the (invertible) matrix $C^{ab}$ is the inverse of the matrix $C_{ab}:=\{\chi_a,\chi_b\}$.

        The benefit of using the Dirac bracket (after the Poisson bracket has been used to separate constraints in first-class and second-class constraints) is that second-class constraints become strong equalities, i.e. they can be used even before evaluating further (Dirac) brackets. The Dirac bracket satisfies the same algebraic properties as the Poisson bracket, i.e. it defines a Poisson algebra \ref{lie:poisson_algebra}. From here on, all constraints will be assumed to be first-class, i.e. the Poisson bracket will be assumed to be the one obtained after applying the Dirac procedure to all second-class constraints.
    }
    \begin{remark}
        Instead of splitting the constraints in first- and second-class instances and having to work with the nontrivial Dirac bracket, one can also try to remove second-class constraints in a different way. In the above formula for the degrees of freedom, the factor 2 on the right-hand side is obtained by the introduction of gauge fixing conditions. What these actually do is turning first-class constraints into second-class ones. In fact, the converse is also possible. One can obtain all second-class constraints as gauge fixed first-class constraints after enlarging the system (although this procedure is not unique). After doing this, there is no need for the Dirac bracket anymore and one can simply work with the Poisson bracket (with the added complexity that all constraints now only hold weakly).
    \end{remark}

    \newdef{Gauge-invariant functions}{\label{constraint:functions}
        Consider the algebra of smooth functions on phase space $C^\infty(M)$. In the spirit of algebraic geometry the space of functions on the constraint surface $\Sigma$ is given by the quotient algebra $C^\infty(\Sigma):=C^\infty(M)/\mathcal{N}$, where $\mathcal{N}$ is the ideal having $\Sigma$ as its zero locus, i.e. $\mathcal{N}$ is the ideal generated by the constraints. The elements of $C^\infty(\Sigma)$ that are gauge-invariant, i.e. first-class with respect to first-class constraints, should be considered as the \textbf{classical observables}.

        The restriction to gauge-invariant functions is also imperative if one wants to extend the bracket operation to $C^\infty(\Sigma)$. In general the ideal $\mathcal{N}$ is not an ideal of the Dirac bracket. The gauge-invariant subalgebra is in fact the maximal subalgebra of $C^\infty(\Sigma)$ for which $\mathcal{N}$ is again an ideal.
    }

    \begin{property}[Geometric characterization]\index{phase space!reduced}
        Restricted to a first-class constraint surface, the ``symplectic'' form becomes maximally degenerate with rank $\rk(\omega) = \dim(M) - 2\dim(\Sigma)$. This essentially says that the constraint surface is coisotropic and, as a consequence, that the Poisson bracket is ill-defined (since this would involve the inverse of the symplectic form). After passing to the \textbf{reduced phase space}, i.e. the leaf space of the Hamiltonian foliation generated by the constraints, one again obtains a well-defined Poisson bracket that coincides with the ordinary Poisson bracket without any constraints.

        The opposite situation arises for constraint surfaces that only involve second-class constraints. Here, the induced symplectic form is of maximal rank $\rk(\omega) = \dim(M) - \dim(\Sigma)$, which implies that the surface is isotropic. Furthermore, the induced Poisson bracket coincides with the restriction of the Dirac bracket.
    \end{property}
    \begin{remark}[Algebraic characterization]
        The fact that first-class constraints define a coisotropic submanifold is not a peculiarity. A multiplicative ideal of a Poisson algebra \ref{lie:poisson_algebra} that is closed under the Poisson bracket, is often called a \textbf{coisotrope} (or coisotropic ideal). Coisotropic submanifolds of a Poisson manifold  \ref{symplectic:poisson_manifold} are exactly the zero loci of such coisotropes. In fact, one can restate the above constructions in purely algebraic terms. Given a Poisson algebra $P$ and a coisotrope $\mathcal{I}$, one can pass to the quotient $N(\mathcal{I})/\mathcal{I}$, where $N$ denotes the normalizer in $P$. This quotient is again a Poisson algebra, called the \textbf{reduced Poisson algebra}. This construction is strictly more general than the symplectic case considered above. (The sections further on could also be generalized to this setting.)
    \end{remark}

\section{Gauge algebra}

    In this section the gauge symmetries of local action $S$, i.e. an action \[S[q] := \int L(q,\dot{q},\ldots,t) dt\] where the Lagrangian depends on the derivatives up to a finite order $k$, are considered. A \textbf{gauge transformation} of this action is a coordinate transformation that depends arbitrarily on the time variable, but leaves the action invariant. The most general form of such a transformation is
    \begin{gather}
        \label{constraint:gauge_transformation}
        \delta_\varepsilon y^i = R^i_{(0),j}\varepsilon^j + R^i_{(1),j}\dot{\varepsilon}^j + \cdots + R^i_{(s),j}\mderiv{s}{\varepsilon^j}{t}\equiv R^i_j\varepsilon^j,
    \end{gather}
    where the coefficients $R$ are arbitrary functions of time and in the last step a new shorthand was introduced where the summation over $j$ also includes an integral over $t$:
    \begin{gather}
        R^i_j\varepsilon^j := \int dt'\sum_j\Big(R^i_{(0),j}(t)\delta(t-t')+R^i_{(1),j}(t)\delta'(t-t')+R^i_{(2),j}(t)\delta^{(2)}(t-t')+\cdots\Big)\varepsilon^j(t').
    \end{gather}
    Invariance of the action implies that
    \begin{gather}
        \delta_\varepsilon S = \frac{\delta S}{\delta q^i}\delta_\varepsilon q^i = \frac{\delta S}{\delta q^i}R^i_j\varepsilon^j = 0.
    \end{gather}
    Beause this should hold for every value of the transformation parameters $\varepsilon^j$, one immediately obtains the variational Noether identities:
    \begin{property}[Noether identities]
        If a local action is invariant under the transformation \eqref{constraint:gauge_transformation}, then
        \begin{gather}
            \frac{\delta S}{\delta q^i}R^i_j = 0
        \end{gather}
        for all ``indices'' $j$ (including time $t$). In contrast to Noether's theorem \ref{lagrange:noether_cyclic}, these identities do not imply conserved quantities. Instead they show that the equations of motion are not independent.
    \end{property}
    The structure of the infinitesimal gauge transformations is easily seen to be that of a (real) Lie algebra, whilst that of finite (exponentiated) transformations is a Lie group. However, the gauge algebra $\overline{\mathcal{G}}$ is very large (in fact it is infinite-dimensional) and contains a lot of physically irrelevant information. The simplest example is that of the \textbf{zilch symmetries} as referred to by \textit{Freedman} and \textit{Van Proeyen} \cite{supergravity}:
    \newdef{Trivial gauge symmetry}{\index{zilch}
        All transformations of the form
        \begin{gather}
            \delta_\varepsilon q^i = \varepsilon^{ij}\frac{\delta S}{\delta q^j},
        \end{gather}
        where $\varepsilon^{ij}$ is antisymmetric, are physically irrelevant since they are not generated by constraints. The trivial gauge transformations form an ideal $\mathcal{N}$ of the gauge algebra and the physically relevant algebra is the quotient $\mathcal{G} := \overline{\mathcal{G}}/\mathcal{N}$.

        In fact one can show that any gauge transformation, satisfying suitable conditions, that vanishes on-shell is equal to some trivial transformation. ?? EXPLAIN (see HENNEAUX and TEITELBOIM) ??
    }
    A further problem with the gauge algebra is that independent transformations might lead to dependent Noether identities wich implies that there is still some redundancy. To fix this one defines the following minimal set:
    \newdef{Generating set}{\index{open!algebra}
        A generating set\footnote{Sometimes called a \textbf{complete set} of gauge symmetries.} of the gauge algebra is a set of transformations $\delta_\varepsilon q^i = R^i_j\varepsilon^j$ such that every gauge transformation can be written as follows:
        \begin{gather}
            \delta q^i = R^i_j\mu^j + M^{ij}\frac{\delta S}{\delta q^j},
        \end{gather}
        where $M^{ij}=-M^{ji}$. Because the coefficients might be functions of the coordinates $q,\dot{q},\ldots$\,, the generating set is generally not a basis for the gauge algebra. However, due to the Lie algebra structure, there must exist structure functions $C^i_{kl}$ and $M^{ij}_{kl}$ such that
        \begin{gather}
            R^j_k\frac{\delta R^i_l}{\delta q^j} - R^i_l\frac{\delta R^j_k}{\delta q^i} = C_{kl}^mR^i_m + M_{kl}^{ij}\frac{\delta S}{\delta q^j},
        \end{gather}
        where $M^{ij}_{kl} = -M^{ji}_{kl}$. If all $M$ are zero, the algebra is said to be \textbf{closed} (even though the generating set itself might not be closed as a Lie algebra because the $C$'s generally are functions of the coordinates) and otherwise it is said to be \textbf{open}. A generating set is said to be \textbf{irreducible} if there exist no nontrivial combinations of elements:
        \begin{gather}
            \varepsilon_jR^i_j = M^{ij}\frac{\delta S}{\delta q^j}\implies\varepsilon^j = N^{jk}\frac{\delta S}{\delta q^k}.
        \end{gather}
    }

\section{Fermionic systems}

    In this section the study of constrained systems with ``fermionic'' or odd statistics is considered. For an introduction to Grassmann numbers, see Section \ref{section:berezin}. In general the phase space will be assumed to be a \textit{supermanifold}.

    First, the ordinary Poisson bracket is extended to Grassmann-odd coordinates as follows:
    \begin{gather}
        \{\theta^i,\theta^j\} = 0 = \{\pi_i,\pi_j\}
    \end{gather}
    and
    \begin{gather}
        \{\theta^i,\pi_j\} = \delta^i_j = \{\pi_j,\theta^i\}.
    \end{gather}
    By defining the matrix $\sigma^{ij} := \{z^i,z^j\}$, where $z$ can be any of the $q,p,\theta$ or $\pi$, one can then succintly write the Poisson bracket of superfunctions as follows:
    \begin{gather}
        \{f,g\} := \pderiv{^Rf}{z^i}\sigma^{ij}\pderiv{^Lg}{z^j}.
    \end{gather}
    Note that this is virtually the same expression as the ordinary Poisson bracket, where the matrix $\sigma$ was the inverse of the symplectic matrix. Writing out all terms gives
    \begin{gather}
        \{f,g\} = \left(\pderiv{f}{p_i}\pderiv{g}{q^i}-\pderiv{f}{q^i}\pderiv{g}{p_i}\right) + (-1)^{\deg(f)}\left(\pderiv{f}{\pi_i}\pderiv{g}{\theta^i} + \pderiv{f}{\theta^i}\pderiv{g}{\pi_i}\right).
    \end{gather}
    The algebraic properties of this generalized Poisson bracket are graded generalizations of those of the ordinary one:
    \begin{align}
        \{f,g\} &= -(-1)^{\deg(f)\deg(g)}\{g,f\}\\
        0 &= \{f,\{g,h\}\} + (-1)^{[\deg(f)+\deg(g)]\deg(h)}\{h,\{f,g\}\}\nonumber\\
        &\ \phantom{= \{f,\{g,h\}\} } + (-1)^{\deg(f)[\deg(g)+\deg(h)]}\{g,\{h,f\}\}\\\nonumber\\
        \{f,gh\} &= \{f,g\}h + (-1)^{\deg(f)\deg(g)}f\{g,h\}\\
        \deg(\{f,g\}) &= \deg(f)+\deg(g).
    \end{align}
    The first two properties state that the generalized Poisson bracket gives rise to a Lie superalgebra \ref{hda:lie_superalgebra}. The third property states that it is a \textit{Poisson superalgebra}, in fact this is the example that lends its name to the algebraic structure. Geometrically, the matrix $\sigma$ gives rise to a \textit{supersymplectic structure}.

\section{BRST symmetry}\label{section:classical_brst}
\subsection{Introduction}

    Consider a dynamical system $(M,\omega,H)$ together with a set of first-class constraints $\{\phi_a\}_{a\in I}$. For further convenience the constraints will be assumed to be \textbf{irreducible}, i.e. their Jacobian is assumed to be of full rank on the constraint surface. As was shown before, these constraints generate an algebra under the Poisson bracket. However, more structure exists. To explore this structure, enlarge the phase space by introducing for every constraint and every relation between constraints a Grassmann-odd\footnote{In fact one can generalize this section to phase spaces that already contain odd variables. In that case the ghost variables should have the opposite parity of the associated constraint.} \textbf{ghost variable} $\eta^a$ and its canonical conjugate $\overline{P}_a$, i.e.
    \begin{gather}
        \{\overline{P}_a,\eta^b\} := -\delta^b_a,
    \end{gather}
    of degrees $\mathrm{gh}(\overline{P}_a) = -1$ and $\mathrm{gh}(\eta^a) = 1$.
    \begin{remark}[Nonminimal sectors]\index{Nakanishi-Lautrup field}
        In certain situations it is useful to extend the phase space even further by introducing additional conjugate pairs, e.g. the Lagrange multipliers in an action principle. Such descriptions are said to belong to the nonminimal sector. An example would be the \textit{Nakanishi-Lautrup field} $B$, introduced when quantizing Yang-Mills theory, which is the BRST-partner of the \textit{Faddeev-Popov antighost field} $\overline{c}$, i.e. $\{\overline{c},\Omega\}=B$.
    \end{remark}

    \newdef{BRST operator}{\index{BRST}
        To any dynamical system governed by first-class constraints $\{\phi_a\}_{a\in I}$ one can associate a BRST operator (or function) defined by the following conditions:
        \begin{enumerate}
            \item It is of (ghost) degree 1:
                \begin{gather}
                    \mathrm{gh}(\Omega) = 1.
                \end{gather}
            \item It is nilpotent with respect to the Poisson bracket:
                \begin{gather}
                    \{\Omega,\Omega\} = 0.
                \end{gather}
            \item It is Hermitian:
                \begin{gather}
                    \Omega^* = \Omega.
                \end{gather}
            \item It is proportional to the constraints in lowest order:
                \begin{gather}
                    \Omega = \eta^a\phi_a + \text{terms in ghost momenta}.
                \end{gather}
        \end{enumerate}
    }
    \begin{example}[Abelian constraint algebra]
        In the case where the constraints form an Abelian algebra, i.e. $\{\phi_a,\phi_b\}=0$, the BRST operator has a simple expression:
        \begin{gather}
            \Omega = \eta^a\phi_a.
        \end{gather}
    \end{example}
    \begin{example}[Closed constraint algebra]
        In the case where the constraints form a closed algebra, i.e. $\{\phi_a,\phi_b\}=C^c_{ab}\phi_c$ with $C^c_{ab}$ constant, the BRST operator has a slightly more complex expression since the zeroth order term in the BRST expansion is not nilpotent on its own. However, since the structure functions $C^c_{ab}$ are constants, all higher order terms still vanish:
        \begin{gather}
            \Omega = \eta^a\phi_a -\frac{(-1)^{\varepsilon_b}}{2}\eta^b\eta^c C^a_{bc}\overline{P}_a.
        \end{gather}
    \end{example}
    \begin{remark}[Off-shell closure]
        It should be noted that the nilpotency of the BRST operator not only holds on-shell, but everywhere on $M$. In this sense the ghost momenta appearing in its definition are the fields necessary to close the algebra outside the constraint surface. In fact, it is important to work in the Hamiltonian formalism if one wants to achieve this off-shell nilpotency. It has been shown that in the Lagrangian formalism this property cannot hold for gauge transformations that only close on-shell. (This latter property is related to the fact that the structure coefficients are generally functions of the canonical variables. Only when they are constants, does the algebra of canonical transformations generated by the constraints close off-shell.)
    \end{remark}

    Because of the algebraic properties above, the BRST operator defines a cohomology theory \ref{homalg:homology}:
    \begin{property}[BRST cohomology]
        For all functions $f$ on the extended phase space, one has the following equality:
        \begin{gather}
            \{\{f,\Omega\},\Omega\} = 0.
        \end{gather}
        In view of this structure one defines a BRST-closed function as a function $f$ satisfying
        \begin{gather}
            \{f,\Omega\} = 0
        \end{gather}
        and a BRST-exact function as a function $f$ that can be written as
        \begin{gather}
            f = \{g,\Omega\}
        \end{gather}
        for some function $g$. It is clear that the resulting BRST cohomology theory is gauge-invariant, since $\Omega$ is gauge-invariant.
    \end{property}
    It can also be shown that the BRST operator only depends on the constraint surface and not on the choice of a local description:
    \begin{property}[Uniqueness]
        Any two BRST generators $\Omega,\Omega'$ associated to the same constraint surface are related by a canonical transformation on the extended phase space.
    \end{property}

    For negative ghost numbers it can be shown that BRST cohomology vanishes. In degree 0 the BRST cohomology is characterized as follows:
    \begin{property}[Gauge-invariant functions]\label{constraint:brst_0}
        $H^0(\Omega)$ is isomorphic to the set of equivalence classes of weakly equal, gauge-invariant functions.

        Given a BRST-closed function $f$ of ghost-degree 0, the associated \textbf{classical observable} is obtained as the term of antighost number 0 in its BRST expansion. Conversely, any BRST-closed function of ghost number 0 is called a \textbf{BRST-invariant extension} of its term of antighost number 0.
    \end{property}
    \begin{property}[Poisson bracket]
        The Poisson bracket descends to $H^0(\Omega)$ and defines a (graded) Poisson algebra structure. Furthermore, if $f$ and $g$ are BRST-invariant extensions of $f_0$ and $g_0$ respectively, the functions $fg$ and $\{f,g\}$ are BRST-invariant extensions of $f_0g_0$ and $\{f_0,g_0\}$, respectively.
    \end{property}

    \begin{example}[Extension of constraints]
        Consider a constraint $\phi_a$. A BRST-invariant extension is given by the Poisson bracket
        \begin{gather}
            G_a := \{-\mathcal{P}_a,\Omega\}.
        \end{gather}
        This immediately shows that the extension $G_a$ corresponds to the observable 0, since it is $\Omega$-exact and, hence, vanishes in cohomology. If the constraints form a closed algebra, so do their extensions (due to the property above). However, in general, the BRST-extensions do not obey any kind of algebra-like condition.
    \end{example}

    \sremark{The interpretation of higher cohomology groups will be adressed in Chapter \ref{chapter:quantization}.}

    \newdef{Gauge-fixing}{\index{gauge!fixing}
        Consider a classical Hamiltonian $H_0$ and its BRST extension $H$. One can change the Hamiltonian $H$ by a BRST exact term $\{K,\Omega\}$ without changing the cohomology, i.e. without changing the dynamics of BRST-invariant functions. However, the dynamics of noninvariant functions is modified. For this reason the function $K$ is called the \textbf{gauge-fixing fermion}.
    }

\subsection{Irreducible constraints}

    In this section only systems with irreducible constraints are considered, i.e. it will be assumed that no relations between the constraints exist. To formulate the BRST complex in terms of invariant geometric notions, a homological and differential-geometric approach will be adopted.

    A first step is to express the algebra of on-shell functions $C^\infty(\Sigma)$ in an invariant way. The idea is to rewrite the quotient $C^\infty(M)/\mathcal{N}$ as a homology group (which is invariant by its very nature). To this end one passes to the Koszul complex \ref{homalg:koszul_resolution} associated to the first-class constraints $\phi_a$. (Independence of the constraints exactly says that they form a regular sequence and, hence, the complex gives a homological resolution.) One then finds that $H_0(\delta)\cong C^\infty(M)/\mathcal{N}\cong C^\infty(\Sigma)$, where $\delta$ is the Koszul differential.
    \newdef{Antighost number}{\index{ghost!number}
        The degree induced by $\delta$ is called the \textbf{antighost number}. The Koszul generators $\mathcal{P}_a$, associated to the constraints $\phi_a$, have antighost number 1 and have Grassmann parity $\varepsilon_a+1$.
    }

    A second step is to characterize the gauge structure on the constraint surface $\Sigma$. To this end a modified exterior derivative on the phase space is introduced. Although the gauge algebra spanned by the constraints $\phi_a$ does not necessarily generate a closed gauge group on the full phase space, it does so when restricted to the constraint surface. The $|I|$-dimensional leaves of the foliation generated by the constraints are called the \textbf{gauge orbits}.

    The Hamiltonian vector fields associated to the first-class constraints are tangent to the gauge orbits. Furthermore, by the irreducibility of the constraints, the vector fields form a frame field for the tangent bundle of the gauge orbits.
    \newdef{Longitudinal complex}{
        Vector fields that are tangent to the gauge orbits are called longitudinal or vertical vector fields (not to be confused with the vertical vector fields from Section \ref{section:connections}). A frame is given by the Hamiltonian vector fields $X_a:=\{\phi_a,\cdot\}$.

        Longitudinal forms $\eta^a$ are defined as the multilinear duals to the longitudinal vector fields. The tangent bundle of $\Sigma$ in $M$ can be decomposed as follows:
        \begin{gather}
            TM|_\Sigma = T\mathcal{F}\oplus N\Sigma,
        \end{gather}
        where $T\mathcal{F}$ denotes the tangent bundle of the foliation generated by the constraints and $N\Sigma$ denotes the normal bundle to the foliation. This decomposition also turns the de Rham complex $\Omega(\Sigma):=\Omega(M)|_\Sigma$ into a bicomplex $\Omega^{\bullet,\bullet}(\Sigma)=\Lambda^\bullet T^*\mathcal{F}\otimes\Lambda^\bullet N^*\Sigma$. The longitudinal (or vertical) complex is given by the subcomplex $\Omega^{\bullet,0}(\Sigma)$ and the longitudinal exterior derivative is the projection of the total de Rham differential on the longitudinal subcomplex, i.e. the operator $\mathbf{d}:\Omega^{\bullet,0}(\Sigma)\rightarrow\Omega^{\bullet+1,0}(\Sigma)$ given by
        \begin{align}
            \mathbf{d}f &:= df = \{\phi_a,f\}\,\eta^a,\\
            \mathbf{d}\eta^a &:= -\frac{1}{2}\eta^b\wedge\eta^cC^a_{bc}(q,p),\label{constraint:chevalley_eilenberg}
        \end{align}
        where $C^a_{bc}(q,p)$ are the structure functions of the constraint algebra. The Grassmann parity of the forms $\eta^a$ is taken to be $\varepsilon_a+1$. Note that the action of $\mathbf{d}$ is exactly the action of the Chevalley-Eilenberg differential from Section \ref{section:lie_algebra_cohomology}. (This is not a coincidenceas will be explained further on.)

        The longitudinal complex can be extended to all of $M$ by taking its elements to be the forms
        \begin{gather}
            A \equiv A_{i_1\ldots i_k}(q,p)\eta^{i_1}\wedge\cdots\wedge\eta^{i_k},
        \end{gather}
        where the coefficients are equivalence classes of weakly equal functions in $C^\infty(M)$.
    }

    \newdef{Ghost number}{\index{ghost!number}
        The form degree of a longitudinal differential form is called the \textbf{(pure) ghost number}. It is denoted by ``$\mathrm{pure\ gh}$''.
    }
    Note that the number of Koszul generators is the same as the number of ghost fields since both of these are induced by the constraints $\phi^a$. To extend the Poisson bracket to the \textbf{extended phase space} containing phase space functions, ghost fields and ghost momenta, the following convention is introduced:
    \begin{gather}
        \{\mathcal{P}_a,\eta^b\} = -(-1)^{(\varepsilon_a+1)(\varepsilon_b+1)}\{\eta^b,\mathcal{P}_a\} := -\delta_a^b.
    \end{gather}

    \newdef{Ghost number}{\index{ghost!number}
        The total ghost number of an element in the coordinate superalgebra $C^\infty(M)\otimes\mathbb{C}[\eta^a]\otimes\mathbb{C}[\mathcal{P}_a]$ on the extended phase space is defined as follows:
        \begin{gather}
            \mathrm{gh}(A) := \mathrm{pure\ gh}(A) - \mathrm{antigh}(A).
        \end{gather}
        It satisfies
        \begin{gather}
            \mathrm{gh}(AB) = \mathrm{gh}(A)+\mathrm{gh}(B).
        \end{gather}
        It can be obtained as the eigenvalue of the operator
        \begin{gather}
            \label{constraint:ghost_number}
            \mathcal{G}:=i\eta^a\mathcal{P}_a.
        \end{gather}
    }
    When passing to longitudinal forms on all of $M$, the operator $\mathbf{d}$ fails to be a differential, i.e. $\mathbf{d}^2\neq0$ on $M$. It is only weakly zero outside $\Sigma$. Furthermore, when extending the longitudinal derivative $\mathbf{d}$ to the extended phase space one has the freedom to choose the action on the ghost momenta under the constraint that $\mathrm{gh}(\mathbf{d})=1$ and $\mathrm{antigh}(\mathbf{d})=0$.\footnote{Because $\delta$ is a boundary operator, i.e. it decreases the degree, there is less freedom in defining $\delta\eta^a$. Only $\delta\eta^a=0$ is allowed.} By making the choice
    \begin{gather}
        \mathbf{d}\mathcal{P}_a := (-1)^{\varepsilon_a}\eta^c C^b_{ca}\mathcal{P}_b,
    \end{gather}
    the Koszul differential and longitudinal derivative satisfy $[\delta,\mathbf{d}]=0$. This also turns $\mathbf{d}$ into a differential modulo $\delta$ (Definition \ref{homalg:differential_modulus_differential}). The homology of $\delta$ can be generalized to the full extended phase space by tensoring the Koszul resolution of $C^\infty(\Sigma)$ by $\mathbb{C}[\eta^a]$. Because the latter is a free and, in particular, projective module, the homology of the tensor product is the tensor product of the homology with this module. The cohomology of $\mathbf{d}$ modulo $\delta$ on $M$ can be shown to coincide with the cohomology of $\mathbf{d}$ on $\Sigma$. This cohomology theory is exactly the \textbf{BRST cohomology} from the previous section.

    Homological perturbation theory \ref{homalg:homological_perturbation} now also says that there exists a true differential $s$ on the extended phase space  generating BRST cohomology with the following additional properties:
    \begin{align}
        s &= \delta + \mathbf{d} + \cdots\nonumber\\
        \varepsilon(s) &= 1\\
        \mathrm{gh}(s) &= 1.\nonumber
    \end{align}
    This operator can be induced by a \textbf{BRST function} $\Omega$ such that
    \begin{gather}
        sA := \{A,\Omega\}
    \end{gather}
    as before.

\subsection{Reducible constraints}

    In this section, the irreducibility requirement for the first-class constraints is relaxed. To recover the BRST complex as a homological object, one has to modify the construction from the previous section. First of all the Koszul complex is not a resolution for $C^\infty(\Sigma)$ anymore. Because higher-order relations exist among the constraints, the higher-order homology does not vanish. Mathematically, the issue is that the constraints do not form a regular sequence anymore. However, they still generate a module and so a Koszul-Tate resolution \ref{homalg:koszul_tate_resolution} exists. Instead of only introducing ghost momenta corresponding to constraints, one also has to introduce ghost-of-ghosts.

    A second problem occurs when trying to define the longitudinal complex and trying to combine it with the Koszul-Tate complex. The number of ghost momenta is now greater than the number of (longitudinal) ghost fields and, furthermore, the longitudinal algebra is not a tensor product $C^\infty(\Sigma)\otimes\mathbb{C}[\eta^a]$ due to the existence of relations among the constraints. The solution here is again to pass to a larger structure that has the correct ``homotopical'' structure. In this case this will be a Sullivan model, i.e. the Chevalley-Eilenberg algebra associated to a $L_\infty$-algebroid.

    \begin{formula}[Ghost number]
        Due to the introduction of ghost-of-ghosts, Equation \eqref{constraint:ghost_number} has to be modified. Let $\eta^{a_1}$ denote the ghost fields, i.e. fields of (pure) ghost number 1, $\eta^{a_2}$ the ghost-of-ghosts, i.e. fields of (pure) ghost number 2, etc. The total ghost number operator is then given by
        \begin{gather}
            \mathcal{G} := i\sum_{i=1}^\infty\eta^{a_i}\mathcal{P}_{a_i} + \text{constants due to operator ordering},
        \end{gather}
        where $\mathcal{P}_{a_i}$ are the ghost-of-ghost momenta of antighost number $i$.
    \end{formula}
    \begin{remark}[Irreducible constraints]
        The case of irreducible constraints can be recovered from this general situation by throwing away all higher-order generators.
    \end{remark}

    \begin{remark}[Chevalley-Eilenberg complex]
        As has been noted before, there are some relations between BRST complexes and Chevalley-Eilenberg algebras. In fact these relations are no mere coincidences. The constraint algebra
        \begin{gather}
            \{\phi_a,\phi_b\} = C^c_{ab}\phi_c
        \end{gather}
        defines a Lie algebroid in the case of irreducible constraints and a (potentially truncated) $L_\infty$-algebroid in the case of reducible constraints. Similar to the case of Lie algebra cohomology (Equation \ref{lie:zeroth_cohomology}), one can characterize invariants of Lie algebroids in terms of their Chevalley-Eilenberg cohomology. From this point of view, gauge-invariant functions do not just resemble elements of the zeroth cohomology group of a Chevalley-Eilenberg differential, they are exactly that.
    \end{remark}
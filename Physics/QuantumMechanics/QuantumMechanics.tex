\chapter{Quantum Mechanics}\label{chapter:qm}

    The main reference for this chapter is~\citet{bransden_quantum_2000}. In the first two sections, the two basic formalisms of quantum mechanics are introduced: wave and matrix mechanics. The main reference for the mathematically rigorous treatment of quantum mechanics, in particular in the infinite-dimensional setting, is~\citet{moretti_mathematical_2016}. The main reference for the generalization to curved backgrounds is~\citet{schuller_lectures_2016}. The section on the WKB approximation is based on~\citet{bates_lectures_1997}. Relevant chapters in this compendium are, amongst others, \ref{chapter:distributions}, \ref{chapter:functional} and \ref{chapter:operator_algebras}.

    \minitoc

\section{Introduction}

    This section will give both an introduction and formal treatment of the objects and notions used in quantum mechanics.

\subsection{Particle-wave duality}

    \newdef{de Broglie wavelength}{\index{wavelength!de Broglie}\label{qm:debroglie_wavelength}
        \indexauthor{de Broglie} proposed that all particles also exhibit wavelike behaviour. For a particle with momentum $p$, the associated wavelength is given by
        \begin{gather}
            \lambda := \frac{h}{p}\,,
        \end{gather}
        where $h$ is Planck's constant.
    }

    \newdef{Compton wavelength}{\index{wavelength!Compton}\label{qm:compton_wavelength}
        Rather similar to the de Broglie wavelength, the Compton wavelength attributes wavelike behaviour to a particle. However, instead of taking a plane wave with the same momentum as the particle, it takes a (light) wave with the same energy (in its rest frame):
        \begin{gather}
            \lambda_c := \frac{h}{mc}\,,
        \end{gather}
        where $m$ is the mass of the particle (cf.~\cref{relativity:relativistic_energy}).
    }

\subsection{Dirac--von Neumann postulates}\index{Dirac--von Neumann postulates}\label{section:qm_postulates}

    \begin{axiom}[States]\index{state}
        The states of a (closed) system are represented by vectors in a (complex) Hilbert space $\mathcal{H}$. In the infinite-dimensional setting, one often further restricts to separable spaces, i.e.~the spaces are required to admit a countable Hilbert basis.
    \end{axiom}

    \begin{notation}[Dirac notation]\index{notation!braket}\index{notation!Dirac}
        State vectors $\ket{\psi}$ are called \textbf{ket}'s and their duals $\bra{\psi}$ are called \textbf{bra}'s. The inner product of a state $\ket{\phi}$ and a state $\ket{\psi}$ is denoted by $\braket{\phi}{\psi}$. This notation is often called the \textbf{braket notation} (or Dirac notation).
    \end{notation}

    \begin{axiom}[Observables]\index{observable}
        Every physical property is represented by a bounded, self-adjoint operator. In the finite-dimensional case, this is equivalent to an operator that admits a complete set of eigenfunctions.
    \end{axiom}

    \newdef{Compatible observables}{\index{observable!compatibility}
        Two observables are said to be compatible if they share a complete set of eigenvectors.
    }

    \begin{formula}[Closure relation]\index{closure!relation}\index{resolution!of the identity}
        For a complete set of eigenvectors, the closure relation (also called the \textbf{resolution of the identity}) is given by (see also \cref{ncg:spectral_resolution})
        \begin{gather}
            \label{qm:closure}
            \sum_n\ket{\psi_n}\bra{\psi_n} + \Int_X\ket{x}\bra{x}\,dx = \mathbbm{1}\,,
        \end{gather}
        where the sum ranges over the discrete spectrum and the integral over the continuous spectrum. For simplicity, the summation will also be used for the continuous part.
    \end{formula}

    \begin{axiom}[Born rule]\index{Born!rule}\label{qm:born_rule}
        Let $\mathcal{H}$ be the Hilbert space of a physical system and consider an observable $\widehat{O}$. If $\ket{\psi}$ is a state vector and $\widehat{P}_\phi$ is the projection onto an eigenvector $\ket{\phi}$ of $\widehat{O}$, the probability of observing the state $\ket{\phi}$ is given by:
        \begin{gather}
            \frac{\langle\psi\mid\widehat{P}_\phi\mid\psi\rangle}{\braket{\psi}{\psi}} = \frac{|\braket{\psi}{\phi}|^2}{\braket{\psi}{\psi}}\,.
        \end{gather}
    \end{axiom}

    \begin{property}[Projectivization]
        In light of the Born rule, the dynamics of a system does not depend on the global phase or normalization, i.e.~states are represented by rays in a projective Hilbert space $\mathcal{H}\mathbb{P}$ (\cref{alggeom:projective_space}).
    \end{property}

    Combining Born's rule with \cref{prob:expectation_value}, gives the following definition.
    \newdef{Expectation value}{\index{expectation}\label{qm:expectation}
        The expectation value of an observable $\widehat{A}$ in a (normalized) state $\ket{\psi}$ is defined as follows:
        \begin{gather}
            \langle\widehat{A}\rangle_\psi := \bra{\psi}\widehat{A}\ket{\psi}\,.
        \end{gather}
        The subscript $\psi$ is often left implicit. As in ordinary statistics (\cref{statistics:variance_without_sum}), the uncertainty or variance is defined as follows:
        \begin{gather}
            \Delta A := \langle\widehat{A}^2\rangle - \langle\widehat{A}\rangle^2\,.
        \end{gather}
    }
    \newformula{Uncertainty relation}{\index{Heisenberg!uncertainty relation}\index{Robertson|see{Heisenberg uncertainty relation}}\label{qm:uncertainty_relation}
        Let $\widehat{A},\widehat{B}$ be two observables and let $\Delta A,\Delta B$ be the corresponding uncertainties. The (\textbf{Robertson}) uncertainty relation reads as follows:
        \begin{gather}
            \Delta A\Delta B\geq\frac{1}{4}\left|\left\langle\left[\widehat{A},\widehat{B}\right]\right\rangle\right|^2\,.
        \end{gather}
    }

    \begin{axiom}[Projection\footnotemark]\index{measurement}\index{collapse}
        \footnotetext{Also called the \textbf{measurement postulate}.}
        Let $\mathcal{H}$ be the Hilbert space of a physical system and consider an observable $\widehat{O}$ with eigenvalues $\{o_i\}_{i\in I}$. After measuring the observable $\widehat{O}$ in the state $\ket{\psi}$, the outcome will be one of the eigenvalues $o_i$ and system will `collapse' to, i.e.~get projected onto, the eigenstate $\widehat{P}_{o_i}\ket{\psi}\equiv\ket{o_i}$.
    \end{axiom}

    \begin{axiom}[Unitary evolution]\index{evolution}\label{qm:evolution_axiom}
        The evolution of a closed system is unitary, i.e.~there exists a unitary operator $\widehat{U}(t,t')\in\Aut(\mathcal{H})$, for all times $t\leq t'$, such that\footnote{Note that some authors use a different convention whereby the two arguments are interchanged.}
        \begin{gather}
            \ket{\psi(t)} = \widehat{U}(t,t')\ket{\psi(t')}\,.
        \end{gather}
    \end{axiom}

\section{Schr\"odinger picture}

    Since the energy is of paramount importance in physics, the associated eigenvalue equation deserves its own name.
    \begin{formula}[Time-independent Schr\"odinger equation]\index{Schr\"odinger!equation}\index{Hamilton!function}\label{qm:TISE}
        \begin{gather}
            \widehat{H}\ket{\psi} = E\ket{\psi}
        \end{gather}
        The operator $\widehat{H}$ is called the \textbf{Hamiltonian} of the system. The wave function $\psi$ is an element of the vector space $L^2(\mathbb{R},\mathbb{C})\otimes\mathcal{H}$ with $\mathcal{H}$ the internal Hilbert space (describing, for example, the spin or charge of a particle). This is an eigenvalue equation for the energy levels of the system.
    \end{formula}

    \todo{INTRODUCE POSITION/CONFIGURATION REPRESENTATION}

    The time evolution of a wave function was governed by \cref{qm:evolution_axiom}. By passing to generators, the following equation is obtained.
    \begin{formula}[Time-dependent Schr\"odinger equation]\index{Schr\"odinger!equation}\label{qm:TDSE}
        \begin{gather}
            i\hbar\pderiv{}{t}\ket{\psi(t)} = \widehat{H}\ket{\psi(t)}\,.
        \end{gather}
        In case $\widehat{H}$ is time independent, the TISE can be obtained from this equation by separation of variables (see below).

        \begin{mdframed}[roundcorner=10pt, linecolor=blue, linewidth=1pt]
            \begin{proof}[Derivation of TISE from TDSE]
                Starting from the one-dimensional TDSE in position space with a time-independent Hamiltonian, one can perform a separation of variables and assert a solution of the form $\psi(x,t) = X(x)T(t)$. Inserting this in the previous equation gives
                \begin{gather*}
               		i\hbar X(x)T'(t) = \left(\widehat{H}X(x)\right)T(t)\,.
               	\end{gather*}
                Dividing both sides by $X(x)T(t)$ and rearranging the terms gives
                \begin{gather*}
               		i\hbar\frac{T'(t)}{T(t)} = \frac{\widehat{H}X(x)}{X(x)}\,.
               	\end{gather*}
                Because the left side only depends on $t$ and the right side only depends on $x$, one can conclude that they both have to equal a constant $E\in\mathbb{C}$. This leads to the following system of differential equations:
                \begin{gather*}
                    \begin{cases}
                        &i\hbar T'(t) = ET(t)\,,\\
                        &\widehat{H}X(x) = EX(x)\,.
                    \end{cases}
                \end{gather*}
                The first equation immediately gives a solution for $T$:
                \begin{gather}
                    \label{derivations_qm:exponential}
               		T(t) = C\exp\left(-\frac{iE}{\hbar}t\right)\,.
               	\end{gather}
                The second equation is exactly the TISE (\cref{qm:TISE}).
            \end{proof}
        \end{mdframed}
    \end{formula}

    \begin{example}[Massive particle in a stationary potential]
        \begin{gather}
            \label{qm:TDSE_position}
            i\hbar\pderiv{}{t}\psi(x,t) = \left(-\frac{\hbar^2}{2m}\partial_x^{\ 2} + V(x)\right)\psi(x,t)
        \end{gather}
        In this case, the TISE reads as follows:
        \begin{gather}
            \label{derivations_qm:TISE}
            \psi''(x) = -\frac{2m}{\hbar^2}\bigl(E - V(x)\bigr)\psi(x)\,.
        \end{gather}
    \end{example}

    \begin{formula}[General solution]
        A general solution of the TDSE (for time-independent Hamiltonians) is given by the following formula (cf.~\cref{ode:first_order_general_solution}):
        \begin{gather}
            \label{qm:general_solution}
            \psi(x,t) = \sum_Ec_E\psi_E(x)e^{-\frac{i}{\hbar}Et}\,,
        \end{gather}
        where the functions $\psi_E(x)$ are the eigenfunctions of the TISE. The coefficients $c_E$ can be found using the orthogonality relations
        \begin{gather}
            \label{qm:general_solution_coefficients}
            c_E=\left(\Int_{\mathbb{R}}\overline{\psi_E}(x)\psi(x,t_0)\,dx\right)e^{\frac{i}{\hbar}Et_0}\,.
        \end{gather}
    \end{formula}

    \newformula{Dyson series}{\index{Dyson series}\index{time ordering}\label{qm:evolution_operator}
        Inserting the evolution operator from \cref{qm:evolution_axiom} into the TDSE~\ref{qm:TDSE}, even generalising to time-dependent Hamiltonians, the following operator equation is obtained:
        \begin{gather}
            i\hbar\deriv{}{t}\widehat{U}(t,t') = \widehat{H}(t)\widehat{U}(t,t')\,.
        \end{gather}
        With the initial condition $\widehat{U}(t,t)=1$ for all $t\in\mathbb{R}$, this can be formally solved as follows (for $t\geq t'$):
        \begin{gather}
            \widehat{U}(t,t') = \mathbbm{1} - \frac{i}{\hbar}\Int_{t'}^t\widehat{H}(\tau)\widehat{U}(\tau,t')\,d\tau\,.
        \end{gather}
        This solution can be iterated to obtain a series expansion of the evolution operator:
        \begin{gather}
            \widehat{U}(t,t') = 1 - \frac{i}{\hbar}\Int_{t'}^t\widehat{H}(\tau)\,d\tau + \left(-\frac{i}{\hbar}\right)^2\Int_{t'}^t\Int_{t'}^\tau\widehat{H}(\tau)\widehat{H}(\tau')\,d\tau'\,d\tau + \cdots\,.
        \end{gather}
        It is clear that the integrands are time-ordered. By explicitly introducing the \textbf{time-ordering operator}
        \begin{gather}
            \label{perturbation:time_ordering_operator}
            \mathcal{T}\left(\widehat{H}(t_1)\widehat{H}(t_2)\right) =
            \begin{cases}
                \widehat{H}(t_1)\widehat{H}(t_2)&\cif t_1 \geq t_2\,,\\
                \widehat{H}(t_2)\widehat{H}(t_1)&\cif t_2 > t_1\,,
            \end{cases}
        \end{gather}
        the integrals can be rewritten in a more symmetric form:
        \begin{gather}
            \widehat{U}(t,t') = 1 - \frac{i}{\hbar}\Int_{t'}^t\widehat{H}(\tau)\,d\tau + \frac{1}{2!}\left(-\frac{i}{\hbar}\right)\Int_{t'}^t\Int_{t'}^{\textcolor{red}{t}}\mathcal{T}\left(\widehat{H}(\tau)\widehat{H}(\tau')\right)\,d\tau'\,d\tau + \cdots\,.
        \end{gather}
        By comparing this expression to the series expansion for exponential functions, the following concise formula is obtained:
        \begin{gather}
            \widehat{U}(t,t') = \mathcal{T}\exp\left(-\frac{i}{\hbar}\Int_{t'}^t\widehat{H}(\tau)\,d\tau\right)\,.
        \end{gather}
        The expression on the right-hand side is called the \textbf{Dyson series}.
    }

\section{Heisenberg--Born--Jordan picture}

    In the previous section, the central object was the wave function. It was this object that evolved in time and the operators acting on the Hilbert space of physical states were assumed to be fixed. However, it is also possible to transfer this dependence on time to the operators.

    \begin{formula}[Time-dependent observables]
        \begin{gather}
            \widehat{O}_H(t) := e^{\frac{i}{\hbar}\widehat{H}t}\widehat{O}_S(t)e^{-\frac{i}{\hbar}\widehat{H}t}
        \end{gather}
        The equivalence between the Sch\"odinger and Heisenberg pictures essentially come from the fact that the time-evolving expectation values of operators are given by the following formula:
        \begin{gather}
            \langle\widehat{O}(t)\rangle = \bra{\psi}e^{\frac{i}{\hbar}\widehat{H}t}\widehat{O}(t)e^{-\frac{i}{\hbar}\widehat{H}t}\ket{\psi}\,.
        \end{gather}
        The difference between the pictures is simply the choice of whether to include the evolution operator in the states or in the operators.
    \end{formula}

    Using the above transformation, the Sch\"odinger equation (\cref{qm:TDSE}) can also be reexpressed.
    \begin{formula}[Time-dependent Schr\"odinger equation]
        \begin{gather}
            \pderiv{\widehat{O}_H}{t}(t) = \frac{i}{\hbar}\left[\widehat{H}_H(t),\widehat{O}_H(t)\right] + \left(\pderiv{\widehat{O}}{t}(t)\!\right)_H
        \end{gather}
    \end{formula}

    Taking this expression for the Schr\"odinger equation and taking expectation values (using the linearity of the equation), gives the following (interaction-independent) result.

    \begin{theorem}[Ehrenfest]\index{Ehrenfest}\label{qm:ehrenfest}
        Let $\widehat{H}$ be the Hamiltonian and consider an observable $\widehat{O}$. The expectation value of this operator evolves as follows:
        \begin{gather}
            \deriv{\langle\widehat{O}\rangle}{t} = \frac{1}{i\hbar}\bigl\langle[\widehat{O},\widehat{H}]\bigr\rangle + \left\langle\pderiv{\widehat{O}}{t}\right\rangle\,.
        \end{gather}
    \end{theorem}

    \begin{remark}[Equivalence]
        It is important to note that the Schr\"odinger equation could be replaced by Ehrenfest's theorem. They are entirely equivalent.
    \end{remark}

    But, given the abstract state vectors $\ket{\psi}$ from \cref{section:qm_postulates}, how does one recover the position (configuration) representation $\psi(x)$? This is simply the projection of the state vector $\ket{\psi}$ on the `basis function' $\delta(x)$, i.e.~$\psi(x)$ represents an expansion coefficient in terms of a `basis' for the physical Hilbert space. In the same way, one can obtain the momentum representation $\psi(p)$ by projecting onto the plane waves $e^{ipx}$.

    \begin{remark}\index{Hilbert!rigged Hilbert space}
        It should be noted that neither the `basis states' $\delta(x)$, nor the plane waves $e^{ipx}$ are square integrable and, hence, they are not elements of the Hilbert space $L^2(\mathbb{R},\mathbb{C})$. This issue can be resolved through the concept of \textit{rigged Hilbert spaces}.
    \end{remark}

\subsection{Hydrogen atom}

    Consider the hydrogen atom, i.e.~a single proton (the nucleus) orbited by a single electron with only the electrostatic Coulomb force acting between them (gravity can safely be neglected):
    \begin{gather}
        \widehat{H} := \frac{\widehat{p}_p^2}{2m_p} + \frac{\widehat{p}_e^2}{2m_e} - \frac{e^2}{4\pi\varepsilon r^2}\,.
    \end{gather}
    It is not hard to see that this is the quantum mechanical version of the Kepler problem (\cref{section:kepler}). The special property of the Kepler problem was that it contained a `hidden' symmetry that gave rise to the conserved Laplace--Runge--Lenz vector (\cref{classic:lrl_vector}). As is the case for all conserved charges in quantum mechanics, this symmetry induces a degeneracy of the energy eigenvalues. Degeneracy of the magnetic quantum number $m\in\mathbb{N}$ follows from rotational symmetry, but the energy levels of the hydrogen atom only depend on the principal quantum number $n\in\mathbb{N}$. It is the degeneracy of the total angular quantum number $l\in\mathbb{N}$ that is due to this `hidden' $\mathrm{SO}(4)$-symmetry. It is often called an `accidental degeneracy' for this reason.

\subsection{Molecular dynamics}

    Consider the Hamiltonian of two interacting atoms:
    \begin{gather}
        \widehat{H} = \frac{\widehat{P}_1^2}{2M_1} + \frac{\widehat{P}_2^2}{2M_2} + \frac{\widehat{q}_1\widehat{q}_2}{4\pi\varepsilon R^2} + \sum_i\frac{\widehat{p}_i^2}{2m} - \frac{e\widehat{q}_1}{4\pi\varepsilon r_{i1}^2} - \frac{e\widehat{q}_2}{4\pi\varepsilon r_{i2}^2} + \sum_{i\neq j}\frac{e^2}{4\pi\varepsilon r_{ij}^2}\,,
    \end{gather}
    where the indices $i,j$ indicate the electrons and uppercase symbols denote operators associated to the nuclei.

    Except for the most simple situations, solving the Schr\"odinger equation for this Hamiltonian becomes intractable (both analytically and numerically). However, in general, one can approximate the situation. The masses of nuclei are much larger than those of the electrons and this influences their motion, they move much slower than the electrons. In essence, the nuclei and electrons live on different time scales and this allows to decouple their dynamics:
    \begin{gather}
        \widehat{H}_{\text{nucl}} = \frac{\widehat{P}_1^2}{2M_1} + \frac{\widehat{P}_2^2}{2M_2} + \frac{Q_1Q_2}{4\pi\varepsilon R^2} + V_{\text{eff}}(R_1,R_2).
    \end{gather}
    The electrons generate an effective potential for the nuclei and the Schr\"odinger equation decouples as follows:
    \begin{gather}
        \begin{aligned}
            \widehat{H}_{\text{nucl}}(R)\psi(R) &= E\psi(R)\,,\\
            \widehat{H}_{\text{el}}(r,R)\phi(r,R) &= E_{\text{el}}\phi(r,R)\,.
        \end{aligned}
    \end{gather}
    This is the so-called \textbf{Born--Oppenheimer approximation}. From a more modern physical perspective, this approximation can also be seen to be a specific instance of renormalization theory, where the short time-scale (or, equivalently, the high energy-scale) degrees of freedom are integrated out of the theory.\index{Born--Oppenheimer approximation}

\section{Mathematical formalism}\label{section:mathematical_formalism_qm}
\subsection{Weyl systems}

    \newdef{Canonical commutation relations}{\index{canonical!commutation relation}\index{Weyl!relations}\label{qm:CCR}
        Two observables $\widehat{A},\widehat{B}$ are said to obey a canonical commutation relation (CCR) if they satisfy (up to a constant factor $\hbar$)
        \begin{gather}
            [\widehat{A},\widehat{B}] = i\,.
        \end{gather}
        The prime examples are the position and momentum operators $\widehat{x},\widehat{p}$. Through functional calculus, one can also define the exponential operators $e^{is\widehat{A}}$ and $e^{it\widehat{B}}$. The above relation then induces the so-called \textbf{Weyl form} of the CCR:
        \begin{gather}
            e^{is\widehat{A}}e^{it\widehat{B}} = e^{ist}e^{it\widehat{B}}e^{is\widehat{A}}\,.
        \end{gather}
    }
    \begin{theorem}[Stone--von Neumann]\index{Stone--von Neumann}\label{qm:stone_von_neumann}
        All pairs of irreducible, unitary one-parameter subgroups satisfying the Weyl form of the CCRs are unitarily equivalent.
    \end{theorem}
    \begin{result}
        The Schr\"odinger and Heisenberg pictures are unitarily equivalent.
    \end{result}

    In fact, one can generalize the Weyl form of the CCRs.
    \newdef{Weyl system}{\index{Weyl!system}
        Let $(L,\omega)$ be a symplectic vector space and let $K$ be a complex vector space. Consider a map $W$ from $L$ to the space of unitary operators on $K$. The pair $(K,W)$ is called a Weyl system over $(L,\omega)$ if it satisfies
        \begin{gather}
            W(z)W(z') = e^{\sfrac{i}{2}\omega(z,z')}W(z+z')
        \end{gather}
        for all $z,z'\in L$, i.e.~$W$ is a projective representation of the Abelian group $L$ and $\omega$ is, up to rescaling, the group cocycle inducing it (\cref{section:projective_representation}). The relation itself is called a \textbf{Weyl relation}.
    }

    \newdef{Heisenberg system}{\index{Heisenberg!system}
        Let $W$ be a Weyl system. The selfadjoint generators $\phi(z)$, which exist by Stone's theorem~\ref{functional:stone}, of the maps $t\mapsto W(tz)$ are said to form a Heisenberg system. These operators satisfy the following properties:
        \begin{enumerate}
            \item\textbf{Positive homogeneity}: $\lambda\phi(z) = \phi(\lambda z)$ for all $\lambda>0$,
            \item\textbf{Commutator}: $[\phi(z),\phi(z')] = -i\omega(z,z')$, and
            \item\textbf{Weak additivity}: $\phi(z+z')$ is the closure (\cref{functional:closure}) of $\phi(z)+\phi(z')$.
        \end{enumerate}
    }

    \begin{remark}
        It should be noted that the Weyl relations are more fundamental than their infinitesimal counterparts. Only the Weyl relations are well defined on more general spaces and when passing to a relativistic setting.
    \end{remark}

    Recall \cref{section:noncommutative_measure_theory}, where the framework of measure theory and distributions was generalized to the noncommutative context.
    \begin{property}[Schr\"odinger representation]\index{Schr\"odinger!representation}\index{topology!algebraic}
        Consider a distribution $d$ on a (real) TVS $V$. There exists a unique unitary representation $U$ of the additive group $V^*$ on $L^2(V,d)$ such that
        \begin{gather}
            U(\lambda)f = e^{id(\lambda)}f
        \end{gather}
        for all bounded tame functions $f$ and such that $1$ is cyclic for $U$ in $L^2(V,d)$. Moreover, this representation is continuous with respect to the finest locally convex topology on $V$ (the one generated by all seminorms on $V$)\footnote{This topology is also known as the \textbf{algebraic topology}}. 
    \end{property}

    \todo{EXPLAIN RELEVANCE e.g.~\citet{baez_introduction_2014}}

\subsection{Dirac--von Neumann postulates: revisited}\index{Dirac--von Neumann postulates}

    \Cref{section:qm_postulates} presented the axioms of quantum mechanics in terms of Hilbert spaces and the operators thereon. However, the incredible insight of \indexauthor{von Neumann} was that one can do away with the Hilbert space. By \cref{operators:bounded_operators}, the observables of a quantum-mechanical system form a $C^*$-algebra. Consequently, the idea is to rephrase the axioms in purely $C^*$-algebraic terms (\cref{section:c_star_algebras}). By \cref{operators:gelfand_naimark}, these two approaches are equivalent.

    \begin{axiom}[Observables]\index{observable}
        A physical system is characterized by a $C^*$-algebra, with the observables corresponding to the self-adjoint elements.
    \end{axiom}

    \begin{axiom}[States]\index{state}
        A state of a quantum-mechanical system is given by a state of the associated $C^*$-algebra (\cref{operators:state}).
    \end{axiom}

    \begin{axiom}[Born rule]\index{Born!rule}
        The expectation value of an observable $a$ in a state $\omega$ is given by the evaluation $\omega(a)$.
    \end{axiom}
    \begin{remark}
        \Cref{section:density_operator} will link this axiom to traces and operator theory through \cref{operators:tracial_state} and \cref{operators:normal_state}.
    \end{remark}

    \begin{axiom}[Projection]\index{measurement}\index{collapse}
        
    \end{axiom}

    \begin{axiom}[Unitary evolution]\index{evolution}

    \end{axiom}

    \todo{CORRECT ALL AXIOMS}

\subsection{Symmetries}

    \begin{property}[States]\index{state}\index{Fubini--Study metric}
        By the postulates of quantum mechanics, states are represented by rays in the projective Hilbert space $\mathcal{H}\mathbb{P}$. The probabilities, given by the Born rule (\cref{qm:born_rule}), can be expressed in terms of the \textit{Fubini--Study metric} on $\mathcal{H}\mathbb{P}$ as follows:
        \begin{gather}
            \mathcal{P}(\psi,\phi) := \cos^2\bigl(d_{\text{FS}}(\psi,\phi)\bigr) = \frac{\left|\braket{\psi}{\phi}\right|^2}{\braket{\psi}{\psi}\braket{\phi}{\phi}}\,,
        \end{gather}
        where $\ket{\psi},\ket{\phi}$ are representatives of the states $\psi,\phi$ in $\mathcal{H}\mathbb{P}$.
    \end{property}

    \newdef{Symmetry}{\index{symmetry!quantum}\index{automorphism!quantum}
        A quantum symmetry (or \textbf{quantum automorphism}) is an isometric automorphism of $\mathcal{H}\mathbb{P}$. The group of these symmetries is denoted by $\Aut_{\text{QM}}(\mathcal{H}\mathbb{P})$.
    }

    The following theorem due to \indexauthor{Wigner} gives a (linear) characterization of quantum symmetries.\footnote{It is a particular case of a more general theorem in projective geometry.}
    \begin{theorem}[Wigner]\index{Wigner}
        Every quantum automorphism of $\mathcal{H}\mathbb{P}$ is induced by a unitary or anti-unitary operator on $\mathcal{H}$.
    \end{theorem}
    This is equivalent to saying that the group morphism
    \begin{gather}
        \pi:\Aut(\mathcal{H},\mathcal{P}):=\mathrm{U}(\mathcal{H})\times\mathrm{AU}(\mathcal{H})\rightarrow\Aut_{\text{QM}}(\mathcal{H}\mathbb{P})
    \end{gather}
    is surjective. Together with the kernel $\mathrm{U}(1)$, given by phase shifts, this forms a short exact sequence:
    \begin{gather}
        1\longrightarrow\mathrm{U}(1)\longrightarrow\Aut(\mathcal{H},\mathcal{P})\longrightarrow\Aut_{\text{QM}}(\mathcal{H}\mathbb{P})\longrightarrow1\,.
    \end{gather}
    In the case of symmetry breaking (e.g.~lattice systems), the full symmetry group is reduced to a subgroup $G\subset\Aut_{\text{QM}}(\mathcal{H}\mathbb{P})$. The group of operators acting on $\mathcal{H}$ is then given by the pullback $\widetilde{G}$ of the diagram
    \begin{gather}
        \Aut(\mathcal{H},\mathcal{P})\longrightarrow\Aut_{\text{QM}}(\mathcal{H}\mathbb{P})\longleftarrow G\,.
    \end{gather}
    It should also be noted that the kernel of the homomorphism $\widetilde{G}\rightarrow G$ is again $\mathrm{U}(1)$. This leads to the property that $\widetilde{G}$ is a $\mathbb{Z}_2$-twisted (hence noncentral) $\mathrm{U}(1)$-extension of $G$, where the twist is induced by the homomorphism $\phi:\Aut(\mathcal{H},\mathcal{P})\rightarrow\mathbb{Z}_2$ that says whether an operator is implemented unitarily or anti-unitarily.

\subsection{Symmetric states}

    \begin{axiom}[Symmetrization postulate]\index{symmetrization postulate}
        Let $\mathcal{H}$ be the single-particle Hilbert space. A system of $n\in\mathbb{N}$ identical particles is described by a state $\ket{\Psi}$ belonging to either $S^n\mathcal{H}$ or $\Lambda^n\mathcal{H}$. These \textbf{bosonic} and \textbf{fermionic} states are, respectively, of the form
        \begin{gather}
            \ket{\Psi_B} = \sum_{\sigma\in S_n}\ket{\psi_{\sigma(1)}}\cdots\ket{\psi_{\sigma(n)}}
        \end{gather}
        and
        \begin{gather}
            \ket{\Psi_F} = \sum_{\sigma\in S_n}\sgn(\sigma)\ket{\psi_{\sigma(1)}}\cdots\ket{\psi_{\sigma(n)}}\,,
        \end{gather}
        where the $\ket{\psi_i}$ are single-particle states and $S_n$ is the permutation group on $n$ elements.
    \end{axiom}
    \begin{remark}\index{spin-statistics theorem}
        In ordinary quantum mechanics, this is a postulate, but in quantum field theory, this is a consequence of the \textit{spin-statistics theorem}. \todo{ADD THIS THEOREM TO [QFT]}
    \end{remark}

    \newdef{Slater determinant}{\index{Slater!determinant}\index{spin!orbitals}\index{permanent}
        Let $\{\phi_i(\vector{q})\}_{i\leq n}$ be a set of wave functions, called \textbf{spin orbitals}, describing a system of $n$ identical fermions. The totally antisymmetric wave function of the system is given by
        \begin{gather}
            \label{qm:slater_determinant}
            \psi(\vector{q}_1,\ldots,\vector{q}_n) = \frac{1}{\sqrt{n!}}\det
            \begin{pmatrix}
                \phi_1(\vector{q}_1)&\cdots&\phi_n(\vector{q}_1)\\
                \vdots&\ddots&\vdots\\
                \phi_1(\vector{q}_n)&\cdots&\phi_n(\vector{q}_n)
            \end{pmatrix}\,.
            \end{gather}
            A similar function can be defined for bosonic systems using the concept of \textit{permanents}.
    }

\section{\difficult{Foundations}}
\subsection{Measurement problem}

    If one looks at the Schr\"odinger equation (\cref{qm:TDSE}) or Ehrenfest's theorem (\cref{qm:ehrenfest}), it is easy to see that time evolution is entirely linear and deterministic. Superpositions are preserved under Hamiltonian flow (a crucial ingredient of quantum mechanics) and, given an initial state, time evolution will always lead to the same final state. However, the Born rule (\cref{qm:born_rule}), which governs `measurements' is very nonlinear and nondeterministic. It is probabilistic and, once a `measurement' has been performed, the state has `collapsed' onto an eigenstate of the observable under consideration.

    The issue of what constitutes a `measurement' --- Is it a conscious human doing an experiment? Is it a mouse interfering with an experiment? Is it two particles interacting? ...\footnote{This (perhaps artificial) boundary between classical and quantum is sometimes called the \textbf{Heisenberg cut}.\index{Heisenberg!cut}} --- and why exactly the Born rule holds and what it entails, i.e.~how probabilities arise, is known as the measurement problem. On a historical note, it should be noted that, after an initial surge of interest shortly after the $5^{\text{th}}$ Solvay Conference (1927), where quantum mechanics was formally established, the study of the foundations of quantum mechanics (the measurement problem specifically) became an infamous topic due to the pragmatic mentality of nuclear physics during the $20^{\text{th}}$ century.

    \todo{ADD (dynamical collapse, epistemic)}

\subsection{Copenhagen interpretation}

    The Copenhagen interpretation\footnote{This name stems from the fact that its initial proponents were from the group of physicists centered around \indexauthor{Bohr}.} takes the foundations of quantum mechanics as presented above very literally. 

    \todo{COMPLETE (e.g.~collapse)}

\subsection{Many-worlds interpretation}

    This interpretation, originating with \indexauthor{Everett}, posits a different idea, which does away with the need of the explicit Born rule axiom. In this interpretation, there is a kind of `universal wave function', which governs both the observer and the experiment. A 
    `measurement' is then simply an entanglement-inducing interaction between these two subsystems.

    The main implication of such an interpretation is, however, that the universal wave function branches every time such an interaction occurs. More precisely, assume that `we', the observers, perform a measurement on some system (for simplicity, assume that the measurement has a binary outcome). The measurement process is then described as follows:
    \begin{gather}
        \ket{\text{in}}_{\text{obs}}\ket{\text{in}}_{\text{exp}}\longrightarrow\lambda_0\ket{0}_{\text{obs}}\ket{0}_{\text{exp}}+\lambda_1\ket{1}_{\text{obs}}\ket{1}_{\text{exp}}\,.
    \end{gather}
    Taking this superposition as a physical reality, this means that if we had measured the state 0, a copy of us living on the other branch will have measured 1 (and the other way around).

    \todo{COMPLETE (e.g.~origin of probabilities)}

\subsection{Relational quantum mechanics}

    An important notion in classical physics is that of a \textit{reference frame}, i.e.~a choice of axes and scales. Usually, this corresponds to choosing an observer, relative to which one expresses the motion of all other objects. In relativity, the relative treatment of physics was the grand breakthrough by Einstein. However, although this notion had been left aside for a long time in the treatment of quantum mechanics and a specific choice of reference frame was silently assumed, this assumption was not as innocuous as it appears. Superposition and complementarity make a definite choice of absolute reference frame impossible.\index{reference frame!quantum}

    To understand the relevance of a relational approach to quantum mechanics, consider the following thought experiment. 
    \newdef{Wigner's friend}{\index{Wigner!friend}
        Consider two observers, Wigner and his friend, performing an experiment as shown diagrammatically in \cref{fig:wigners_friend}. One envisions Wigner standing outside the laboratory, having no way to observe what happens inside the lab, and his friend who performs an experiment inside the lab. The paradox arises from the two ways one can describe the sequence of the friend performing a measurement and Wigner checking up on the results in the classical (Copenhagen) interpretation.

        \begin{figure}[ht!]
            \centering
            \begin{tikzpicture}
                \draw (0, 0) rectangle (10, 6) node[above]{universe};
                \draw (5, 1) rectangle (9, 5) node[above]{lab};
                \draw[fill = black] (2.5, 3) circle (.1) node[above]{Wigner};
                \draw[fill = black] (6.5, 4) circle (.1) node[above]{friend};
                \draw[fill = blue] (7.5, 2) circle (.1) node[below, color = blue]{experiment};
            \end{tikzpicture}
            \caption{Wigner's friend thought experiment.}
            \label{fig:wigners_friend}
        \end{figure}

        From the point of view of the friend, at the moment of measurement, the projection/collapse axiom states that the wave function describing $\text{friend}+\text{experiment}$ `collapses' to:
        \begin{gather}
            \ket{\psi} = \ket{\uparrow}_{\text{friend}}\ket{\uparrow}_{\text{exp}}\,.
        \end{gather}
        However, from the point of view of Wigner, who has not observed the measurement, the state is described by
        \begin{gather}
            \ket{\psi}' = \alpha\ket{\uparrow}_{\text{friend}}\ket{\uparrow}_{\text{exp}}+\beta\ket{\downarrow}_{\text{friend}}\ket{\downarrow}_{\text{exp}}\,.
        \end{gather}
    }

    Whereas in the many-world approach one would simply take the branching approach, which is fully unitary and resolves this issue by avoiding collapse, the relational approach takes collapse at face value, but states that observations are relative, i.e.~always with respect to some fixed observer (be it a person, a classical object or another quantum-mechanical system). From this point of view, textbook Copenhagen QM is simply quantum mechanics with respect to some god-given observer, and collapse and unitary evolution do not have to be reconciled.

    The more general idea is that information and, hence, the values of observables are a relative notion, i.e.~variables only attain their values when considered with respect to a certain observer. As such, RQM is an epistemic interpretation of quantum mechanics in that the wave function only captures `our' information about the system (or universe) and not the `true' physical state. When applied to the notion of instantaneity (or velocity), this line of thinking will give rise to (special) relativity as in \cref{chapter:special_relativity} (and \cref{chapter:GR}).

    \todo{COMPLETE}

    For example, consider three observers: Alice, Bob and Charlie. Assume that each observer has a spin-$\tfrac{1}{2}$ particle and that, relative to Alice, the joint state is given by
    \begin{gather}
        \ket{\psi}^A_{ABC} = \ket{\uparrow}^A_A\left(\ket{\uparrow}^A_B+\ket{\downarrow}^A_B\right)\ket{\downarrow}^A_C\,.
    \end{gather}
    Note that this state is separable. Now, what would the state be relative to Bob? If one supposes that changes of reference frame are \textit{coherent} (to be formalized below), the joint state will be
    \begin{gather}
        \ket{\psi}^B_{ABC} = \ket{\uparrow}^B_B\left(\ket{\uparrow}^B_A\ket{\downarrow}^B_C+\ket{\downarrow}^B_A\ket{\uparrow}^B_C\right)\,.
    \end{gather}
    A mere change of reference frame, an operation that would classically leave the physics invariant, has transformed a product state into an entangled state.

    \begin{axiom}[Relational physics]
        Given $n\in\mathbb{N}$ systems\footnote{An abstraction of the notion of observer.}, any state is described relative to one of these systems. Given a choice of `observing system', let it be system $i$, the state of system $i$ is given by a fiducial state $\ket{0}^i_i$.
    \end{axiom}

    \begin{axiom}[Coherent change]\index{coherence}
        Consider a change of reference frame $0\longrightarrow i$ such that
        \begin{gather}
            \begin{cases}
                &\ket{\psi}^0\longrightarrow\ket{\psi}^i\\
                &\ket{\phi}^0\longrightarrow\ket{\phi}^i\,.
            \end{cases}
        \end{gather}
        Then
        \begin{gather}
            \alpha\ket{\psi}^0+\beta\ket{\phi}^0\longrightarrow\alpha\ket{\psi}^i+\beta\ket{\phi}^i
        \end{gather}
        for all $\alpha,\beta\in\mathbb{C}$.
    \end{axiom}

    Abstractly, a (classical) reference frame is defined as follows in the spirit of \cref{section:smooth_spaces} and \cref{section:space_and_quantity}.
    \newdef{Reference frame}{\index{reference frame}
        Let $X$ be an object of interest. Whereas a coordinate chart on $X$, modeled on an object $Y$, is given by a morphism $Y\rightarrow X$, a \textbf{coordinate system} on $X$ is given by an isomorphism $Y\cong X$, i.e.~a global coordinate chart. A reference frame is coordinate system for which $Y$ corresponds the a physical system.
    }

    Let the system of interest $X$ admit a group action that is both free and transitive, turning it into a $G$-torsor (\cref{group:torsor}). At the level of sets, one has $X\cong G$ and a choice of origin, i.e.~a specific choice of isomorphism, corresponds to a choice of reference frame (the identity element corresponding to the fiducial state above). A change of reference frames $s^0\longrightarrow s^i$, frome system $0$ to system $i$, is given by the right regular action of the relative coordinate of $i$ on all relative coordinates:
    \begin{gather}
        \phi^{0\longrightarrow i}(e,g^0_1,\ldots,g^0_n)\mapsto(g^i_0,g^0_1g^i_0,\ldots,e,\ldots,g^0_ng^i_0)\,,
    \end{gather}
    where the relation $g^0_i=(g^i_0)^{-1}$ was used. It should be noted that this boils down to a \textit{passive transformation}. When passing to the quantization of these systems, one should assume that $G$ is locally compact and comes equipped with the canonical Haar measure (\cref{distribution:haar_theorem}). In this case, a quantization is given by the space of square-integrable functions $L^2(G)$, where basis states are labeled by group elements.

    \todo{VERIFY THIS STATEMENT}

    The change-of-reference-frame operator is given as follows:
    \begin{gather}
        \widehat{U}^{0\longrightarrow i} := \mathrm{SWAP}_{0,i}\circ\Int_G\mathbbm{1}_{L^2(G)}\otimes \widehat{U}_R(g_i^0)^{\otimes i-2}\otimes\ket{g^i_0}\bra{g^0_i}\otimes\widehat{U}_R(g_i^0)^{\otimes n-i-2}\,dg^0_i\,,
    \end{gather}
    where
    \begin{gather}
        \widehat{U}_R(g):\ket{x}\mapsto\ket{xg^{-1}}
    \end{gather}
    is the unitary implementation of the right regular action and $dg$ denotes integration with respect to the Haar measure on $G$. It can be shown that $\widehat{U}^{0\longrightarrow i}$ is unitary, its inverse being given by $\widehat{U}^{i\longrightarrow 0}$ and composition is transitive. It can be shown that this procedure can be extended to any one-particle Hilbert space $\mathcal{H}$ as long as the inclusion $G\rightarrow\mathcal{H}$ is injective and maps $G$ to an orthonormal basis of (a subset of) $\mathcal{H}$.

\section{Angular Momentum}
\subsection{Angular momentum operator}

    \begin{property}[Lie algebra]
       The angular momentum operators generate a Lie algebra (\cref{lie:lie_algebra}). The Lie bracket is defined by the following commutation relation:
       \begin{gather}
           \label{angular_momentum:commutation}
           \left[\widehat{J}_i,\widehat{J}_j\right] = i\hbar\varepsilon_{ijk}\widehat{J}_k\,.
       \end{gather}
       Since rotations correspond to actions of the orthogonal group $\mathrm{SO}(3)$, it should not come as a surprise that the above relation is exactly the defining relation of the Lie algebra $\mathfrak{so}(3)$ from \cref{lie:so3}.
    \end{property}

    \begin{property}
       The mutual eigenbasis of $\widehat{J}^2$ and $\widehat{J}_z$ is defined by the following two eigenvalue equations:
       \begin{align}
           \label{angular_momentum:j}
           \widehat{J}^2\ket{j,m} &= j(j+1)\hbar^2\,\ket{j,m}\,,\\
           \label{angular_momentum:m}
           \widehat{J}_z\ket{j,m} &= m\hbar\,\ket{j,m}\,.
        \end{align}
    \end{property}

    \newdef{Ladder operators\footnotemark}{\index{ladder operators}
        \footnotetext{Also called the \textbf{creation} and \textbf{annihilation} operators (especially in quantum field theory).}
        The raising and lowering operators $\widehat{J}_+$ and $\widehat{J}_-$ are defined as follows:
        \begin{gather}
            \widehat{J}_+ := \widehat{J}_x + i\widehat{J}_y \qquad\text{and}\qquad \widehat{J}_- := \widehat{J}_x - i\widehat{J}_y\,.
        \end{gather}
        These operators only change the quantum number $m_z\in\mathbb{N}$, not the total angular momentum.
    }
    \begin{result}
        From the commutation relations of the angular momentum operators, one can derive the commutation relations of the ladder operators:
        \begin{gather}
            \left[\widehat{J}_+,\widehat{J}_-\right] = 2\hbar\widehat{J}_z\,.
        \end{gather}
    \end{result}

    \begin{formula}
        The total angular momentum operator $\widehat{J}^2$ can now be expressed in terms of $\widehat{J}_z$ and the ladder operators using the commutation relation~\eqref{angular_momentum:commutation}:
        \begin{gather}
            \widehat{J}^2 = \widehat{J}_+\widehat{J}_- + \widehat{J}_z^2 - \hbar\widehat{J}_z\,.
        \end{gather}
    \end{formula}
    \begin{remark}[Casimir operator]\index{Casimir!invariant}
        From the definition of $\widehat{J}^2$, it follows that this operator is a Casimir invariant (\cref{lie:casimir_invariant}) of $\mathfrak{so}(3)$.
    \end{remark}

\subsection{Rotations}

    \begin{formula}
        An infinitesimal rotation $\widehat{R}(\delta\vector{\varphi})$ is given by the following formula:
        \begin{gather}
            \label{angular_momentum:infinitesimal_rotation}
            \widehat{R}(\delta\vector{\varphi}) = \mathbbm{1} - \frac{i}{\hbar}\vector{J}\cdot\delta\vector{\varphi}\,.
        \end{gather}
        A finite rotation can be generated by applying this infinitesimal rotation repeatedly:
        \begin{gather}
            \label{angular_momentum:finite_rotation}
            \widehat{R}(\vector{\varphi}) = \left(\mathbbm{1} - \frac{i}{\hbar}\vector{J}\cdot\frac{\vector{\varphi}}{n}\right)^n = \exp\left(-\frac{i}{\hbar}\vector{J}\cdot\vector{\varphi}\right)\,.
        \end{gather}
    \end{formula}

    \newformula{Matrix elements}{\index{Wigner!$D$-function}
        Applying a rotation over an angle $\varphi$ about the $z$-axis to a state $\ket{j,m}$ gives
        \begin{gather}
            \widehat{R}(\varphi\vector{e}_z)\ket{j,m} = \exp\left(-\frac{i}{\hbar}\widehat{J}_z\varphi\right)\ket{j,m} = \exp\left(-\frac{i}{\hbar}m\varphi\right)\ket{j,m}\,.
        \end{gather}
        Multiplying these states with a bra $\bra{j',m'}$ and using the orthonormality of the eigenstates, gives the matrix elements of the rotation operator:
        \begin{gather}
            \widehat{R}_{ij}(\varphi\vector{e}_z) = \exp\left(-\frac{i}{\hbar}m\varphi\right)\delta_{jj'}\delta_{mm'}\,.
        \end{gather}
        From the expression of the angular momentum operators and the rotation operator, it is clear that a general rotation has no effect on the total angular momentum number $j\in\mathbb{N}$. This means that the rotation matrix will be block diagonal with respect to $j$. This amounts to the following reduction of the representation of the rotation group:
        \begin{gather}
            \bra{j,m'}\widehat{R}(\varphi\vector{n})\ket{j,m} = \mathcal{D}^{(j)}_{m,m'}(\widehat{R})\,,
        \end{gather}
        where the functions $\mathcal{D}^{(j)}_{m,m'}(\widehat{R})$ are called the \textbf{Wigner $D$-functions}. For every value of $j$, there are $(2j+1)$ values for $m$. This implies that the matrix $\mathcal{D}^{(j)}(\widehat{R})$ is a $(2j+1)\times(2j+1)$-matrix.
    }

\subsection{Spinor representation}

    \newdef{Pauli matrices}{\index{Pauli!matrix}\label{angular_momentum:pauli_matrices}
        \begin{gather}
            \sigma_x :=
            \begin{pmatrix}
                0&1\\
                1&0
            \end{pmatrix}
            \qquad
            \sigma_y :=
            \begin{pmatrix}
                0&-i\\
                i&0
            \end{pmatrix}
            \qquad
            \sigma_z :=
            \begin{pmatrix}
                1&0\\
                0&-1
            \end{pmatrix}
        \end{gather}
        From this definition, it is clear that the Pauli matrices are Hermitian and unitary. Together with the $2\times2$ identity matrix, they form a basis for the space of $2\times2$ Hermitian matrices. For this reason, the identity matrix is often denoted by $\sigma_0$ (especially in the context of relativistic QM).
    }

    \begin{formula}
        In the spinor representation ($J=\frac{1}{2}$), the Wigner-$D$ matrix reads as follows:
        \begin{gather}
            \mathcal{D}^{(1/2)}(\varphi\vector{e}_z) =
            \begin{pmatrix}
                e^{-i/2 \varphi}&0\\
                0&e^{i/2\varphi}
            \end{pmatrix}\,.
        \end{gather}
    \end{formula}

\subsection{Coupling of angular momenta}

    Due to the tensor product structure of a coupled Hilbert space, the angular momentum operator $\widehat{J}_i$ should now be interpreted as $\mathbbm{1}\otimes\cdots\otimes\widehat{J}_i\otimes\cdots\otimes\mathbbm{1}$ (cf.~\cref{vector:tensor_abuse}). Because the angular momentum operators $\widehat{J}_{k\neq i}$ do not act on the space $\mathcal{H}_i$, one can pull these operators through the tensor product:
    \begin{gather}
        \widehat{J}_i\ket{j_1}\otimes\cdots\otimes\ket{j_n} = \ket{j_1}\otimes\cdots\otimes\widehat{J}_i\ket{j_i}\otimes\cdots\otimes\ket{j_n}\,.
    \end{gather}
    The basis used above is called the \textbf{uncoupled basis}.

    For simplicity, the total Hilbert space is, from here on, assumed to be that of a two-particle system. Let $\widehat{J}$ denote the total angular momentum:
    \begin{gather}
        \widehat{J} = \widehat{J}_1 + \widehat{J}_2\,.
    \end{gather}
    With this operator, one can define a \textbf{coupled} state $\ket{J,M}$, where $M$ is the total magnetic quantum number which ranges from $-J$ to $J$.

    \newformula{Clebsch--Gordan coefficients}{\index{Clebsch--Gordan coefficient}\label{angular_momentum:clebsch-gordan}
        Because both bases (coupled and uncoupled) span the total Hilbert space $\mathcal{H}$, there exists an invertible transformation between them. The transformation coefficients can be found by using the resolution of the identity:
        \begin{gather}
            \ket{J,M} = \sum_{m_1=-j_1}^{j_1}\sum_{m_2=-j_2}^{j_2}\ket{j_1,j_2,m_1,m_2}\braket{j_1,j_2,m_1,m_2}{J,M}\,.
        \end{gather}
        These coefficients are called the Clebsch--Gordan coefficients.
    }

    \begin{property}
        By acting with the operator $\widehat{J}_z$ on both sides of \cref{angular_momentum:clebsch-gordan}, it is possible to prove that the Clebsch--Gordan coefficients are nonzero if and only if $M = m_1 + m_2$.
    \end{property}

\section{Electromagnetism}\index{electromagnetism}
\subsection{Pauli theory}

    Consider a charge $q$ moving though an electromagnetic field with potential $\symbf{A}\equiv(\varphi,\vector{A})$. In classical physics, the potential is often considered `nonphysical', as only the fields themselves are measurable. However, when also including quantum mechanics, this picture changes (see the next subsection).

    To account for the electromagnetic field, the ordinary Hamiltonian~\eqref{qm:TDSE_position} first has to be modified. In this section this will be considered in a nonrelativistic way, i.e.~the Dirac equation will not be considered.

    \newdef{Minimal coupling}{\index{minimal!coupling}\label{qm:minimal_coupling}
        In an electromagnetic potential $(\varphi,\vector{A})$, one performs the transformation
        \begin{gather}
            \label{qm:minimal_coupling_momentum}
            \widehat{p}\longrightarrow\widehat{p}+q\vector{A}\,.
        \end{gather}
        The reason for this transformation is that the canonical momentum $\widehat{p}=-i\hbar\nabla$ takes into account the effect of the electromagnetic field, but the kinetic part of the Hamiltonian should only care about the `kinetic momentum $m\vector{v}$'. This gives the following (minimally coupled) Hamiltonian:
        \begin{gather}
            \widehat{H} = \frac{(\widehat{p}-q\vector{A})^2}{2m}+q\varphi\,.
        \end{gather}
    }
    Note that transformation can be derived from the Lorentz force by writing in the form of \cref{classic:velocity_dependent_force}. Through the Lagrangian formalism, this then gives rise to a canonical momentum, which can be shown to be the minimally coupled momentum in \cref{qm:minimal_coupling_momentum} above.

\subsection{Aharonov--Bohm effect}\index{Aharonov--Bohm effect}

    Under a gauge transformation (\cref{section:em_gauge_theory}), the wave function changes as follows:
    \begin{gather}
        \psi' = \psi e^{-\frac{iq}{\hbar}\chi}\,.
    \end{gather}
    Now, consider a system where $\vector{B}=0$ or, equivalently, $\vector{A}=\nabla\chi$, i.e.~the field is \textbf{pure gauge}. As the name implies, this configuration can be gauge transformed to get $\vector{A}=0$. This gives
    \begin{gather}
        \psi' = \psi\exp\left(\frac{iq}{\hbar}\Int_{\vector{r_0}}^{\vector{r}}\vector{A}\cdot d\vector{r}\right)\,.
    \end{gather}
    Hence, to get the wave function for a pure gauge configuration,  one simply has to solve Schr\"odinger equation for a free particle and multiply by a phase factor (which is determined by the potential)! In particular, if one takes a path around a closed loop, one obtains
    \begin{gather}
        \frac{q}{\hbar}\Oint_\gamma\vector{A}\cdot d\vector{r} = 2\pi n
    \end{gather}
    for $n\in\mathbb{Z}$, since the free particle will return to its initial state without nontrivial phase factors. Now, by the Kelvin--Stokes Theorem~\ref{vector:kelvin_stokes_theorem}, the left-hand side is proportional to the magnetic flux through the loop:
    \begin{gather}
        \frac{q}{\hbar}\Phi = 2\pi n\,.
    \end{gather}
    This \textbf{flux quantization} can be observed in superconducting loops, where the field outside the solenoid has nonzero potential even though the magnetic field vanishes.

    Moreover, if one cuts the loop in two, representing the path of two charges going around the solenoid along different paths, one obtains a phase difference
    \begin{gather}
        \Delta\phi = \frac{q}{\hbar}\Phi\,.
    \end{gather}
    It follows that the magnetic flux induces an interference pattern, even though the charges themselves do not move through a nonzero field!

    \begin{formula}[Aharonov--Casher effect]\index{Aharonov--Casher effect}
        A dual (in the sense of electric-magnetic duality) also exists: the Aharonov--Casher effect.
        
        The phase shift along a path $\gamma$ is given by
        \begin{gather}
            \Delta\phi_\gamma = \frac{1}{\hbar c^2}\Int_\gamma(\vector{E}\times\vector{\mu})\cdot d\vector{x}\,,
        \end{gather}
        where $\vector{\mu}$ is the magnetic dipole moment.

        \todo{CHECK if $c^2$ is required in SI units (vs Gaussian)}
    \end{formula}

\section{Approximation methods}
\subsection{WKB approximation}\index{WKB approximation}\index{Green--Liouville method|see{WKB approximation}}

    The Wentzel--Kramers--Brillouin (WKB) approximation\footnote{This approach to solving second-order ODEs was essentially introduced a century earlier by \indexauthor{Green} and \indexauthor{Liouville}.} starts from the ansatz
    \begin{gather}
        \psi(\vector{q}) := \exp\left(iS(\vector{q})/\hbar\right)\,,
    \end{gather}
    with $S:\mathbb{R}^n\rightarrow\mathbb{R}$ a phase function that is to be determined. Inserting this in the TDSE (in configuration representation) gives:
    \begin{gather}
        \left[\frac{\|\vec{\nabla}S(\vector{q})\|^2}{2m} + \bigl(V(\vector{q})-E\bigr) - \frac{i\hbar \Delta S(\vector{q})}{2m}\right]\exp\left(iS(\vector{q})/\hbar\right) = 0\,.
    \end{gather}
    To first order, i.e.~for slowly varying potentials, the last term can be ignored. In this case, the phase function satisfies the Hamilton--Jacobi equation~\eqref{classic:time_independent_hje}:
    \begin{gather}
        H\bigl(\vector{q},S'(\vector{q})\bigr) = \frac{\|\vec{\nabla}S(\vector{q})\|^2}{2m}+\bigl(V(x)-E\bigr) = 0\,.
    \end{gather}
    In physics, the Hamilton--Jacobi equation without time derivative is often called the \textbf{eikonal equation}\footnote{This name stems from optics.}. This leads to the following result.

    \begin{property}\index{admissible!solution}\label{quantum:admissible_solution}
        A function $S:\mathbb{R}^n\rightarrow\mathbb{R}$ is a phase function for a first-order solution to the Schr\"odinger equation if its differential lies in a level set of the classical Hamiltonian $H:T^*\mathbb{R}^n\rightarrow\mathbb{R}$. These solutions are said to be \textbf{admissible}.
    \end{property}

    To obtain higher-order approximations, the solution has to be generalized beyond a pure phase function:
    \begin{gather}
        \psi(\vector{q}) = a(\vector{q})\exp\left(iS(\vector{q})/\hbar\right)\,.
    \end{gather}
    Assuming $S$ is admissible, the factor $a:\mathbb{R}^n\rightarrow\mathbb{R}$ satisfies the \textbf{homogeneous transport equation}:\index{transport equation}
    \begin{gather}
        \label{quantum:homogeneous_transport_equation}
        a\Delta S + 2\vec{\nabla}a\cdot\vec{\nabla}S = 0\,.
    \end{gather}
    If $a$ satisfies this equation, $\psi$ is called a \textbf{semiclassical state}.\index{semiclassical} Note that this equation is equivalent to $a^2\vec{\nabla}S$ being divergence free or, equivalently:
    \begin{gather}
        \mathcal{L}_{\pi_*X^H}(a^2\vol) = 0\,.
    \end{gather}
    Since Lie derivatives pull back under diffeomorphisms (\cref{bundle:pullback_lie_derivative}) and the image $\im(\dr S)$ gives a trivial subbundle of $T^*\mathbb{R}^n$, this is also equivalent to
    \begin{gather}
        \mathcal{L}_{X^H}(a^2\pi^*\vol) = 0\,.
    \end{gather}
    This quadratic behaviour in $a$ leads to the idea that the correct object for representing quantum states is a half-density (see also \cref{quantization:half_form}). This leads to the following statement:
    \begin{quote}
        A second-order solution to the Schr\"odinger equation is given by a pair $(S,a)$, where $S$ is an admissible phase function and $a\in\Omega^{1/2}(\im(\dr S))$ is a half-form that is invariant under the (classical) Hamiltonian flow.
    \end{quote}

    The generalization to curved spaces, i.e.~replacing $\mathbb{R}^{2n}$ by a symplectic manifold $M$, will be covered in \cref{section:curved_wkb}.

\section{\difficult{Curved backgrounds}}

    Using the tools of distribution theory and differential geometry (\namecrefs{chapter:distributions}~\ref{chapter:distributions}, \ref{chapter:bundles} and onwards), one can introduce quantum mechanics on curved backgrounds (in the sense of `space', not `spacetime').

\subsection{Extending quantum mechanics}

    \begin{remark}[Rigged Hilbert spaces]\index{Hilbert!rigged Hilbert space}\index{Gel'fand!triple}
        A first important remark to be made is that the classical definition of the wave function as an element of $L^2(\mathbb{R}^d,\mathbb{C})$ is not sufficient, even in flat Cartesian space. A complete description requires the introduction of so-called \textit{Gel'fand triples} or \textit{rigged Hilbert spaces}, where the space of square-integrable functions is replaced by the Schwartz space (\cref{distribution:schwartz_space}) of rapidly decreasing functions. The linear functionals on this space are then given by the tempered distributions.
    \end{remark}

    When working on curved spaces or even in non-Cartesian coordinates on flat space, one can encounter problems with the definition of the self-adjoint operators $\widehat{q}^i$ and $\widehat{p}_i$. The naive definition $\widehat{q}^i = q^i,\widehat{p}_i = -i\partial_i$ gives rise to extra terms that break the canonical commutation relations and the selfadjointness of the operators (e.g.~the angular position operator $\widehat{\varphi}$ on the circle together with its conjugate $\widehat{L}$) when calculating inner products.

    An elegant solution to this problem is obtained by giving up the definition of the wave function as a well-defined function $\psi:\mathbb{R}^d\rightarrow\mathbb{C}$. Assume that the physical space has the structure of a Riemannian manifold $(M,g)$ and that the `naive' wave functions take values in a vector space $V$. Then, construct a vector bundle $E$ with typical fibre $V$ over $M$. By \cref{bundle:section_bijection}, an invariant description of the `true' wave function is a map $\Psi:F(E)\rightarrow V$ or, locally, the pullback $\psi:=\varphi^*\Psi$ for some local section $\varphi:U\subseteq M\rightarrow F(E)$. The Levi-Civita connection on $M$ also induces a covariant derivative $\nabla$ on $E$ that can be used to define differential operators.

    Now, a general inner product can be introduced:
    \begin{gather}
        \langle\psi,\phi\rangle := \Int_M\overline{\psi(x)}\phi(x)\vol_M\,.
    \end{gather}
    Because the factor $\sqrt{\det(g)}$ transforms in the inverse manner of the measure $dx$, the integrand is invariant under coordinate transforms (something that is generally required of physical laws). Using this new inner product, one can for example check the selfadjointness of the momentum operator $\widehat{P}_i := -i\nabla_i$:
    \begin{align*}
        \langle\psi,\widehat{P}_i\phi\rangle = &\Int_M\overline{\psi(x)}(-i\nabla_i)\phi(x)\sqrt{\det(g)}\,dx\\
        \overset{\cref{bundle:local_covariant_derivative}}{=} &\Int_M\overline{\psi(x)}(-i\partial_i - i\omega_i)\phi(x)\sqrt{\det(g)}\,dx\\
        = &\Int_M\overline{(-i\partial_i\psi)(x)}\phi(x)\sqrt{\det(g)}\,dx+i\Int_M\overline{\psi(x)}\phi(x)\left(\partial_i\sqrt{\det(g)}\right)\,dx\\
            &\hspace{2cm} -i\Int_M\overline{\psi(x)}\omega_i\phi(x)\sqrt{\det(g)}\,dx\\
        = &\langle\widehat{P}_i\psi,\phi\rangle -i\Int_M\overline{\psi(x)}\overline{\omega_i}\phi(x)\sqrt{\det(g)}\,dx\\
            &\hspace{2cm} + i\Int_M\overline{\psi(x)}\phi(x)\left(\partial_i\sqrt{\det(g)}\right)\,dx\\
            &\hspace{2cm} -i\Int_M\overline{\psi(x)}\omega_i\phi(x)\sqrt{\det(g)}\,dx\,.
    \end{align*}
    Selfadjointness then requires that
    \begin{gather}
        \sqrt{\det(g)}(\omega_i + \overline{\omega_i}) = \partial_i\sqrt{\det(g)}
    \end{gather}
    or
    \begin{gather}
        2\mathrm{Re}(\omega_i) = \partial_i\ln\left(\sqrt{\det(g)}\right)\,.
    \end{gather}
    
    \todo{COMPLETE (rewrite in global terms)}

\subsection{WKB approximation}\label{section:curved_wkb}

    \Cref{quantum:admissible_solution} is generalized quite trivially after replacing $\mathbb{R}^n$ by a configuration manifold $Q$. A further step is provided by also generalizing \cref{symplectic:projectable_lagrangians}.
    \begin{property}\index{admissible!solution}
        A Lagrangian submanifold $\iota:L\hookrightarrow T^*Q$ will be called an admissible phase function for a first-order solution to the Schr\"odinger equation if it satisfies the classical Hamilton--Jacobi equation, i.e.~lies in a level set of the classical Hamiltonian $H:T^*Q\rightarrow\mathbb{R}$, for a regular value.
    \end{property}

    To obtain a second-order solution, one also needs prefactor for the semiclassical states. The homogeneous transport equation~\eqref{quantum:homogeneous_transport_equation} is generalized as follows:
    \begin{gather}
        a\Delta S + 2\mathcal{L}_{\nabla S}a = 0\,,
    \end{gather}
    where $\Delta$ is the Laplace--Beltrami operator on $Q$. As before, a general second-order solution, assuming $S$ is admissible, is given by a half-form $a\in\Omega^{1/2}(L)$ satisfying
    \begin{gather}
        \mathcal{L}_Ya = 0\,,
    \end{gather}
    where $Y$ is the (nonsingular) vector field on $L$ induced by $X^H$. This then gives a second-order solution on $Q$ by pulling back along the inverse $(\pi\circ\iota)^{-1}$, which is a diffeomorphism since $L$ is projectable. Moreover, if $L$ is exact (\cref{symplectic:exact_lagrangian}), then $S$ is induced by a primitive of the induced Liouville form $\iota^*\alpha$. If both the exactness and projectability conditions are dropped, the notion of a \textbf{geometric solution} are obtained.\index{geometric!solution}

    To pass to this more general situation, some more structure is needed. If $L$ is not exact, the Liouville form does not admit a global primitive. However, $L$ does admit a (good) cover $\{U_k\}_{k\in I}$ such that on every patch, a second-order solution can be found, and then the problem becomes how to glue these together. The gluing condition is the following integrality condition:
    \begin{gather}
        \label{quantum:integrality_condition}
        \phi_k(x)-\phi_l(x)\in2\pi\hbar\mathbb{Z}\,,
    \end{gather}
    where $\phi_k$ is the phase function on $U_k$, for all $x\in U_k\cap U_l$. Note that this condition can only be satisfied for all $\hbar\in\mathbb{R}^+$ if $[\alpha]=0$. However, this is exactly the condition that should be relaxed. Luckily, $\hbar$ should be a fixed value.
    
    \newdef{Quantizable Lagrangian}{
        A projectable Lagrangian submanifold $L\subset T^*M$ is said to be quantizable if there exists an $\hbar\in\mathbb{R}^+$ such that the restriction of the Liouville class to $L$ is $\hbar$-integral, i.e.~the integrality condition~\eqref{quantum:integrality_condition} is satisfied. All values $\hbar$ for which the integrality condition is satisfied, are said to be \textbf{admissible}.
    }
    \begin{remark}
        Note that the admissible values for $\hbar$ will form a decreasing sequence of the form
        \begin{gather}
            \hbar_0,\frac{\hbar_0}{2},\ldots\,,
        \end{gather}
        where $\hbar_0$ is the greatest admissible value.
    \end{remark}

    For the weakening of the projectability condition, see~\citet{bates_lectures_1997}. However, even without weakening that condition, there is still a remaining issue to the quantization of classical solutions. This will involve Maslov indices (\cref{section:maslov}) and Morse theory (\cref{symplectic:maslow_hormander}).